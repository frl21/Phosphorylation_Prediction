{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, LSTM, Embedding, Bidirectional, Input, Add, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from keras import regularizers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score, confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.initializers import he_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELM Dataset, S positive shape:  (1554, 9)\n",
      "PELM Dataset, T positive shape:  (707, 9)\n",
      "PELM Dataset, Y positive shape:  (267, 9)\n",
      "PPA Dataset, S positive shape:  (307, 9)\n",
      "PPA Dataset, T positive shape:  (68, 9)\n",
      "PPA Dataset, Y positive shape:  (51, 9)\n",
      "\n",
      "PELM Dataset, S negative shape:  (1543, 9)\n",
      "PELM Dataset, T negative shape:  (453, 9)\n",
      "PELM Dataset, Y negative shape:  (226, 9)\n",
      "PPA Dataset, S negative shape:  (307, 9)\n",
      "PPA Dataset, T negative shape:  (68, 9)\n",
      "PPA Dataset, Y negative shape:  (51, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read sample from Dataset\n",
    "\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_S_pos.fasta', 'r') as f:\n",
    "    PELM_s_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_T_pos.fasta', 'r') as f:\n",
    "    PELM_t_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_Y_pos.fasta', 'r') as f:\n",
    "    PELM_y_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/S_IDS_pos.fasta', 'r') as f:\n",
    "    PPA_s_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/T_IDS_pos.fasta', 'r') as f:\n",
    "    PPA_t_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/Y_IDS_pos.fasta', 'r') as f:\n",
    "    PPA_y_positif_txt = f.readlines()\n",
    "\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_S_neg.fasta', 'r') as f:\n",
    "    PELM_s_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_T_neg.fasta', 'r') as f:\n",
    "    PELM_t_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_Y_neg.fasta', 'r') as f:\n",
    "    PELM_y_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/S_IDS_neg.fasta', 'r') as f:\n",
    "    PPA_s_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/T_IDS_neg.fasta', 'r') as f:\n",
    "    PPA_t_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/Y_IDS_neg.fasta', 'r') as f:\n",
    "    PPA_y_negatif_txt = f.readlines()\n",
    "\n",
    "# Pick the window 9\n",
    "\n",
    "PELM_s_positif = np.array([])\n",
    "for i in range(1,len(PELM_s_positif_txt),2):\n",
    "    temp = PELM_s_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_s_positif = np.append(PELM_s_positif, temp2)\n",
    "print('PELM Dataset, S positive shape: ', PELM_s_positif.reshape(int(len(PELM_s_positif)/9),9).shape)\n",
    "\n",
    "PELM_t_positif = np.array([])\n",
    "for i in range(1,len(PELM_t_positif_txt),2):\n",
    "    temp = PELM_t_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_t_positif = np.append(PELM_t_positif, temp2)\n",
    "print('PELM Dataset, T positive shape: ', PELM_t_positif.reshape(int(len(PELM_t_positif)/9),9).shape)\n",
    "    \n",
    "PELM_y_positif = np.array([])\n",
    "for i in range(1,len(PELM_y_positif_txt),2):\n",
    "    temp = PELM_y_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_y_positif = np.append(PELM_y_positif, temp2)\n",
    "print('PELM Dataset, Y positive shape: ', PELM_y_positif.reshape(int(len(PELM_y_positif)/9),9).shape)\n",
    "\n",
    "PPA_s_positif = np.array([])\n",
    "for i in range(1,len(PPA_s_positif_txt),2):\n",
    "    temp = PPA_s_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_s_positif = np.append(PPA_s_positif, temp2)\n",
    "print('PPA Dataset, S positive shape: ', PPA_s_positif.reshape(int(len(PPA_s_positif)/9),9).shape)\n",
    "\n",
    "PPA_t_positif = np.array([])\n",
    "for i in range(1,len(PPA_t_positif_txt),2):\n",
    "    temp = PPA_t_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_t_positif = np.append(PPA_t_positif, temp2)\n",
    "print('PPA Dataset, T positive shape: ', PPA_t_positif.reshape(int(len(PPA_t_positif)/9),9).shape)\n",
    "    \n",
    "PPA_y_positif = np.array([])\n",
    "for i in range(1,len(PPA_y_positif_txt),2):\n",
    "    temp = PPA_y_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_y_positif = np.append(PPA_y_positif, temp2)\n",
    "print('PPA Dataset, Y positive shape: ', PPA_y_positif.reshape(int(len(PPA_y_positif)/9),9).shape)\n",
    "\n",
    "print()\n",
    "\n",
    "PELM_s_negatif = np.array([])\n",
    "for i in range(1,len(PELM_s_negatif_txt),2):\n",
    "    temp = PELM_s_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_s_negatif = np.append(PELM_s_negatif, temp2)\n",
    "print('PELM Dataset, S negative shape: ', PELM_s_negatif.reshape(int(len(PELM_s_negatif)/9),9).shape)\n",
    "\n",
    "PELM_t_negatif = np.array([])\n",
    "for i in range(1,len(PELM_t_negatif_txt),2):\n",
    "    temp = PELM_t_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_t_negatif = np.append(PELM_t_negatif, temp2)\n",
    "print('PELM Dataset, T negative shape: ', PELM_t_negatif.reshape(int(len(PELM_t_negatif)/9),9).shape)\n",
    "    \n",
    "PELM_y_negatif = np.array([])\n",
    "for i in range(1,len(PELM_y_negatif_txt),2):\n",
    "    temp = PELM_y_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_y_negatif = np.append(PELM_y_negatif, temp2)\n",
    "print('PELM Dataset, Y negative shape: ', PELM_y_negatif.reshape(int(len(PELM_y_negatif)/9),9).shape)\n",
    "\n",
    "PPA_s_negatif = np.array([])\n",
    "for i in range(1,len(PPA_s_negatif_txt),2):\n",
    "    temp = PPA_s_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_s_negatif = np.append(PPA_s_negatif, temp2)\n",
    "print('PPA Dataset, S negative shape: ', PPA_s_negatif.reshape(int(len(PPA_s_negatif)/9),9).shape)\n",
    "\n",
    "PPA_t_negatif = np.array([])\n",
    "for i in range(1,len(PPA_t_negatif_txt),2):\n",
    "    temp = PPA_t_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_t_negatif = np.append(PPA_t_negatif, temp2)\n",
    "print('PPA Dataset, T negative shape: ', PPA_t_negatif.reshape(int(len(PPA_t_negatif)/9),9).shape)\n",
    "    \n",
    "PPA_y_negatif = np.array([])\n",
    "for i in range(1,len(PPA_y_negatif_txt),2):\n",
    "    temp = PPA_y_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_y_negatif = np.append(PPA_y_negatif, temp2)\n",
    "print('PPA Dataset, Y negative shape: ', PPA_y_negatif.reshape(int(len(PPA_y_negatif)/9),9).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Dataset shape:  (267, 9)\n",
      "Positive Label shape:  (267, 1)\n",
      "Negative Dataset shape:  (226, 9)\n",
      "Negative Label shape:  (226, 1)\n"
     ]
    }
   ],
   "source": [
    "# Choose Dataset to train, make sure correspond with negative dataset\n",
    "\n",
    "dataset_pos = PELM_y_positif\n",
    "dataset_neg = PELM_y_negatif\n",
    "string_name = 'PELM_y'\n",
    "\n",
    "# Expand dimension, Reshape and Create Label\n",
    "\n",
    "sequenceLP = int(len(dataset_pos)/9)\n",
    "dataset_pos = np.expand_dims(dataset_pos, axis=0)\n",
    "dataset_pos = dataset_pos.reshape(sequenceLP,9)\n",
    "label_pos = np.ones((sequenceLP,), dtype=int)\n",
    "label_pos = np.expand_dims(label_pos, axis=0)\n",
    "label_pos = label_pos.reshape(sequenceLP,1)\n",
    "\n",
    "sequenceLN = int(len(dataset_neg)/9)\n",
    "dataset_neg = np.expand_dims(dataset_neg, axis=0)\n",
    "dataset_neg = dataset_neg.reshape(sequenceLN,9)\n",
    "label_neg = np.zeros((sequenceLN,), dtype=int)\n",
    "label_neg = np.expand_dims(label_neg, axis=0)\n",
    "label_neg = label_neg.reshape(sequenceLN,1)\n",
    "\n",
    "# Validate\n",
    "\n",
    "print('Positive Dataset shape: ', dataset_pos.shape)\n",
    "print('Positive Label shape: ', label_pos.shape)\n",
    "print('Negative Dataset shape: ', dataset_neg.shape)\n",
    "print('Negative Label shape: ', label_neg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample shape:  (355, 9)\n",
      "Training label shape:  (355, 2)\n",
      "Validation sample shape:  (88, 9)\n",
      "Validation label shape:  (88, 2)\n",
      "\n",
      "Training sample shape:  (354, 9)\n",
      "Training label shape:  (354, 2)\n",
      "Validation sample shape:  (89, 9)\n",
      "Validation label shape:  (89, 2)\n",
      "\n",
      "Training sample shape:  (355, 9)\n",
      "Training label shape:  (355, 2)\n",
      "Validation sample shape:  (88, 9)\n",
      "Validation label shape:  (88, 2)\n",
      "\n",
      "Training sample shape:  (354, 9)\n",
      "Training label shape:  (354, 2)\n",
      "Validation sample shape:  (89, 9)\n",
      "Validation label shape:  (89, 2)\n",
      "\n",
      "Training sample shape:  (354, 9)\n",
      "Training label shape:  (354, 2)\n",
      "Validation sample shape:  (89, 9)\n",
      "Validation label shape:  (89, 2)\n",
      "\n",
      "Test sample shape:  (50, 9)\n",
      "Test label shape:  (50, 2)\n",
      "Test sample shape:  (443, 9)\n",
      "Test label shape:  (443, 2)\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation\n",
    "\n",
    "dataset_X = np.concatenate((dataset_pos, dataset_neg), axis=0, out=None)\n",
    "dataset_Y = np.concatenate((label_pos, label_neg), axis=0, out=None)\n",
    "\n",
    "# Tokenizing, Unique character got its own number\n",
    "\n",
    "asam = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(asam)\n",
    "dataset_X_token = []\n",
    "for i in range(len(dataset_X)):\n",
    "    temp = tokenizer.texts_to_sequences(dataset_X[i])\n",
    "    dataset_X_token = np.append(dataset_X_token, temp)\n",
    "\n",
    "dataset_X_token = dataset_X_token-1\n",
    "dataset_X_token = dataset_X_token.reshape(len(dataset_X),9)\n",
    "\n",
    "# Onehot\n",
    "\n",
    "dataset_X_token_onehot = to_categorical(dataset_X_token)\n",
    "dataset_X_token_onehot = np.expand_dims(dataset_X_token_onehot, axis=3)\n",
    "dataset_X_token_onehot = dataset_X_token_onehot.reshape(len(dataset_X),9,20,1)\n",
    "\n",
    "dataset_Y_onehot = to_categorical(dataset_Y)\n",
    "\n",
    "# Spliting Dataset\n",
    "\n",
    "test_size = 0.1\n",
    "randomtest = 13\n",
    "main_X, test_X, main_Y, test_Y = train_test_split(dataset_X_token, dataset_Y_onehot, \n",
    "                                                      test_size=test_size, random_state=randomtest)\n",
    "\n",
    "# Divide into 5 dataset for cross validation\n",
    "\n",
    "pjg = len(main_X)\n",
    "A = int(pjg/5)\n",
    "B = int(pjg/5*2)\n",
    "C = int(pjg/5*3)\n",
    "D = int(pjg/5*4)\n",
    "\n",
    "train_X1 = main_X[A:pjg]\n",
    "train_Y1 = main_Y[A:pjg]\n",
    "valid_X1 = main_X[0:A]\n",
    "valid_Y1 = main_Y[0:A]\n",
    "\n",
    "train_X2 = np.vstack((main_X[0:A], main_X[B:pjg]))\n",
    "train_Y2 = np.vstack((main_Y[0:A], main_Y[B:pjg]))\n",
    "valid_X2 = main_X[A:B]\n",
    "valid_Y2 = main_Y[A:B]\n",
    "\n",
    "train_X3 = np.vstack((main_X[0:B], main_X[C:pjg]))\n",
    "train_Y3 = np.vstack((main_Y[0:B], main_Y[C:pjg]))\n",
    "valid_X3 = main_X[B:C]\n",
    "valid_Y3 = main_Y[B:C]\n",
    "\n",
    "train_X4 = np.vstack((main_X[0:C], main_X[D:pjg]))\n",
    "train_Y4 = np.vstack((main_Y[0:C], main_Y[D:pjg]))\n",
    "valid_X4 = main_X[C:D]\n",
    "valid_Y4 = main_Y[C:D]\n",
    "\n",
    "train_X5 = main_X[0:D]\n",
    "train_Y5 = main_Y[0:D]\n",
    "valid_X5 = main_X[D:pjg]\n",
    "valid_Y5 = main_Y[D:pjg]\n",
    "\n",
    "# Validation\n",
    "\n",
    "print('Training sample shape: ', train_X1.shape)\n",
    "print('Training label shape: ', train_Y1.shape)\n",
    "print('Validation sample shape: ', valid_X1.shape)\n",
    "print('Validation label shape: ', valid_Y1.shape)\n",
    "print()\n",
    "\n",
    "print('Training sample shape: ', train_X2.shape)\n",
    "print('Training label shape: ', train_Y2.shape)\n",
    "print('Validation sample shape: ', valid_X2.shape)\n",
    "print('Validation label shape: ', valid_Y2.shape)\n",
    "print()\n",
    "\n",
    "print('Training sample shape: ', train_X3.shape)\n",
    "print('Training label shape: ', train_Y3.shape)\n",
    "print('Validation sample shape: ', valid_X3.shape)\n",
    "print('Validation label shape: ', valid_Y3.shape)\n",
    "print()\n",
    "\n",
    "print('Training sample shape: ', train_X4.shape)\n",
    "print('Training label shape: ', train_Y4.shape)\n",
    "print('Validation sample shape: ', valid_X4.shape)\n",
    "print('Validation label shape: ', valid_Y4.shape)\n",
    "print()\n",
    "\n",
    "print('Training sample shape: ', train_X5.shape)\n",
    "print('Training label shape: ', train_Y5.shape)\n",
    "print('Validation sample shape: ', valid_X5.shape)\n",
    "print('Validation label shape: ', valid_Y5.shape)\n",
    "print()\n",
    "\n",
    "print('Test sample shape: ', test_X.shape)\n",
    "print('Test label shape: ', test_Y.shape)\n",
    "print('Test sample shape: ', main_X.shape)\n",
    "print('Test label shape: ', main_Y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 9, 128)            2560      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 183,426\n",
      "Trainable params: 183,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Modeling\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(20, 256, input_length=9))\n",
    "# model.add(Flatten(data_format=None))\n",
    "# model.add(Dense(128, activation='elu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dropout(0.8, noise_shape=None, seed=None))\n",
    "# model.add(Dense(128, activation='elu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dropout(0.8, noise_shape=None, seed=None))\n",
    "# model.add(Dense(128, activation='elu', kernel_initializer='he_uniform'))\n",
    "# model.add(Dropout(0.9, noise_shape=None, seed=None))\n",
    "# model.add(Dense(2, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "checkpoint1 = ModelCheckpoint('weight_best1.hdf5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "checkpoint2 = ModelCheckpoint('weight_best2.hdf5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "checkpoint3 = ModelCheckpoint('weight_best3.hdf5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "checkpoint4 = ModelCheckpoint('weight_best4.hdf5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "checkpoint5 = ModelCheckpoint('weight_best5.hdf5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "checkpoint = ModelCheckpoint('weight_best.hdf5', monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch > 70:\n",
    "        return 0.0001\n",
    "    elif epoch > 40:\n",
    "        return 0.0002\n",
    "    elif epoch > 10:\n",
    "        return 0.0005\n",
    "    else:\n",
    "        return 0.001 \n",
    "\n",
    "lr_schedule= LearningRateScheduler(scheduler)\n",
    "callback_list1 = [checkpoint1, lr_schedule]\n",
    "callback_list2 = [checkpoint2, lr_schedule]\n",
    "callback_list3 = [checkpoint3, lr_schedule]\n",
    "callback_list4 = [checkpoint4, lr_schedule]\n",
    "callback_list5 = [checkpoint5, lr_schedule]\n",
    "callback_list = [checkpoint, lr_schedule]\n",
    "\n",
    "# Input layer\n",
    "\n",
    "NODES = 13\n",
    "DROPOUT = 0.7\n",
    "BIAS = 0.001\n",
    "KERNEL = 0.001\n",
    "LR = 0.01\n",
    "\n",
    "inp = Input(shape=(9,))\n",
    "x = inp\n",
    "opt = Adam(lr=LR)\n",
    "\n",
    "# Hidden layers\n",
    "x = Embedding(20, 128, input_length=9)(x)\n",
    "x = Flatten(data_format=None)(x)\n",
    "x = Dense(128, activation='elu', kernel_initializer='he_uniform', bias_regularizer=regularizers.l2(BIAS), kernel_regularizer=regularizers.l2(KERNEL))(x)\n",
    "x = Dropout(DROPOUT, noise_shape=None, seed=None)(x)\n",
    "#x1 = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu', kernel_initializer='he_uniform', bias_regularizer=regularizers.l2(BIAS), kernel_regularizer=regularizers.l2(KERNEL))(x)\n",
    "x = Dropout(DROPOUT, noise_shape=None, seed=None)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x1 = Add()([x1, x])\n",
    "x = Dense(128, activation='elu', kernel_initializer='he_uniform', bias_regularizer=regularizers.l2(BIAS), kernel_regularizer=regularizers.l2(KERNEL))(x)\n",
    "x = Dropout(DROPOUT, noise_shape=None, seed=None)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x1 = Add()([x1, x])\n",
    "# x = Dense(128, activation='relu', kernel_initializer='he_uniform', bias_regularizer=regularizers.l2(BIAS), kernel_regularizer=regularizers.l2(KERNEL))(x1)\n",
    "# x = Dropout(DROPOUT, noise_shape=None, seed=None)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x1 = Add()([x1, x])\n",
    "output = Dense(2, activation='softmax', bias_regularizer=regularizers.l2(BIAS), kernel_regularizer=regularizers.l2(KERNEL), name='output_layer')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.save_weights('model.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train 1\n",
      "Train on 355 samples, validate on 88 samples\n",
      "Epoch 1/80\n",
      "355/355 [==============================] - 1s 2ms/step - loss: 1.4899 - acc: 0.5408 - val_loss: 1.4423 - val_acc: 0.6136\n",
      "Epoch 2/80\n",
      "355/355 [==============================] - 0s 118us/step - loss: 1.4492 - acc: 0.5296 - val_loss: 1.4220 - val_acc: 0.5795\n",
      "Epoch 3/80\n",
      "355/355 [==============================] - 0s 120us/step - loss: 1.4457 - acc: 0.5606 - val_loss: 1.4018 - val_acc: 0.5795\n",
      "Epoch 4/80\n",
      "355/355 [==============================] - 0s 138us/step - loss: 1.4464 - acc: 0.5577 - val_loss: 1.3610 - val_acc: 0.7045\n",
      "Epoch 5/80\n",
      "355/355 [==============================] - 0s 126us/step - loss: 1.4111 - acc: 0.5521 - val_loss: 1.3444 - val_acc: 0.6818\n",
      "Epoch 6/80\n",
      "355/355 [==============================] - 0s 124us/step - loss: 1.3693 - acc: 0.5944 - val_loss: 1.3185 - val_acc: 0.7045\n",
      "Epoch 7/80\n",
      "355/355 [==============================] - 0s 128us/step - loss: 1.3562 - acc: 0.6282 - val_loss: 1.2950 - val_acc: 0.7500\n",
      "Epoch 8/80\n",
      "355/355 [==============================] - 0s 111us/step - loss: 1.2983 - acc: 0.6225 - val_loss: 1.2491 - val_acc: 0.7273\n",
      "Epoch 9/80\n",
      "355/355 [==============================] - 0s 114us/step - loss: 1.2654 - acc: 0.6761 - val_loss: 1.2135 - val_acc: 0.7273\n",
      "Epoch 10/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 1.2271 - acc: 0.6620 - val_loss: 1.1961 - val_acc: 0.7273\n",
      "Epoch 11/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 1.1418 - acc: 0.7521 - val_loss: 1.1744 - val_acc: 0.7386\n",
      "Epoch 12/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 1.1292 - acc: 0.7577 - val_loss: 1.1568 - val_acc: 0.7386\n",
      "Epoch 13/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 1.1229 - acc: 0.7718 - val_loss: 1.1243 - val_acc: 0.8068\n",
      "Epoch 14/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 1.0891 - acc: 0.7803 - val_loss: 1.1151 - val_acc: 0.7955\n",
      "Epoch 15/80\n",
      "355/355 [==============================] - 0s 116us/step - loss: 1.0461 - acc: 0.7887 - val_loss: 1.1150 - val_acc: 0.7955\n",
      "Epoch 16/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 1.0957 - acc: 0.7718 - val_loss: 1.1152 - val_acc: 0.7727\n",
      "Epoch 17/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 1.0194 - acc: 0.8000 - val_loss: 1.0964 - val_acc: 0.7955\n",
      "Epoch 18/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 1.0076 - acc: 0.8141 - val_loss: 1.0890 - val_acc: 0.7841\n",
      "Epoch 19/80\n",
      "355/355 [==============================] - 0s 125us/step - loss: 0.9867 - acc: 0.8394 - val_loss: 1.1026 - val_acc: 0.7614\n",
      "Epoch 20/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.9963 - acc: 0.8169 - val_loss: 1.0946 - val_acc: 0.7727\n",
      "Epoch 21/80\n",
      "355/355 [==============================] - 0s 115us/step - loss: 0.9605 - acc: 0.8535 - val_loss: 1.1066 - val_acc: 0.7614\n",
      "Epoch 22/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 1.0158 - acc: 0.8366 - val_loss: 1.1227 - val_acc: 0.7386\n",
      "Epoch 23/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.9230 - acc: 0.8563 - val_loss: 1.1352 - val_acc: 0.7500\n",
      "Epoch 24/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.9541 - acc: 0.8479 - val_loss: 1.1476 - val_acc: 0.7727\n",
      "Epoch 25/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.9253 - acc: 0.8423 - val_loss: 1.1640 - val_acc: 0.7727\n",
      "Epoch 26/80\n",
      "355/355 [==============================] - 0s 111us/step - loss: 0.9054 - acc: 0.8592 - val_loss: 1.1630 - val_acc: 0.7386\n",
      "Epoch 27/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.9053 - acc: 0.8732 - val_loss: 1.2048 - val_acc: 0.7273\n",
      "Epoch 28/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.9265 - acc: 0.8451 - val_loss: 1.2117 - val_acc: 0.7386\n",
      "Epoch 29/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 0.8723 - acc: 0.8761 - val_loss: 1.2017 - val_acc: 0.7500\n",
      "Epoch 30/80\n",
      "355/355 [==============================] - 0s 115us/step - loss: 0.8854 - acc: 0.8676 - val_loss: 1.1824 - val_acc: 0.7727\n",
      "Epoch 31/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.9035 - acc: 0.8648 - val_loss: 1.1741 - val_acc: 0.7614\n",
      "Epoch 32/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.8640 - acc: 0.8845 - val_loss: 1.1811 - val_acc: 0.7500\n",
      "Epoch 33/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.8768 - acc: 0.8507 - val_loss: 1.1727 - val_acc: 0.7386\n",
      "Epoch 34/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.8301 - acc: 0.8986 - val_loss: 1.1897 - val_acc: 0.7500\n",
      "Epoch 35/80\n",
      "355/355 [==============================] - 0s 113us/step - loss: 0.8842 - acc: 0.8620 - val_loss: 1.1806 - val_acc: 0.7614\n",
      "Epoch 36/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.8408 - acc: 0.8930 - val_loss: 1.1516 - val_acc: 0.7727\n",
      "Epoch 37/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.8230 - acc: 0.8930 - val_loss: 1.1666 - val_acc: 0.7500\n",
      "Epoch 38/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.7984 - acc: 0.8986 - val_loss: 1.2076 - val_acc: 0.7159\n",
      "Epoch 39/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.7847 - acc: 0.9099 - val_loss: 1.2106 - val_acc: 0.7386\n",
      "Epoch 40/80\n",
      "355/355 [==============================] - 0s 111us/step - loss: 0.8051 - acc: 0.8845 - val_loss: 1.1888 - val_acc: 0.7500\n",
      "Epoch 41/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.8087 - acc: 0.8845 - val_loss: 1.2003 - val_acc: 0.7614\n",
      "Epoch 42/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.7541 - acc: 0.9014 - val_loss: 1.2262 - val_acc: 0.7386\n",
      "Epoch 43/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.7982 - acc: 0.8732 - val_loss: 1.2260 - val_acc: 0.7386\n",
      "Epoch 44/80\n",
      "355/355 [==============================] - 0s 114us/step - loss: 0.7662 - acc: 0.9070 - val_loss: 1.2211 - val_acc: 0.7386\n",
      "Epoch 45/80\n",
      "355/355 [==============================] - 0s 118us/step - loss: 0.7747 - acc: 0.9127 - val_loss: 1.2234 - val_acc: 0.7386\n",
      "Epoch 46/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.7850 - acc: 0.8761 - val_loss: 1.2321 - val_acc: 0.7273\n",
      "Epoch 47/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.7579 - acc: 0.9014 - val_loss: 1.2729 - val_acc: 0.7386\n",
      "Epoch 48/80\n",
      "355/355 [==============================] - 0s 112us/step - loss: 0.7596 - acc: 0.9042 - val_loss: 1.2773 - val_acc: 0.7273\n",
      "Epoch 49/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.7509 - acc: 0.8986 - val_loss: 1.2832 - val_acc: 0.7273\n",
      "Epoch 50/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.7676 - acc: 0.9070 - val_loss: 1.2951 - val_acc: 0.7045\n",
      "Epoch 51/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.7665 - acc: 0.9296 - val_loss: 1.3045 - val_acc: 0.7045\n",
      "Epoch 52/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.7780 - acc: 0.8930 - val_loss: 1.3073 - val_acc: 0.7045\n",
      "Epoch 53/80\n",
      "355/355 [==============================] - 0s 115us/step - loss: 0.7296 - acc: 0.9183 - val_loss: 1.3012 - val_acc: 0.7159\n",
      "Epoch 54/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.7271 - acc: 0.9070 - val_loss: 1.3083 - val_acc: 0.7045\n",
      "Epoch 55/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.7225 - acc: 0.9127 - val_loss: 1.3150 - val_acc: 0.7045\n",
      "Epoch 56/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.7825 - acc: 0.9042 - val_loss: 1.3150 - val_acc: 0.7159\n",
      "Epoch 57/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.7097 - acc: 0.9211 - val_loss: 1.3131 - val_acc: 0.7159\n",
      "Epoch 58/80\n",
      "355/355 [==============================] - 0s 116us/step - loss: 0.7557 - acc: 0.9014 - val_loss: 1.3027 - val_acc: 0.7159\n",
      "Epoch 59/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.7418 - acc: 0.9183 - val_loss: 1.3056 - val_acc: 0.7159\n",
      "Epoch 60/80\n",
      "355/355 [==============================] - 0s 122us/step - loss: 0.7356 - acc: 0.9268 - val_loss: 1.3103 - val_acc: 0.7159\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 0s 102us/step - loss: 0.7177 - acc: 0.9070 - val_loss: 1.3230 - val_acc: 0.7159\n",
      "Epoch 62/80\n",
      "355/355 [==============================] - 0s 98us/step - loss: 0.7082 - acc: 0.9296 - val_loss: 1.3311 - val_acc: 0.7045\n",
      "Epoch 63/80\n",
      "355/355 [==============================] - 0s 94us/step - loss: 0.6964 - acc: 0.9183 - val_loss: 1.3333 - val_acc: 0.7045\n",
      "Epoch 64/80\n",
      "355/355 [==============================] - 0s 96us/step - loss: 0.7288 - acc: 0.9014 - val_loss: 1.3177 - val_acc: 0.7273\n",
      "Epoch 65/80\n",
      "355/355 [==============================] - 0s 99us/step - loss: 0.6852 - acc: 0.9070 - val_loss: 1.3254 - val_acc: 0.7273\n",
      "Epoch 66/80\n",
      "355/355 [==============================] - 0s 117us/step - loss: 0.7090 - acc: 0.9099 - val_loss: 1.3409 - val_acc: 0.7159\n",
      "Epoch 67/80\n",
      "355/355 [==============================] - 0s 115us/step - loss: 0.7096 - acc: 0.9211 - val_loss: 1.3685 - val_acc: 0.7045\n",
      "Epoch 68/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.7002 - acc: 0.9183 - val_loss: 1.3616 - val_acc: 0.7045\n",
      "Epoch 69/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.6809 - acc: 0.9239 - val_loss: 1.3618 - val_acc: 0.7045\n",
      "Epoch 70/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.6889 - acc: 0.9099 - val_loss: 1.3575 - val_acc: 0.7159\n",
      "Epoch 71/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.7073 - acc: 0.9070 - val_loss: 1.3687 - val_acc: 0.7045\n",
      "Epoch 72/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.7120 - acc: 0.9155 - val_loss: 1.3644 - val_acc: 0.7159\n",
      "Epoch 73/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.6792 - acc: 0.9408 - val_loss: 1.3705 - val_acc: 0.7045\n",
      "Epoch 74/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.6853 - acc: 0.9437 - val_loss: 1.3789 - val_acc: 0.7045\n",
      "Epoch 75/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.6987 - acc: 0.8986 - val_loss: 1.3727 - val_acc: 0.7159\n",
      "Epoch 76/80\n",
      "355/355 [==============================] - 0s 111us/step - loss: 0.7231 - acc: 0.9127 - val_loss: 1.3723 - val_acc: 0.7159\n",
      "Epoch 77/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.6840 - acc: 0.9155 - val_loss: 1.3602 - val_acc: 0.7273\n",
      "Epoch 78/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 0.6547 - acc: 0.9296 - val_loss: 1.3588 - val_acc: 0.7273\n",
      "Epoch 79/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.6908 - acc: 0.9211 - val_loss: 1.3671 - val_acc: 0.7159\n",
      "Epoch 80/80\n",
      "355/355 [==============================] - 0s 113us/step - loss: 0.6756 - acc: 0.9211 - val_loss: 1.3776 - val_acc: 0.7045\n",
      "Model Train 2\n",
      "Train on 354 samples, validate on 89 samples\n",
      "Epoch 1/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.4838 - acc: 0.5254 - val_loss: 1.4594 - val_acc: 0.4607\n",
      "Epoch 2/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.4609 - acc: 0.5593 - val_loss: 1.4522 - val_acc: 0.4607\n",
      "Epoch 3/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 1.4862 - acc: 0.5282 - val_loss: 1.4241 - val_acc: 0.4719\n",
      "Epoch 4/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.4608 - acc: 0.5452 - val_loss: 1.3920 - val_acc: 0.5618\n",
      "Epoch 5/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.4235 - acc: 0.5565 - val_loss: 1.3809 - val_acc: 0.5056\n",
      "Epoch 6/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.4151 - acc: 0.5565 - val_loss: 1.3651 - val_acc: 0.5056\n",
      "Epoch 7/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.3635 - acc: 0.5989 - val_loss: 1.3364 - val_acc: 0.5618\n",
      "Epoch 8/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.3318 - acc: 0.6328 - val_loss: 1.2929 - val_acc: 0.7416\n",
      "Epoch 9/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.3205 - acc: 0.6299 - val_loss: 1.2630 - val_acc: 0.7079\n",
      "Epoch 10/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.2706 - acc: 0.6610 - val_loss: 1.2428 - val_acc: 0.6742\n",
      "Epoch 11/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 1.2457 - acc: 0.6695 - val_loss: 1.2059 - val_acc: 0.7640\n",
      "Epoch 12/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.2052 - acc: 0.7062 - val_loss: 1.2057 - val_acc: 0.7079\n",
      "Epoch 13/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.1654 - acc: 0.7514 - val_loss: 1.2045 - val_acc: 0.6742\n",
      "Epoch 14/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.1472 - acc: 0.7401 - val_loss: 1.1762 - val_acc: 0.7191\n",
      "Epoch 15/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.1163 - acc: 0.7797 - val_loss: 1.1479 - val_acc: 0.7528\n",
      "Epoch 16/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.1358 - acc: 0.7712 - val_loss: 1.1387 - val_acc: 0.7528\n",
      "Epoch 17/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.0829 - acc: 0.7910 - val_loss: 1.1519 - val_acc: 0.7528\n",
      "Epoch 18/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 1.0753 - acc: 0.7740 - val_loss: 1.1482 - val_acc: 0.7528\n",
      "Epoch 19/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.0505 - acc: 0.8107 - val_loss: 1.1273 - val_acc: 0.7640\n",
      "Epoch 20/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.0359 - acc: 0.8475 - val_loss: 1.1410 - val_acc: 0.7528\n",
      "Epoch 21/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.9931 - acc: 0.8333 - val_loss: 1.1469 - val_acc: 0.7528\n",
      "Epoch 22/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.9913 - acc: 0.8418 - val_loss: 1.1490 - val_acc: 0.7640\n",
      "Epoch 23/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.9822 - acc: 0.8531 - val_loss: 1.1390 - val_acc: 0.7640\n",
      "Epoch 24/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.9581 - acc: 0.8588 - val_loss: 1.1441 - val_acc: 0.7753\n",
      "Epoch 25/80\n",
      "354/354 [==============================] - 0s 117us/step - loss: 0.9484 - acc: 0.8475 - val_loss: 1.1404 - val_acc: 0.7640\n",
      "Epoch 26/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.9136 - acc: 0.8672 - val_loss: 1.1453 - val_acc: 0.7753\n",
      "Epoch 27/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.9076 - acc: 0.8531 - val_loss: 1.1513 - val_acc: 0.7753\n",
      "Epoch 28/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.8979 - acc: 0.8559 - val_loss: 1.1857 - val_acc: 0.7303\n",
      "Epoch 29/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.9167 - acc: 0.8672 - val_loss: 1.1862 - val_acc: 0.7303\n",
      "Epoch 30/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.8920 - acc: 0.8927 - val_loss: 1.2082 - val_acc: 0.7303\n",
      "Epoch 31/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.8799 - acc: 0.8729 - val_loss: 1.1948 - val_acc: 0.7416\n",
      "Epoch 32/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.8923 - acc: 0.8701 - val_loss: 1.1736 - val_acc: 0.7753\n",
      "Epoch 33/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8776 - acc: 0.8898 - val_loss: 1.2053 - val_acc: 0.7416\n",
      "Epoch 34/80\n",
      "354/354 [==============================] - 0s 112us/step - loss: 0.8691 - acc: 0.8701 - val_loss: 1.2277 - val_acc: 0.7303\n",
      "Epoch 35/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8222 - acc: 0.8898 - val_loss: 1.2230 - val_acc: 0.7416\n",
      "Epoch 36/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.8258 - acc: 0.8927 - val_loss: 1.2119 - val_acc: 0.7528\n",
      "Epoch 37/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.8551 - acc: 0.8729 - val_loss: 1.2198 - val_acc: 0.7303\n",
      "Epoch 38/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.8140 - acc: 0.8757 - val_loss: 1.2392 - val_acc: 0.7303\n",
      "Epoch 39/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.8107 - acc: 0.8927 - val_loss: 1.2369 - val_acc: 0.7191\n",
      "Epoch 40/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.7817 - acc: 0.9096 - val_loss: 1.2519 - val_acc: 0.7303\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 105us/step - loss: 0.8126 - acc: 0.8927 - val_loss: 1.2915 - val_acc: 0.7191\n",
      "Epoch 42/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7729 - acc: 0.9096 - val_loss: 1.3195 - val_acc: 0.7303\n",
      "Epoch 43/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.8015 - acc: 0.8785 - val_loss: 1.3147 - val_acc: 0.7303\n",
      "Epoch 44/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.7789 - acc: 0.9209 - val_loss: 1.3158 - val_acc: 0.7079\n",
      "Epoch 45/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7535 - acc: 0.9266 - val_loss: 1.3179 - val_acc: 0.7079\n",
      "Epoch 46/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7797 - acc: 0.9096 - val_loss: 1.3209 - val_acc: 0.7079\n",
      "Epoch 47/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7765 - acc: 0.9096 - val_loss: 1.3310 - val_acc: 0.7079\n",
      "Epoch 48/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.7622 - acc: 0.8927 - val_loss: 1.3438 - val_acc: 0.7079\n",
      "Epoch 49/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7539 - acc: 0.9266 - val_loss: 1.3370 - val_acc: 0.7079\n",
      "Epoch 50/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7874 - acc: 0.9068 - val_loss: 1.3451 - val_acc: 0.7191\n",
      "Epoch 51/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7744 - acc: 0.8983 - val_loss: 1.3498 - val_acc: 0.7079\n",
      "Epoch 52/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.7541 - acc: 0.9153 - val_loss: 1.3473 - val_acc: 0.7191\n",
      "Epoch 53/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7375 - acc: 0.9181 - val_loss: 1.3522 - val_acc: 0.7191\n",
      "Epoch 54/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7345 - acc: 0.9266 - val_loss: 1.3474 - val_acc: 0.7079\n",
      "Epoch 55/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 0.7552 - acc: 0.9040 - val_loss: 1.3645 - val_acc: 0.7079\n",
      "Epoch 56/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7636 - acc: 0.9124 - val_loss: 1.3889 - val_acc: 0.7191\n",
      "Epoch 57/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7493 - acc: 0.9124 - val_loss: 1.3858 - val_acc: 0.7191\n",
      "Epoch 58/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7322 - acc: 0.9011 - val_loss: 1.3846 - val_acc: 0.7079\n",
      "Epoch 59/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.7475 - acc: 0.9096 - val_loss: 1.3855 - val_acc: 0.7191\n",
      "Epoch 60/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.7638 - acc: 0.9011 - val_loss: 1.3794 - val_acc: 0.7079\n",
      "Epoch 61/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.6932 - acc: 0.9237 - val_loss: 1.3850 - val_acc: 0.7079\n",
      "Epoch 62/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.7116 - acc: 0.9237 - val_loss: 1.3676 - val_acc: 0.7303\n",
      "Epoch 63/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.7322 - acc: 0.9350 - val_loss: 1.3878 - val_acc: 0.7191\n",
      "Epoch 64/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.7304 - acc: 0.9237 - val_loss: 1.4067 - val_acc: 0.7191\n",
      "Epoch 65/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.6985 - acc: 0.9209 - val_loss: 1.4029 - val_acc: 0.7191\n",
      "Epoch 66/80\n",
      "354/354 [==============================] - 0s 112us/step - loss: 0.6971 - acc: 0.9322 - val_loss: 1.4117 - val_acc: 0.7191\n",
      "Epoch 67/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.6959 - acc: 0.9209 - val_loss: 1.4201 - val_acc: 0.7191\n",
      "Epoch 68/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7109 - acc: 0.9237 - val_loss: 1.4303 - val_acc: 0.7191\n",
      "Epoch 69/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7026 - acc: 0.9237 - val_loss: 1.4372 - val_acc: 0.7191\n",
      "Epoch 70/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.6907 - acc: 0.9294 - val_loss: 1.4479 - val_acc: 0.7191\n",
      "Epoch 71/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.6937 - acc: 0.9237 - val_loss: 1.4432 - val_acc: 0.7303\n",
      "Epoch 72/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 0.6665 - acc: 0.9435 - val_loss: 1.4355 - val_acc: 0.7191\n",
      "Epoch 73/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.6615 - acc: 0.9548 - val_loss: 1.4420 - val_acc: 0.7191\n",
      "Epoch 74/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.6769 - acc: 0.9492 - val_loss: 1.4570 - val_acc: 0.7191\n",
      "Epoch 75/80\n",
      "354/354 [==============================] - 0s 112us/step - loss: 0.6762 - acc: 0.9463 - val_loss: 1.4582 - val_acc: 0.7191\n",
      "Epoch 76/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.6877 - acc: 0.9209 - val_loss: 1.4608 - val_acc: 0.7191\n",
      "Epoch 77/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.6902 - acc: 0.9237 - val_loss: 1.4790 - val_acc: 0.7303\n",
      "Epoch 78/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.6843 - acc: 0.9294 - val_loss: 1.4808 - val_acc: 0.7303\n",
      "Epoch 79/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.6818 - acc: 0.9153 - val_loss: 1.4837 - val_acc: 0.7303\n",
      "Epoch 80/80\n",
      "354/354 [==============================] - 0s 112us/step - loss: 0.6788 - acc: 0.9350 - val_loss: 1.4792 - val_acc: 0.7303\n",
      "Model Train 3\n",
      "Train on 355 samples, validate on 88 samples\n",
      "Epoch 1/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 1.4926 - acc: 0.4873 - val_loss: 1.4516 - val_acc: 0.5909\n",
      "Epoch 2/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 1.4822 - acc: 0.5465 - val_loss: 1.4293 - val_acc: 0.6932\n",
      "Epoch 3/80\n",
      "355/355 [==============================] - 0s 113us/step - loss: 1.4860 - acc: 0.5211 - val_loss: 1.4191 - val_acc: 0.6705\n",
      "Epoch 4/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 1.4506 - acc: 0.5380 - val_loss: 1.4087 - val_acc: 0.6250\n",
      "Epoch 5/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 1.4668 - acc: 0.5070 - val_loss: 1.3849 - val_acc: 0.6705\n",
      "Epoch 6/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 1.4247 - acc: 0.5549 - val_loss: 1.3574 - val_acc: 0.5795\n",
      "Epoch 7/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 1.3972 - acc: 0.5775 - val_loss: 1.3320 - val_acc: 0.6136\n",
      "Epoch 8/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 1.3894 - acc: 0.5746 - val_loss: 1.3184 - val_acc: 0.6818\n",
      "Epoch 9/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 1.3887 - acc: 0.5690 - val_loss: 1.2970 - val_acc: 0.7273\n",
      "Epoch 10/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 1.3182 - acc: 0.5887 - val_loss: 1.2710 - val_acc: 0.7500\n",
      "Epoch 11/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 1.2807 - acc: 0.6366 - val_loss: 1.2436 - val_acc: 0.7273\n",
      "Epoch 12/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 1.2456 - acc: 0.6817 - val_loss: 1.2267 - val_acc: 0.7500\n",
      "Epoch 13/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 1.2469 - acc: 0.6648 - val_loss: 1.1964 - val_acc: 0.7386\n",
      "Epoch 14/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 1.2097 - acc: 0.7014 - val_loss: 1.1735 - val_acc: 0.7500\n",
      "Epoch 15/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 1.1969 - acc: 0.7183 - val_loss: 1.1606 - val_acc: 0.7159\n",
      "Epoch 16/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 1.1948 - acc: 0.7211 - val_loss: 1.1419 - val_acc: 0.7386\n",
      "Epoch 17/80\n",
      "355/355 [==============================] - 0s 112us/step - loss: 1.1483 - acc: 0.7437 - val_loss: 1.1253 - val_acc: 0.7614\n",
      "Epoch 18/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 1.1190 - acc: 0.7690 - val_loss: 1.1062 - val_acc: 0.7727\n",
      "Epoch 19/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 1.0885 - acc: 0.7408 - val_loss: 1.0778 - val_acc: 0.7727\n",
      "Epoch 20/80\n",
      "355/355 [==============================] - 0s 113us/step - loss: 1.0949 - acc: 0.7746 - val_loss: 1.0597 - val_acc: 0.7841\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 0s 104us/step - loss: 1.1023 - acc: 0.7634 - val_loss: 1.0526 - val_acc: 0.7727\n",
      "Epoch 22/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 1.0911 - acc: 0.7746 - val_loss: 1.0477 - val_acc: 0.7614\n",
      "Epoch 23/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 1.0605 - acc: 0.7972 - val_loss: 1.0357 - val_acc: 0.7955\n",
      "Epoch 24/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 1.0318 - acc: 0.8254 - val_loss: 1.0285 - val_acc: 0.7727\n",
      "Epoch 25/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 1.0419 - acc: 0.8085 - val_loss: 1.0011 - val_acc: 0.8068\n",
      "Epoch 26/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 1.0338 - acc: 0.8000 - val_loss: 0.9858 - val_acc: 0.8295\n",
      "Epoch 27/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 1.0304 - acc: 0.7887 - val_loss: 0.9738 - val_acc: 0.8409\n",
      "Epoch 28/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.9471 - acc: 0.8310 - val_loss: 0.9648 - val_acc: 0.8523\n",
      "Epoch 29/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.9692 - acc: 0.8479 - val_loss: 0.9520 - val_acc: 0.8523\n",
      "Epoch 30/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.9669 - acc: 0.8535 - val_loss: 0.9417 - val_acc: 0.8523\n",
      "Epoch 31/80\n",
      "355/355 [==============================] - 0s 111us/step - loss: 0.9463 - acc: 0.8366 - val_loss: 0.9414 - val_acc: 0.8409\n",
      "Epoch 32/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.9361 - acc: 0.8507 - val_loss: 0.9398 - val_acc: 0.8409\n",
      "Epoch 33/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.9622 - acc: 0.8366 - val_loss: 0.9279 - val_acc: 0.8409\n",
      "Epoch 34/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.9250 - acc: 0.8535 - val_loss: 0.9245 - val_acc: 0.8182\n",
      "Epoch 35/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.9199 - acc: 0.8535 - val_loss: 0.9261 - val_acc: 0.8409\n",
      "Epoch 36/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.9125 - acc: 0.8648 - val_loss: 0.9097 - val_acc: 0.8295\n",
      "Epoch 37/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.8987 - acc: 0.8563 - val_loss: 0.9072 - val_acc: 0.8295\n",
      "Epoch 38/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.8855 - acc: 0.8620 - val_loss: 0.9176 - val_acc: 0.8295\n",
      "Epoch 39/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.8725 - acc: 0.8507 - val_loss: 0.9111 - val_acc: 0.8182\n",
      "Epoch 40/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 0.9031 - acc: 0.8648 - val_loss: 0.9144 - val_acc: 0.8068\n",
      "Epoch 41/80\n",
      "355/355 [==============================] - 0s 114us/step - loss: 0.8651 - acc: 0.8592 - val_loss: 0.9239 - val_acc: 0.7955\n",
      "Epoch 42/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.8690 - acc: 0.8620 - val_loss: 0.9191 - val_acc: 0.8068\n",
      "Epoch 43/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.8641 - acc: 0.8704 - val_loss: 0.9131 - val_acc: 0.8182\n",
      "Epoch 44/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.8555 - acc: 0.8761 - val_loss: 0.9116 - val_acc: 0.8182\n",
      "Epoch 45/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.8776 - acc: 0.8845 - val_loss: 0.9115 - val_acc: 0.8182\n",
      "Epoch 46/80\n",
      "355/355 [==============================] - 0s 108us/step - loss: 0.8506 - acc: 0.8789 - val_loss: 0.9110 - val_acc: 0.8068\n",
      "Epoch 47/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.8433 - acc: 0.8704 - val_loss: 0.9125 - val_acc: 0.8068\n",
      "Epoch 48/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.8376 - acc: 0.8704 - val_loss: 0.9119 - val_acc: 0.8068\n",
      "Epoch 49/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.8528 - acc: 0.8732 - val_loss: 0.9140 - val_acc: 0.7955\n",
      "Epoch 50/80\n",
      "355/355 [==============================] - 0s 115us/step - loss: 0.8294 - acc: 0.8732 - val_loss: 0.9245 - val_acc: 0.7841\n",
      "Epoch 51/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.8735 - acc: 0.8423 - val_loss: 0.9248 - val_acc: 0.7841\n",
      "Epoch 52/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.8093 - acc: 0.8845 - val_loss: 0.9233 - val_acc: 0.7841\n",
      "Epoch 53/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.8176 - acc: 0.8930 - val_loss: 0.9156 - val_acc: 0.8182\n",
      "Epoch 54/80\n",
      "355/355 [==============================] - 0s 115us/step - loss: 0.8159 - acc: 0.8817 - val_loss: 0.9147 - val_acc: 0.8182\n",
      "Epoch 55/80\n",
      "355/355 [==============================] - 0s 114us/step - loss: 0.8308 - acc: 0.8789 - val_loss: 0.9165 - val_acc: 0.8068\n",
      "Epoch 56/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.8192 - acc: 0.8789 - val_loss: 0.9161 - val_acc: 0.7955\n",
      "Epoch 57/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 0.7857 - acc: 0.9042 - val_loss: 0.9161 - val_acc: 0.7955\n",
      "Epoch 58/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.8249 - acc: 0.8704 - val_loss: 0.9173 - val_acc: 0.7841\n",
      "Epoch 59/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 0.8025 - acc: 0.8789 - val_loss: 0.9182 - val_acc: 0.7955\n",
      "Epoch 60/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.8125 - acc: 0.8789 - val_loss: 0.9191 - val_acc: 0.7955\n",
      "Epoch 61/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 0.7984 - acc: 0.8901 - val_loss: 0.9194 - val_acc: 0.7955\n",
      "Epoch 62/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.7953 - acc: 0.8761 - val_loss: 0.9228 - val_acc: 0.8068\n",
      "Epoch 63/80\n",
      "355/355 [==============================] - 0s 103us/step - loss: 0.7998 - acc: 0.8986 - val_loss: 0.9303 - val_acc: 0.8068\n",
      "Epoch 64/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.7853 - acc: 0.8873 - val_loss: 0.9331 - val_acc: 0.8068\n",
      "Epoch 65/80\n",
      "355/355 [==============================] - 0s 105us/step - loss: 0.7877 - acc: 0.8986 - val_loss: 0.9329 - val_acc: 0.7955\n",
      "Epoch 66/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 0.7759 - acc: 0.8986 - val_loss: 0.9324 - val_acc: 0.8068\n",
      "Epoch 67/80\n",
      "355/355 [==============================] - 0s 118us/step - loss: 0.7897 - acc: 0.8845 - val_loss: 0.9347 - val_acc: 0.8068\n",
      "Epoch 68/80\n",
      "355/355 [==============================] - 0s 107us/step - loss: 0.7844 - acc: 0.8845 - val_loss: 0.9292 - val_acc: 0.8068\n",
      "Epoch 69/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.7954 - acc: 0.8873 - val_loss: 0.9339 - val_acc: 0.7955\n",
      "Epoch 70/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.7799 - acc: 0.9155 - val_loss: 0.9435 - val_acc: 0.8068\n",
      "Epoch 71/80\n",
      "355/355 [==============================] - 0s 104us/step - loss: 0.7970 - acc: 0.8958 - val_loss: 0.9431 - val_acc: 0.7955\n",
      "Epoch 72/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.7635 - acc: 0.8986 - val_loss: 0.9419 - val_acc: 0.8068\n",
      "Epoch 73/80\n",
      "355/355 [==============================] - 0s 112us/step - loss: 0.7487 - acc: 0.9014 - val_loss: 0.9421 - val_acc: 0.8068\n",
      "Epoch 74/80\n",
      "355/355 [==============================] - 0s 109us/step - loss: 0.7460 - acc: 0.9014 - val_loss: 0.9433 - val_acc: 0.7955\n",
      "Epoch 75/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.7620 - acc: 0.9042 - val_loss: 0.9436 - val_acc: 0.8068\n",
      "Epoch 76/80\n",
      "355/355 [==============================] - 0s 106us/step - loss: 0.7715 - acc: 0.8930 - val_loss: 0.9437 - val_acc: 0.8182\n",
      "Epoch 77/80\n",
      "355/355 [==============================] - 0s 113us/step - loss: 0.7517 - acc: 0.8958 - val_loss: 0.9433 - val_acc: 0.8182\n",
      "Epoch 78/80\n",
      "355/355 [==============================] - 0s 110us/step - loss: 0.7711 - acc: 0.8873 - val_loss: 0.9406 - val_acc: 0.8182\n",
      "Epoch 79/80\n",
      "355/355 [==============================] - 0s 102us/step - loss: 0.7332 - acc: 0.9014 - val_loss: 0.9389 - val_acc: 0.8182\n",
      "Epoch 80/80\n",
      "355/355 [==============================] - 0s 111us/step - loss: 0.7587 - acc: 0.8676 - val_loss: 0.9379 - val_acc: 0.8182\n",
      "Model Train 4\n",
      "Train on 354 samples, validate on 89 samples\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 108us/step - loss: 1.4876 - acc: 0.5113 - val_loss: 1.4587 - val_acc: 0.4382\n",
      "Epoch 2/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.5289 - acc: 0.4944 - val_loss: 1.4287 - val_acc: 0.6067\n",
      "Epoch 3/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.5045 - acc: 0.5113 - val_loss: 1.4117 - val_acc: 0.5955\n",
      "Epoch 4/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.4599 - acc: 0.5424 - val_loss: 1.3953 - val_acc: 0.6517\n",
      "Epoch 5/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.4474 - acc: 0.5113 - val_loss: 1.3779 - val_acc: 0.6966\n",
      "Epoch 6/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 1.3675 - acc: 0.6073 - val_loss: 1.3514 - val_acc: 0.7079\n",
      "Epoch 7/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 1.3867 - acc: 0.5593 - val_loss: 1.3280 - val_acc: 0.7079\n",
      "Epoch 8/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.3466 - acc: 0.5989 - val_loss: 1.3095 - val_acc: 0.7191\n",
      "Epoch 9/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 1.3200 - acc: 0.6158 - val_loss: 1.2860 - val_acc: 0.6966\n",
      "Epoch 10/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.2701 - acc: 0.6977 - val_loss: 1.2688 - val_acc: 0.6854\n",
      "Epoch 11/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 1.2693 - acc: 0.6667 - val_loss: 1.2240 - val_acc: 0.7191\n",
      "Epoch 12/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 1.2134 - acc: 0.7232 - val_loss: 1.2087 - val_acc: 0.7528\n",
      "Epoch 13/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.2216 - acc: 0.7260 - val_loss: 1.2015 - val_acc: 0.7528\n",
      "Epoch 14/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 1.1714 - acc: 0.7373 - val_loss: 1.1777 - val_acc: 0.7753\n",
      "Epoch 15/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.1274 - acc: 0.7797 - val_loss: 1.1612 - val_acc: 0.7303\n",
      "Epoch 16/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.1686 - acc: 0.7429 - val_loss: 1.1501 - val_acc: 0.7416\n",
      "Epoch 17/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.0901 - acc: 0.7797 - val_loss: 1.1550 - val_acc: 0.7640\n",
      "Epoch 18/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.0847 - acc: 0.7966 - val_loss: 1.1627 - val_acc: 0.7865\n",
      "Epoch 19/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.0390 - acc: 0.8023 - val_loss: 1.1855 - val_acc: 0.7865\n",
      "Epoch 20/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.0669 - acc: 0.7966 - val_loss: 1.1562 - val_acc: 0.7528\n",
      "Epoch 21/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 1.0603 - acc: 0.7994 - val_loss: 1.1462 - val_acc: 0.7416\n",
      "Epoch 22/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.0017 - acc: 0.8249 - val_loss: 1.1538 - val_acc: 0.7416\n",
      "Epoch 23/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.9855 - acc: 0.8362 - val_loss: 1.1624 - val_acc: 0.7416\n",
      "Epoch 24/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 0.9852 - acc: 0.8418 - val_loss: 1.1807 - val_acc: 0.7303\n",
      "Epoch 25/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.9411 - acc: 0.8729 - val_loss: 1.1850 - val_acc: 0.7191\n",
      "Epoch 26/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.9945 - acc: 0.8220 - val_loss: 1.1924 - val_acc: 0.7416\n",
      "Epoch 27/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.9237 - acc: 0.8701 - val_loss: 1.1908 - val_acc: 0.7416\n",
      "Epoch 28/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.9331 - acc: 0.8814 - val_loss: 1.2227 - val_acc: 0.7528\n",
      "Epoch 29/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.9338 - acc: 0.8757 - val_loss: 1.2398 - val_acc: 0.7640\n",
      "Epoch 30/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.8950 - acc: 0.8729 - val_loss: 1.2375 - val_acc: 0.7640\n",
      "Epoch 31/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.8961 - acc: 0.8729 - val_loss: 1.2521 - val_acc: 0.7753\n",
      "Epoch 32/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.9341 - acc: 0.8588 - val_loss: 1.3162 - val_acc: 0.7079\n",
      "Epoch 33/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.9178 - acc: 0.8672 - val_loss: 1.2740 - val_acc: 0.7191\n",
      "Epoch 34/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.9090 - acc: 0.8644 - val_loss: 1.2814 - val_acc: 0.7416\n",
      "Epoch 35/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8940 - acc: 0.8785 - val_loss: 1.2740 - val_acc: 0.7303\n",
      "Epoch 36/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8479 - acc: 0.8785 - val_loss: 1.2724 - val_acc: 0.7640\n",
      "Epoch 37/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8831 - acc: 0.8785 - val_loss: 1.3012 - val_acc: 0.7528\n",
      "Epoch 38/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.9194 - acc: 0.8390 - val_loss: 1.3145 - val_acc: 0.7416\n",
      "Epoch 39/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.8433 - acc: 0.8701 - val_loss: 1.3076 - val_acc: 0.7416\n",
      "Epoch 40/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.8454 - acc: 0.8785 - val_loss: 1.3120 - val_acc: 0.7528\n",
      "Epoch 41/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.8368 - acc: 0.8983 - val_loss: 1.3165 - val_acc: 0.7416\n",
      "Epoch 42/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8495 - acc: 0.8757 - val_loss: 1.3166 - val_acc: 0.7640\n",
      "Epoch 43/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8331 - acc: 0.8701 - val_loss: 1.3208 - val_acc: 0.7303\n",
      "Epoch 44/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7914 - acc: 0.9068 - val_loss: 1.3205 - val_acc: 0.7416\n",
      "Epoch 45/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.8396 - acc: 0.8814 - val_loss: 1.3160 - val_acc: 0.7416\n",
      "Epoch 46/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8653 - acc: 0.8927 - val_loss: 1.3137 - val_acc: 0.7416\n",
      "Epoch 47/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7980 - acc: 0.8927 - val_loss: 1.3124 - val_acc: 0.7416\n",
      "Epoch 48/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.8134 - acc: 0.9011 - val_loss: 1.3245 - val_acc: 0.7303\n",
      "Epoch 49/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7656 - acc: 0.9237 - val_loss: 1.3231 - val_acc: 0.7303\n",
      "Epoch 50/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7815 - acc: 0.9011 - val_loss: 1.3193 - val_acc: 0.7753\n",
      "Epoch 51/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.8015 - acc: 0.8955 - val_loss: 1.3213 - val_acc: 0.7528\n",
      "Epoch 52/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.8093 - acc: 0.8955 - val_loss: 1.3193 - val_acc: 0.7753\n",
      "Epoch 53/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.7968 - acc: 0.8983 - val_loss: 1.3238 - val_acc: 0.7753\n",
      "Epoch 54/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7979 - acc: 0.8898 - val_loss: 1.3316 - val_acc: 0.7528\n",
      "Epoch 55/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.8089 - acc: 0.9068 - val_loss: 1.3342 - val_acc: 0.7528\n",
      "Epoch 56/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7703 - acc: 0.9153 - val_loss: 1.3356 - val_acc: 0.7528\n",
      "Epoch 57/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7789 - acc: 0.9096 - val_loss: 1.3414 - val_acc: 0.7416\n",
      "Epoch 58/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7777 - acc: 0.9011 - val_loss: 1.3402 - val_acc: 0.7303\n",
      "Epoch 59/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 0.7625 - acc: 0.8955 - val_loss: 1.3548 - val_acc: 0.7079\n",
      "Epoch 60/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7701 - acc: 0.8842 - val_loss: 1.3551 - val_acc: 0.7079\n",
      "Epoch 61/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.7586 - acc: 0.9124 - val_loss: 1.3526 - val_acc: 0.7303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7589 - acc: 0.9181 - val_loss: 1.3525 - val_acc: 0.7191\n",
      "Epoch 63/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7620 - acc: 0.9068 - val_loss: 1.3559 - val_acc: 0.7191\n",
      "Epoch 64/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7892 - acc: 0.9040 - val_loss: 1.3502 - val_acc: 0.7303\n",
      "Epoch 65/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7671 - acc: 0.9068 - val_loss: 1.3423 - val_acc: 0.7528\n",
      "Epoch 66/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7448 - acc: 0.9266 - val_loss: 1.3425 - val_acc: 0.7528\n",
      "Epoch 67/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7414 - acc: 0.9209 - val_loss: 1.3476 - val_acc: 0.7528\n",
      "Epoch 68/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7612 - acc: 0.9124 - val_loss: 1.3536 - val_acc: 0.7528\n",
      "Epoch 69/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7452 - acc: 0.9068 - val_loss: 1.3610 - val_acc: 0.7416\n",
      "Epoch 70/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7594 - acc: 0.8955 - val_loss: 1.3660 - val_acc: 0.7416\n",
      "Epoch 71/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7394 - acc: 0.9124 - val_loss: 1.3649 - val_acc: 0.7416\n",
      "Epoch 72/80\n",
      "354/354 [==============================] - 0s 116us/step - loss: 0.7570 - acc: 0.9237 - val_loss: 1.3667 - val_acc: 0.7416\n",
      "Epoch 73/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7252 - acc: 0.9124 - val_loss: 1.3712 - val_acc: 0.7416\n",
      "Epoch 74/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.6970 - acc: 0.9379 - val_loss: 1.3722 - val_acc: 0.7303\n",
      "Epoch 75/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.7195 - acc: 0.9237 - val_loss: 1.3760 - val_acc: 0.7303\n",
      "Epoch 76/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.7275 - acc: 0.9124 - val_loss: 1.3776 - val_acc: 0.7303\n",
      "Epoch 77/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.7264 - acc: 0.9153 - val_loss: 1.3773 - val_acc: 0.7303\n",
      "Epoch 78/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7331 - acc: 0.9181 - val_loss: 1.3754 - val_acc: 0.7416\n",
      "Epoch 79/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7226 - acc: 0.9209 - val_loss: 1.3763 - val_acc: 0.7416\n",
      "Epoch 80/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7194 - acc: 0.9153 - val_loss: 1.3721 - val_acc: 0.7416\n",
      "Model Train 5\n",
      "Train on 354 samples, validate on 89 samples\n",
      "Epoch 1/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 1.5106 - acc: 0.4802 - val_loss: 1.4520 - val_acc: 0.5393\n",
      "Epoch 2/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 1.4701 - acc: 0.5508 - val_loss: 1.4513 - val_acc: 0.4831\n",
      "Epoch 3/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.4946 - acc: 0.5113 - val_loss: 1.4345 - val_acc: 0.5056\n",
      "Epoch 4/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 1.4231 - acc: 0.5763 - val_loss: 1.4174 - val_acc: 0.5169\n",
      "Epoch 5/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 1.4595 - acc: 0.5339 - val_loss: 1.4010 - val_acc: 0.5056\n",
      "Epoch 6/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.4044 - acc: 0.5395 - val_loss: 1.3768 - val_acc: 0.6292\n",
      "Epoch 7/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.3686 - acc: 0.6045 - val_loss: 1.3524 - val_acc: 0.6742\n",
      "Epoch 8/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.3811 - acc: 0.5904 - val_loss: 1.3285 - val_acc: 0.6966\n",
      "Epoch 9/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 1.3628 - acc: 0.5763 - val_loss: 1.2957 - val_acc: 0.7191\n",
      "Epoch 10/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 1.2946 - acc: 0.6469 - val_loss: 1.2733 - val_acc: 0.6742\n",
      "Epoch 11/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.2393 - acc: 0.7203 - val_loss: 1.2390 - val_acc: 0.7416\n",
      "Epoch 12/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 1.2184 - acc: 0.7119 - val_loss: 1.2250 - val_acc: 0.7191\n",
      "Epoch 13/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.1971 - acc: 0.7401 - val_loss: 1.2251 - val_acc: 0.6854\n",
      "Epoch 14/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 1.1784 - acc: 0.7655 - val_loss: 1.2103 - val_acc: 0.6854\n",
      "Epoch 15/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 1.1327 - acc: 0.7966 - val_loss: 1.2043 - val_acc: 0.7191\n",
      "Epoch 16/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 1.1287 - acc: 0.7797 - val_loss: 1.2065 - val_acc: 0.6966\n",
      "Epoch 17/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.0904 - acc: 0.7938 - val_loss: 1.1982 - val_acc: 0.6742\n",
      "Epoch 18/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 1.0767 - acc: 0.7910 - val_loss: 1.1893 - val_acc: 0.7191\n",
      "Epoch 19/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 1.0528 - acc: 0.8220 - val_loss: 1.1992 - val_acc: 0.6854\n",
      "Epoch 20/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 1.0533 - acc: 0.7994 - val_loss: 1.2180 - val_acc: 0.6854\n",
      "Epoch 21/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 1.0040 - acc: 0.8136 - val_loss: 1.2026 - val_acc: 0.7079\n",
      "Epoch 22/80\n",
      "354/354 [==============================] - 0s 112us/step - loss: 0.9972 - acc: 0.8446 - val_loss: 1.2004 - val_acc: 0.7303\n",
      "Epoch 23/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.9857 - acc: 0.8362 - val_loss: 1.2270 - val_acc: 0.6966\n",
      "Epoch 24/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.9512 - acc: 0.8701 - val_loss: 1.2509 - val_acc: 0.7079\n",
      "Epoch 25/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.9637 - acc: 0.8559 - val_loss: 1.2332 - val_acc: 0.6966\n",
      "Epoch 26/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.9445 - acc: 0.8644 - val_loss: 1.2600 - val_acc: 0.7191\n",
      "Epoch 27/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.9685 - acc: 0.8475 - val_loss: 1.2873 - val_acc: 0.6854\n",
      "Epoch 28/80\n",
      "354/354 [==============================] - 0s 100us/step - loss: 0.9145 - acc: 0.8701 - val_loss: 1.2706 - val_acc: 0.7079\n",
      "Epoch 29/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.9329 - acc: 0.8785 - val_loss: 1.2793 - val_acc: 0.7079\n",
      "Epoch 30/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.8794 - acc: 0.8757 - val_loss: 1.3370 - val_acc: 0.6742\n",
      "Epoch 31/80\n",
      "354/354 [==============================] - 0s 113us/step - loss: 0.9018 - acc: 0.8757 - val_loss: 1.3294 - val_acc: 0.6854\n",
      "Epoch 32/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.9261 - acc: 0.8701 - val_loss: 1.3387 - val_acc: 0.6742\n",
      "Epoch 33/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.8682 - acc: 0.8785 - val_loss: 1.3651 - val_acc: 0.6742\n",
      "Epoch 34/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8640 - acc: 0.9068 - val_loss: 1.3428 - val_acc: 0.6854\n",
      "Epoch 35/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.8791 - acc: 0.8870 - val_loss: 1.3347 - val_acc: 0.6966\n",
      "Epoch 36/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8635 - acc: 0.8785 - val_loss: 1.3441 - val_acc: 0.6854\n",
      "Epoch 37/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.8576 - acc: 0.8898 - val_loss: 1.3346 - val_acc: 0.7079\n",
      "Epoch 38/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8604 - acc: 0.8729 - val_loss: 1.3545 - val_acc: 0.7079\n",
      "Epoch 39/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.8506 - acc: 0.8955 - val_loss: 1.3799 - val_acc: 0.6966\n",
      "Epoch 40/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.8286 - acc: 0.8842 - val_loss: 1.3706 - val_acc: 0.6854\n",
      "Epoch 41/80\n",
      "354/354 [==============================] - 0s 112us/step - loss: 0.8238 - acc: 0.9011 - val_loss: 1.3875 - val_acc: 0.6966\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354/354 [==============================] - 0s 105us/step - loss: 0.8036 - acc: 0.8983 - val_loss: 1.3980 - val_acc: 0.6966\n",
      "Epoch 43/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7696 - acc: 0.9209 - val_loss: 1.3987 - val_acc: 0.7079\n",
      "Epoch 44/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7924 - acc: 0.9011 - val_loss: 1.4131 - val_acc: 0.6966\n",
      "Epoch 45/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7906 - acc: 0.9096 - val_loss: 1.4178 - val_acc: 0.7079\n",
      "Epoch 46/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.7849 - acc: 0.9209 - val_loss: 1.4194 - val_acc: 0.6966\n",
      "Epoch 47/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.8032 - acc: 0.9209 - val_loss: 1.4179 - val_acc: 0.6854\n",
      "Epoch 48/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.7917 - acc: 0.9040 - val_loss: 1.4199 - val_acc: 0.6966\n",
      "Epoch 49/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.8022 - acc: 0.9124 - val_loss: 1.4195 - val_acc: 0.6966\n",
      "Epoch 50/80\n",
      "354/354 [==============================] - 0s 108us/step - loss: 0.7936 - acc: 0.9124 - val_loss: 1.4136 - val_acc: 0.7079\n",
      "Epoch 51/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7661 - acc: 0.9181 - val_loss: 1.4208 - val_acc: 0.6966\n",
      "Epoch 52/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7497 - acc: 0.9209 - val_loss: 1.4387 - val_acc: 0.6966\n",
      "Epoch 53/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7765 - acc: 0.9068 - val_loss: 1.4281 - val_acc: 0.6966\n",
      "Epoch 54/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7575 - acc: 0.9266 - val_loss: 1.4275 - val_acc: 0.6966\n",
      "Epoch 55/80\n",
      "354/354 [==============================] - 0s 106us/step - loss: 0.7629 - acc: 0.9040 - val_loss: 1.4337 - val_acc: 0.6966\n",
      "Epoch 56/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7801 - acc: 0.8842 - val_loss: 1.4366 - val_acc: 0.6966\n",
      "Epoch 57/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7654 - acc: 0.9153 - val_loss: 1.4497 - val_acc: 0.6966\n",
      "Epoch 58/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.7446 - acc: 0.9153 - val_loss: 1.4557 - val_acc: 0.6966\n",
      "Epoch 59/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.7724 - acc: 0.9266 - val_loss: 1.4581 - val_acc: 0.6966\n",
      "Epoch 60/80\n",
      "354/354 [==============================] - 0s 101us/step - loss: 0.7580 - acc: 0.9124 - val_loss: 1.4603 - val_acc: 0.6966\n",
      "Epoch 61/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7672 - acc: 0.9153 - val_loss: 1.4644 - val_acc: 0.6966\n",
      "Epoch 62/80\n",
      "354/354 [==============================] - 0s 114us/step - loss: 0.7440 - acc: 0.9068 - val_loss: 1.4692 - val_acc: 0.6966\n",
      "Epoch 63/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7480 - acc: 0.9209 - val_loss: 1.4740 - val_acc: 0.6966\n",
      "Epoch 64/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.7466 - acc: 0.8955 - val_loss: 1.4753 - val_acc: 0.6966\n",
      "Epoch 65/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7288 - acc: 0.9237 - val_loss: 1.4786 - val_acc: 0.6966\n",
      "Epoch 66/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7370 - acc: 0.9266 - val_loss: 1.4797 - val_acc: 0.6966\n",
      "Epoch 67/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7827 - acc: 0.9096 - val_loss: 1.4844 - val_acc: 0.6966\n",
      "Epoch 68/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.7346 - acc: 0.9181 - val_loss: 1.4844 - val_acc: 0.6966\n",
      "Epoch 69/80\n",
      "354/354 [==============================] - 0s 111us/step - loss: 0.7489 - acc: 0.9068 - val_loss: 1.4921 - val_acc: 0.6966\n",
      "Epoch 70/80\n",
      "354/354 [==============================] - 0s 102us/step - loss: 0.7516 - acc: 0.9294 - val_loss: 1.4980 - val_acc: 0.7079\n",
      "Epoch 71/80\n",
      "354/354 [==============================] - 0s 110us/step - loss: 0.7389 - acc: 0.9294 - val_loss: 1.5090 - val_acc: 0.7079\n",
      "Epoch 72/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7132 - acc: 0.9181 - val_loss: 1.5145 - val_acc: 0.6966\n",
      "Epoch 73/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7333 - acc: 0.9124 - val_loss: 1.5172 - val_acc: 0.6854\n",
      "Epoch 74/80\n",
      "354/354 [==============================] - 0s 107us/step - loss: 0.7061 - acc: 0.9322 - val_loss: 1.5167 - val_acc: 0.6854\n",
      "Epoch 75/80\n",
      "354/354 [==============================] - 0s 105us/step - loss: 0.7124 - acc: 0.9350 - val_loss: 1.5177 - val_acc: 0.6854\n",
      "Epoch 76/80\n",
      "354/354 [==============================] - 0s 104us/step - loss: 0.7415 - acc: 0.9153 - val_loss: 1.5184 - val_acc: 0.6854\n",
      "Epoch 77/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7187 - acc: 0.9266 - val_loss: 1.5188 - val_acc: 0.6854\n",
      "Epoch 78/80\n",
      "354/354 [==============================] - 0s 109us/step - loss: 0.6917 - acc: 0.9379 - val_loss: 1.5200 - val_acc: 0.6854\n",
      "Epoch 79/80\n",
      "354/354 [==============================] - 0s 99us/step - loss: 0.7164 - acc: 0.9266 - val_loss: 1.5256 - val_acc: 0.6854\n",
      "Epoch 80/80\n",
      "354/354 [==============================] - 0s 103us/step - loss: 0.7199 - acc: 0.9266 - val_loss: 1.5290 - val_acc: 0.6854\n"
     ]
    }
   ],
   "source": [
    "# Train The Model\n",
    "\n",
    "print('Model Train 1')\n",
    "model_train1 = model.fit(train_X1, train_Y1, epochs=epochs, batch_size=32, \n",
    "                        validation_data=(valid_X1, valid_Y1), callbacks=callback_list1)\n",
    "model.load_weights(\"model.hdf5\")\n",
    "print('Model Train 2')\n",
    "model_train2 = model.fit(train_X2, train_Y2, epochs=epochs, batch_size=32, \n",
    "                        validation_data=(valid_X2, valid_Y2), callbacks=callback_list2)\n",
    "model.load_weights(\"model.hdf5\")\n",
    "print('Model Train 3')\n",
    "model_train3 = model.fit(train_X3, train_Y3, epochs=epochs, batch_size=32, \n",
    "                        validation_data=(valid_X3, valid_Y3), callbacks=callback_list3)\n",
    "model.load_weights(\"model.hdf5\")\n",
    "print('Model Train 4')\n",
    "model_train4 = model.fit(train_X4, train_Y4, epochs=epochs, batch_size=32, \n",
    "                        validation_data=(valid_X4, valid_Y4), callbacks=callback_list4)\n",
    "model.load_weights(\"model.hdf5\")\n",
    "print('Model Train 5')\n",
    "model_train5 = model.fit(train_X5, train_Y5, epochs=epochs, batch_size=32, \n",
    "                        validation_data=(valid_X5, valid_Y5), callbacks=callback_list5)\n",
    "model.load_weights(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot The Training Accuracy\n",
    "\n",
    "accuracy = model_train1.history['acc']\n",
    "val_accuracy = model_train1.history['val_acc']\n",
    "loss = model_train1.history['loss']\n",
    "val_loss = model_train1.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELM_y Result\n",
      "Accuracy : 0.7840909090909091\n",
      "AUC : 0.7913943355119826\n",
      "Sensitivity : 0.7592592592592593\n",
      "Specificity : 0.8235294117647058\n",
      "F1 : 0.8118811881188118\n",
      "MCC : 0.5688615521268232\n",
      "\n",
      "PELM_y Result\n",
      "Accuracy : 0.7640449438202247\n",
      "AUC : 0.7616869918699186\n",
      "Sensitivity : 0.7317073170731707\n",
      "Specificity : 0.7916666666666666\n",
      "F1 : 0.7407407407407408\n",
      "MCC : 0.5244410062210421\n",
      "\n",
      "PELM_y Result\n",
      "Accuracy : 0.8295454545454546\n",
      "AUC : 0.8245283018867925\n",
      "Sensitivity : 0.8490566037735849\n",
      "Specificity : 0.8\n",
      "F1 : 0.8571428571428571\n",
      "MCC : 0.6461027771035147\n",
      "\n",
      "PELM_y Result\n",
      "Accuracy : 0.7415730337078652\n",
      "AUC : 0.7398648648648648\n",
      "Sensitivity : 0.75\n",
      "Specificity : 0.7297297297297297\n",
      "F1 : 0.7722772277227722\n",
      "MCC : 0.47530363042176793\n",
      "\n",
      "PELM_y Result\n",
      "Accuracy : 0.7191011235955056\n",
      "AUC : 0.7199191102123357\n",
      "Sensitivity : 0.7441860465116279\n",
      "Specificity : 0.6956521739130435\n",
      "F1 : 0.7191011235955057\n",
      "MCC : 0.4398382204246714\n",
      "\n",
      "PELM_y Result\n",
      "Accuracy : 0.7676710929519918\n",
      "AUC : 0.7674787208691789\n",
      "Sensitivity : 0.7668418453235286\n",
      "Specificity : 3.8405779820741457\n",
      "F1 : 0.7802286274641375\n",
      "MCC : 0.5309094372595639\n"
     ]
    }
   ],
   "source": [
    "# Model Score Summary using Cross Validation\n",
    "\n",
    "model.load_weights(\"weight_best1.hdf5\")\n",
    "y_pred1 = np.argmax(model.predict(valid_X1), axis=1)\n",
    "y_true1 = np.argmax(valid_Y1, axis = 1)\n",
    "\n",
    "model.load_weights(\"weight_best2.hdf5\")\n",
    "y_pred2 = np.argmax(model.predict(valid_X2), axis=1)\n",
    "y_true2 = np.argmax(valid_Y2, axis = 1)\n",
    "\n",
    "model.load_weights(\"weight_best3.hdf5\")\n",
    "y_pred3 = np.argmax(model.predict(valid_X3), axis=1)\n",
    "y_true3 = np.argmax(valid_Y3, axis = 1)\n",
    "\n",
    "model.load_weights(\"weight_best4.hdf5\")\n",
    "y_pred4 = np.argmax(model.predict(valid_X4), axis=1)\n",
    "y_true4 = np.argmax(valid_Y4, axis = 1)\n",
    "\n",
    "model.load_weights(\"weight_best5.hdf5\")\n",
    "y_pred5 = np.argmax(model.predict(valid_X5), axis=1)\n",
    "y_true5 = np.argmax(valid_Y5, axis = 1)\n",
    "\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    f1 = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    auc = roc_auc_score(y_true, y_pred, average='macro', sample_weight=None, max_fpr=None)\n",
    "    sensi = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    accu = (tn + tp)/(tn + tp + fn + fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    print('{} Result'.format(string_name))\n",
    "    print('Accuracy :', accu)\n",
    "    print('AUC :', auc)\n",
    "    print('Sensitivity :', sensi)\n",
    "    print('Specificity :', specificity)\n",
    "    print('F1 :', f1)\n",
    "    print('MCC :', mcc)\n",
    "    print()\n",
    "    return [auc, accu, mcc, f1, sensi, specificity]\n",
    "\n",
    "auc1, accu1, mcc1, f11, sen1, spec1 = conf_matrix(y_true1, y_pred1)\n",
    "auc2, accu2, mcc2, f12, sen2, spec2 = conf_matrix(y_true2, y_pred2)\n",
    "auc3, accu3, mcc3, f13, sen3, spec3 = conf_matrix(y_true3, y_pred3)\n",
    "auc4, accu4, mcc4, f14, sen4, spec4 = conf_matrix(y_true4, y_pred4)\n",
    "auc5, accu5, mcc5, f15, sen5, spec5 = conf_matrix(y_true5, y_pred5)\n",
    "\n",
    "accu = (accu1 + accu2 + accu3 + accu4 + accu5)/5\n",
    "auc = (auc1 + auc2 + auc3 + auc4 + auc5)/5\n",
    "f1 = (f11 + f12 + f13 + f14 + f15)/5\n",
    "mcc = (mcc1 + mcc2 + mcc3 + mcc4 + mcc5)/5\n",
    "sen = (sen1 + sen2 + sen3 + sen4 + sen5)/5\n",
    "spec = (spec1 + spec2 + spec3 + spec4 + spec5)\n",
    "\n",
    "print('{} Result'.format(string_name))\n",
    "print('Accuracy :', accu)\n",
    "print('AUC :', auc)\n",
    "print('Sensitivity :', sen)\n",
    "print('Specificity :', spec)\n",
    "print('F1 :', f1)\n",
    "print('MCC :', mcc)\n",
    "    \n",
    "with open('results/summary_{}.csv'.format(string_name), mode='w') as summary_file:\n",
    "    employee_writer = csv.writer(summary_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    employee_writer.writerow(['Accuracy :', accu])\n",
    "    employee_writer.writerow(['AUC :', auc])\n",
    "    employee_writer.writerow(['Sensitivity :', sen])\n",
    "    employee_writer.writerow(['Specificity :', spec])\n",
    "    employee_writer.writerow(['F1 :', f1])\n",
    "    employee_writer.writerow(['MCC :', mcc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Final\n",
      "Train on 443 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 1.0871 - acc: 0.8014 - val_loss: 1.1134 - val_acc: 0.7800\n",
      "Epoch 2/100\n",
      "443/443 [==============================] - 0s 97us/step - loss: 1.0840 - acc: 0.7946 - val_loss: 1.1024 - val_acc: 0.8000\n",
      "Epoch 3/100\n",
      "443/443 [==============================] - 0s 100us/step - loss: 1.0409 - acc: 0.7991 - val_loss: 1.0888 - val_acc: 0.7800\n",
      "Epoch 4/100\n",
      "443/443 [==============================] - 0s 98us/step - loss: 1.0370 - acc: 0.8126 - val_loss: 1.0946 - val_acc: 0.7800\n",
      "Epoch 5/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 1.0202 - acc: 0.8284 - val_loss: 1.0794 - val_acc: 0.7600\n",
      "Epoch 6/100\n",
      "443/443 [==============================] - 0s 94us/step - loss: 0.9639 - acc: 0.8307 - val_loss: 1.0951 - val_acc: 0.7600\n",
      "Epoch 7/100\n",
      "443/443 [==============================] - 0s 95us/step - loss: 0.9504 - acc: 0.8352 - val_loss: 1.0988 - val_acc: 0.7600\n",
      "Epoch 8/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 0.9163 - acc: 0.8578 - val_loss: 1.0719 - val_acc: 0.8200\n",
      "Epoch 9/100\n",
      "443/443 [==============================] - 0s 94us/step - loss: 0.8965 - acc: 0.8600 - val_loss: 1.0726 - val_acc: 0.8000\n",
      "Epoch 10/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.8626 - acc: 0.8713 - val_loss: 1.1079 - val_acc: 0.7400\n",
      "Epoch 11/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.8549 - acc: 0.8871 - val_loss: 1.1072 - val_acc: 0.7600\n",
      "Epoch 12/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.8540 - acc: 0.8826 - val_loss: 1.1150 - val_acc: 0.7800\n",
      "Epoch 13/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.8200 - acc: 0.8916 - val_loss: 1.1239 - val_acc: 0.7600\n",
      "Epoch 14/100\n",
      "443/443 [==============================] - 0s 98us/step - loss: 0.8373 - acc: 0.8804 - val_loss: 1.1221 - val_acc: 0.7400\n",
      "Epoch 15/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.8378 - acc: 0.8623 - val_loss: 1.1223 - val_acc: 0.7600\n",
      "Epoch 16/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.8015 - acc: 0.8871 - val_loss: 1.1230 - val_acc: 0.7600\n",
      "Epoch 17/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.8223 - acc: 0.8826 - val_loss: 1.1220 - val_acc: 0.7400\n",
      "Epoch 18/100\n",
      "443/443 [==============================] - 0s 94us/step - loss: 0.8005 - acc: 0.9029 - val_loss: 1.1331 - val_acc: 0.7400\n",
      "Epoch 19/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.8059 - acc: 0.8894 - val_loss: 1.1257 - val_acc: 0.7400\n",
      "Epoch 20/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.7996 - acc: 0.8849 - val_loss: 1.1221 - val_acc: 0.7600\n",
      "Epoch 21/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.7593 - acc: 0.8984 - val_loss: 1.1201 - val_acc: 0.7200\n",
      "Epoch 22/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.7735 - acc: 0.8939 - val_loss: 1.1389 - val_acc: 0.7200\n",
      "Epoch 23/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.7725 - acc: 0.9007 - val_loss: 1.1440 - val_acc: 0.7400\n",
      "Epoch 24/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 0.7462 - acc: 0.8984 - val_loss: 1.1661 - val_acc: 0.7400\n",
      "Epoch 25/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.7452 - acc: 0.8962 - val_loss: 1.1807 - val_acc: 0.7400\n",
      "Epoch 26/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.7709 - acc: 0.8849 - val_loss: 1.1984 - val_acc: 0.7400\n",
      "Epoch 27/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.7560 - acc: 0.8916 - val_loss: 1.1886 - val_acc: 0.7400\n",
      "Epoch 28/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.7273 - acc: 0.9029 - val_loss: 1.1879 - val_acc: 0.7400\n",
      "Epoch 29/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.7482 - acc: 0.8984 - val_loss: 1.1878 - val_acc: 0.7400\n",
      "Epoch 30/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.7210 - acc: 0.8894 - val_loss: 1.2061 - val_acc: 0.7600\n",
      "Epoch 31/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.7071 - acc: 0.9097 - val_loss: 1.2012 - val_acc: 0.7200\n",
      "Epoch 32/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.7369 - acc: 0.9052 - val_loss: 1.2041 - val_acc: 0.7200\n",
      "Epoch 33/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.7126 - acc: 0.9029 - val_loss: 1.2164 - val_acc: 0.7200\n",
      "Epoch 34/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.7057 - acc: 0.8962 - val_loss: 1.2055 - val_acc: 0.7400\n",
      "Epoch 35/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 0.7003 - acc: 0.9007 - val_loss: 1.1867 - val_acc: 0.7200\n",
      "Epoch 36/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.7118 - acc: 0.9029 - val_loss: 1.1868 - val_acc: 0.7200\n",
      "Epoch 37/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.6771 - acc: 0.9007 - val_loss: 1.2024 - val_acc: 0.7200\n",
      "Epoch 38/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6895 - acc: 0.8894 - val_loss: 1.2064 - val_acc: 0.7400\n",
      "Epoch 39/100\n",
      "443/443 [==============================] - 0s 95us/step - loss: 0.6874 - acc: 0.9052 - val_loss: 1.2190 - val_acc: 0.7400\n",
      "Epoch 40/100\n",
      "443/443 [==============================] - 0s 94us/step - loss: 0.6473 - acc: 0.9255 - val_loss: 1.2469 - val_acc: 0.7600\n",
      "Epoch 41/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.6692 - acc: 0.8894 - val_loss: 1.2464 - val_acc: 0.7400\n",
      "Epoch 42/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6485 - acc: 0.9255 - val_loss: 1.2486 - val_acc: 0.7400\n",
      "Epoch 43/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.6533 - acc: 0.9097 - val_loss: 1.2582 - val_acc: 0.7400\n",
      "Epoch 44/100\n",
      "443/443 [==============================] - 0s 95us/step - loss: 0.6607 - acc: 0.9142 - val_loss: 1.2597 - val_acc: 0.7400\n",
      "Epoch 45/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6304 - acc: 0.9165 - val_loss: 1.2638 - val_acc: 0.7400\n",
      "Epoch 46/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6455 - acc: 0.9255 - val_loss: 1.2700 - val_acc: 0.7400\n",
      "Epoch 47/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.6325 - acc: 0.9187 - val_loss: 1.2644 - val_acc: 0.7400\n",
      "Epoch 48/100\n",
      "443/443 [==============================] - 0s 101us/step - loss: 0.6250 - acc: 0.9255 - val_loss: 1.2687 - val_acc: 0.7400\n",
      "Epoch 49/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.6781 - acc: 0.9052 - val_loss: 1.2738 - val_acc: 0.7400\n",
      "Epoch 50/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6197 - acc: 0.9165 - val_loss: 1.2798 - val_acc: 0.7400\n",
      "Epoch 51/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6024 - acc: 0.9278 - val_loss: 1.2914 - val_acc: 0.7400\n",
      "Epoch 52/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.6394 - acc: 0.9074 - val_loss: 1.2950 - val_acc: 0.7400\n",
      "Epoch 53/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.6144 - acc: 0.9255 - val_loss: 1.2983 - val_acc: 0.7400\n",
      "Epoch 54/100\n",
      "443/443 [==============================] - 0s 88us/step - loss: 0.6330 - acc: 0.9142 - val_loss: 1.3050 - val_acc: 0.7400\n",
      "Epoch 55/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.6046 - acc: 0.9278 - val_loss: 1.3087 - val_acc: 0.7400\n",
      "Epoch 56/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6105 - acc: 0.9233 - val_loss: 1.3070 - val_acc: 0.7400\n",
      "Epoch 57/100\n",
      "443/443 [==============================] - 0s 97us/step - loss: 0.6019 - acc: 0.9255 - val_loss: 1.3052 - val_acc: 0.7400\n",
      "Epoch 58/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6199 - acc: 0.9097 - val_loss: 1.3082 - val_acc: 0.7400\n",
      "Epoch 59/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6161 - acc: 0.9300 - val_loss: 1.3102 - val_acc: 0.7400\n",
      "Epoch 60/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.6166 - acc: 0.9052 - val_loss: 1.3152 - val_acc: 0.7400\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 0s 96us/step - loss: 0.6078 - acc: 0.9187 - val_loss: 1.3241 - val_acc: 0.7400\n",
      "Epoch 62/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6080 - acc: 0.9165 - val_loss: 1.3208 - val_acc: 0.7400\n",
      "Epoch 63/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.6033 - acc: 0.9323 - val_loss: 1.3115 - val_acc: 0.7400\n",
      "Epoch 64/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.5837 - acc: 0.9300 - val_loss: 1.3056 - val_acc: 0.7400\n",
      "Epoch 65/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.5985 - acc: 0.9233 - val_loss: 1.3058 - val_acc: 0.7400\n",
      "Epoch 66/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5972 - acc: 0.9233 - val_loss: 1.3112 - val_acc: 0.7400\n",
      "Epoch 67/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.6001 - acc: 0.9165 - val_loss: 1.3105 - val_acc: 0.7400\n",
      "Epoch 68/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.5716 - acc: 0.9255 - val_loss: 1.3128 - val_acc: 0.7400\n",
      "Epoch 69/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.5873 - acc: 0.9210 - val_loss: 1.3221 - val_acc: 0.7400\n",
      "Epoch 70/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 0.5909 - acc: 0.9278 - val_loss: 1.3268 - val_acc: 0.7400\n",
      "Epoch 71/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5728 - acc: 0.9323 - val_loss: 1.3282 - val_acc: 0.7400\n",
      "Epoch 72/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5911 - acc: 0.9187 - val_loss: 1.3275 - val_acc: 0.7400\n",
      "Epoch 73/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.5782 - acc: 0.9255 - val_loss: 1.3229 - val_acc: 0.7400\n",
      "Epoch 74/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.5851 - acc: 0.9345 - val_loss: 1.3217 - val_acc: 0.7400\n",
      "Epoch 75/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.6068 - acc: 0.9255 - val_loss: 1.3201 - val_acc: 0.7400\n",
      "Epoch 76/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5763 - acc: 0.9345 - val_loss: 1.3175 - val_acc: 0.7400\n",
      "Epoch 77/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5799 - acc: 0.9278 - val_loss: 1.3243 - val_acc: 0.7400\n",
      "Epoch 78/100\n",
      "443/443 [==============================] - 0s 95us/step - loss: 0.5665 - acc: 0.9255 - val_loss: 1.3287 - val_acc: 0.7400\n",
      "Epoch 79/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5622 - acc: 0.9233 - val_loss: 1.3335 - val_acc: 0.7400\n",
      "Epoch 80/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.5636 - acc: 0.9278 - val_loss: 1.3401 - val_acc: 0.7400\n",
      "Epoch 81/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.5913 - acc: 0.9097 - val_loss: 1.3450 - val_acc: 0.7400\n",
      "Epoch 82/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.5520 - acc: 0.9436 - val_loss: 1.3478 - val_acc: 0.7400\n",
      "Epoch 83/100\n",
      "443/443 [==============================] - 0s 95us/step - loss: 0.5751 - acc: 0.9210 - val_loss: 1.3490 - val_acc: 0.7400\n",
      "Epoch 84/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.5375 - acc: 0.9436 - val_loss: 1.3494 - val_acc: 0.7400\n",
      "Epoch 85/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.5818 - acc: 0.9345 - val_loss: 1.3501 - val_acc: 0.7400\n",
      "Epoch 86/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5671 - acc: 0.9345 - val_loss: 1.3480 - val_acc: 0.7400\n",
      "Epoch 87/100\n",
      "443/443 [==============================] - 0s 97us/step - loss: 0.5624 - acc: 0.9300 - val_loss: 1.3525 - val_acc: 0.7400\n",
      "Epoch 88/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 0.5674 - acc: 0.9345 - val_loss: 1.3562 - val_acc: 0.7400\n",
      "Epoch 89/100\n",
      "443/443 [==============================] - 0s 88us/step - loss: 0.5535 - acc: 0.9345 - val_loss: 1.3534 - val_acc: 0.7400\n",
      "Epoch 90/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.5614 - acc: 0.9300 - val_loss: 1.3498 - val_acc: 0.7400\n",
      "Epoch 91/100\n",
      "443/443 [==============================] - 0s 96us/step - loss: 0.5305 - acc: 0.9503 - val_loss: 1.3552 - val_acc: 0.7400\n",
      "Epoch 92/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.5594 - acc: 0.9300 - val_loss: 1.3602 - val_acc: 0.7400\n",
      "Epoch 93/100\n",
      "443/443 [==============================] - 0s 90us/step - loss: 0.5514 - acc: 0.9165 - val_loss: 1.3629 - val_acc: 0.7400\n",
      "Epoch 94/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.5477 - acc: 0.9165 - val_loss: 1.3618 - val_acc: 0.7400\n",
      "Epoch 95/100\n",
      "443/443 [==============================] - 0s 92us/step - loss: 0.5486 - acc: 0.9368 - val_loss: 1.3590 - val_acc: 0.7400\n",
      "Epoch 96/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.5436 - acc: 0.9391 - val_loss: 1.3543 - val_acc: 0.7400\n",
      "Epoch 97/100\n",
      "443/443 [==============================] - 0s 91us/step - loss: 0.5282 - acc: 0.9458 - val_loss: 1.3544 - val_acc: 0.7400\n",
      "Epoch 98/100\n",
      "443/443 [==============================] - 0s 88us/step - loss: 0.5474 - acc: 0.9323 - val_loss: 1.3544 - val_acc: 0.7400\n",
      "Epoch 99/100\n",
      "443/443 [==============================] - 0s 89us/step - loss: 0.5465 - acc: 0.9391 - val_loss: 1.3564 - val_acc: 0.7400\n",
      "Epoch 100/100\n",
      "443/443 [==============================] - 0s 93us/step - loss: 0.5486 - acc: 0.9300 - val_loss: 1.3626 - val_acc: 0.7400\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "print('Model Final')\n",
    "model_train = model.fit(main_X, main_Y, epochs=100, batch_size=32, \n",
    "                        validation_data=(test_X, test_Y), callbacks=callback_list)\n",
    "model.load_weights(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot The Training Accuracy\n",
    "\n",
    "accuracy = model_train.history['acc']\n",
    "val_accuracy = model_train.history['val_acc']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('results/Acc_result_{}.png'.format(string_name))\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('results/Loss_result_{}.png'.format(string_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELM_y Result\n",
      "Accuracy : 0.82\n",
      "AUC : 0.8189102564102564\n",
      "Sensitivity : 0.7916666666666666\n",
      "Specificity : 0.8461538461538461\n",
      "F1 : 0.8085106382978724\n",
      "MCC : 0.63935928589601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weight_best.hdf5\")\n",
    "y_pred_t = np.argmax(model.predict(test_X), axis=1)\n",
    "y_true_t = np.argmax(test_Y, axis = 1)\n",
    "\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    f1 = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "    auc = roc_auc_score(y_true, y_pred, average='macro', sample_weight=None, max_fpr=None)\n",
    "    sensi = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    accu = (tn + tp)/(tn + tp + fn + fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    print('{} Result'.format(string_name))\n",
    "    print('Accuracy :', accu)\n",
    "    print('AUC :', auc)\n",
    "    print('Sensitivity :', sensi)\n",
    "    print('Specificity :', specificity)\n",
    "    print('F1 :', f1)\n",
    "    print('MCC :', mcc)\n",
    "    print()\n",
    "    return [auc, accu, mcc, f1, sensi, specificity]\n",
    "\n",
    "auc_t, accu_t, mcc_t, f1_t, sen_t, spec_t = conf_matrix(y_true_t, y_pred_t)\n",
    "    \n",
    "with open('results/final_summary_{}.csv'.format(string_name), mode='w') as summary_file:\n",
    "    employee_writer = csv.writer(summary_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    employee_writer.writerow(['Accuracy :', accu_t])\n",
    "    employee_writer.writerow(['AUC :', auc_t])\n",
    "    employee_writer.writerow(['Sensitivity :', sen_t])\n",
    "    employee_writer.writerow(['Specificity :', spec_t])\n",
    "    employee_writer.writerow(['F1 :', f1_t])\n",
    "    employee_writer.writerow(['MCC :', mcc_t])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
