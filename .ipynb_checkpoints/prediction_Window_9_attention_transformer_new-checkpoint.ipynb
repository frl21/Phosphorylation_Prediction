{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Reshape\n",
    "from keras.layers import Conv2D, LSTM, Embedding, Bidirectional, Input, merge, multiply, concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELM Dataset, S positive shape:  (1554, 9)\n",
      "PELM Dataset, T positive shape:  (707, 9)\n",
      "PELM Dataset, Y positive shape:  (267, 9)\n",
      "PPA Dataset, S positive shape:  (307, 9)\n",
      "PPA Dataset, T positive shape:  (68, 9)\n",
      "PPA Dataset, Y positive shape:  (51, 9)\n",
      "\n",
      "PELM Dataset, S negative shape:  (1543, 9)\n",
      "PELM Dataset, T negative shape:  (453, 9)\n",
      "PELM Dataset, Y negative shape:  (226, 9)\n",
      "PPA Dataset, S negative shape:  (307, 9)\n",
      "PPA Dataset, T negative shape:  (68, 9)\n",
      "PPA Dataset, Y negative shape:  (51, 9)\n"
     ]
    }
   ],
   "source": [
    "# Read sample from Dataset\n",
    "\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_S_pos.fasta', 'r') as f:\n",
    "    PELM_s_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_T_pos.fasta', 'r') as f:\n",
    "    PELM_t_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_Y_pos.fasta', 'r') as f:\n",
    "    PELM_y_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/S_IDS_pos.fasta', 'r') as f:\n",
    "    PPA_s_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/T_IDS_pos.fasta', 'r') as f:\n",
    "    PPA_t_positif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/Y_IDS_pos.fasta', 'r') as f:\n",
    "    PPA_y_positif_txt = f.readlines()\n",
    "\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_S_neg.fasta', 'r') as f:\n",
    "    PELM_s_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_T_neg.fasta', 'r') as f:\n",
    "    PELM_t_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PELM/Group_Phos_Y_neg.fasta', 'r') as f:\n",
    "    PELM_y_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/S_IDS_neg.fasta', 'r') as f:\n",
    "    PPA_s_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/T_IDS_neg.fasta', 'r') as f:\n",
    "    PPA_t_negatif_txt = f.readlines()\n",
    "with open('fixed_sequences_length_9_PPA/Y_IDS_neg.fasta', 'r') as f:\n",
    "    PPA_y_negatif_txt = f.readlines()\n",
    "\n",
    "# Pick the window 9\n",
    "\n",
    "PELM_s_positif = np.array([])\n",
    "for i in range(1,len(PELM_s_positif_txt),2):\n",
    "    temp = PELM_s_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_s_positif = np.append(PELM_s_positif, temp2)\n",
    "print('PELM Dataset, S positive shape: ', PELM_s_positif.reshape(int(len(PELM_s_positif)/9),9).shape)\n",
    "\n",
    "PELM_t_positif = np.array([])\n",
    "for i in range(1,len(PELM_t_positif_txt),2):\n",
    "    temp = PELM_t_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_t_positif = np.append(PELM_t_positif, temp2)\n",
    "print('PELM Dataset, T positive shape: ', PELM_t_positif.reshape(int(len(PELM_t_positif)/9),9).shape)\n",
    "    \n",
    "PELM_y_positif = np.array([])\n",
    "for i in range(1,len(PELM_y_positif_txt),2):\n",
    "    temp = PELM_y_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_y_positif = np.append(PELM_y_positif, temp2)\n",
    "print('PELM Dataset, Y positive shape: ', PELM_y_positif.reshape(int(len(PELM_y_positif)/9),9).shape)\n",
    "\n",
    "PPA_s_positif = np.array([])\n",
    "for i in range(1,len(PPA_s_positif_txt),2):\n",
    "    temp = PPA_s_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_s_positif = np.append(PPA_s_positif, temp2)\n",
    "print('PPA Dataset, S positive shape: ', PPA_s_positif.reshape(int(len(PPA_s_positif)/9),9).shape)\n",
    "\n",
    "PPA_t_positif = np.array([])\n",
    "for i in range(1,len(PPA_t_positif_txt),2):\n",
    "    temp = PPA_t_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_t_positif = np.append(PPA_t_positif, temp2)\n",
    "print('PPA Dataset, T positive shape: ', PPA_t_positif.reshape(int(len(PPA_t_positif)/9),9).shape)\n",
    "    \n",
    "PPA_y_positif = np.array([])\n",
    "for i in range(1,len(PPA_y_positif_txt),2):\n",
    "    temp = PPA_y_positif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_y_positif = np.append(PPA_y_positif, temp2)\n",
    "print('PPA Dataset, Y positive shape: ', PPA_y_positif.reshape(int(len(PPA_y_positif)/9),9).shape)\n",
    "\n",
    "print()\n",
    "\n",
    "PELM_s_negatif = np.array([])\n",
    "for i in range(1,len(PELM_s_negatif_txt),2):\n",
    "    temp = PELM_s_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_s_negatif = np.append(PELM_s_negatif, temp2)\n",
    "print('PELM Dataset, S negative shape: ', PELM_s_negatif.reshape(int(len(PELM_s_negatif)/9),9).shape)\n",
    "\n",
    "PELM_t_negatif = np.array([])\n",
    "for i in range(1,len(PELM_t_negatif_txt),2):\n",
    "    temp = PELM_t_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_t_negatif = np.append(PELM_t_negatif, temp2)\n",
    "print('PELM Dataset, T negative shape: ', PELM_t_negatif.reshape(int(len(PELM_t_negatif)/9),9).shape)\n",
    "    \n",
    "PELM_y_negatif = np.array([])\n",
    "for i in range(1,len(PELM_y_negatif_txt),2):\n",
    "    temp = PELM_y_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PELM_y_negatif = np.append(PELM_y_negatif, temp2)\n",
    "print('PELM Dataset, Y negative shape: ', PELM_y_negatif.reshape(int(len(PELM_y_negatif)/9),9).shape)\n",
    "\n",
    "PPA_s_negatif = np.array([])\n",
    "for i in range(1,len(PPA_s_negatif_txt),2):\n",
    "    temp = PPA_s_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_s_negatif = np.append(PPA_s_negatif, temp2)\n",
    "print('PPA Dataset, S negative shape: ', PPA_s_negatif.reshape(int(len(PPA_s_negatif)/9),9).shape)\n",
    "\n",
    "PPA_t_negatif = np.array([])\n",
    "for i in range(1,len(PPA_t_negatif_txt),2):\n",
    "    temp = PPA_t_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_t_negatif = np.append(PPA_t_negatif, temp2)\n",
    "print('PPA Dataset, T negative shape: ', PPA_t_negatif.reshape(int(len(PPA_t_negatif)/9),9).shape)\n",
    "    \n",
    "PPA_y_negatif = np.array([])\n",
    "for i in range(1,len(PPA_y_negatif_txt),2):\n",
    "    temp = PPA_y_negatif_txt[i]\n",
    "    temp1 = temp[0:9]\n",
    "    temp2 = list(temp1)\n",
    "    PPA_y_negatif = np.append(PPA_y_negatif, temp2)\n",
    "print('PPA Dataset, Y negative shape: ', PPA_y_negatif.reshape(int(len(PPA_y_negatif)/9),9).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Dataset shape:  (1554, 9)\n",
      "Positive Label shape:  (1554, 1)\n",
      "Negative Dataset shape:  (1543, 9)\n",
      "Negative Label shape:  (1543, 1)\n"
     ]
    }
   ],
   "source": [
    "# Choose Dataset to train, make sure correspond with negative dataset\n",
    "\n",
    "dataset_pos = PELM_s_positif\n",
    "dataset_neg = PELM_s_negatif\n",
    "string_name = 'PELM_s'\n",
    "\n",
    "# Expand dimension, Reshape and Create Label\n",
    "\n",
    "sequenceLP = int(len(dataset_pos)/9)\n",
    "dataset_pos = np.expand_dims(dataset_pos, axis=0)\n",
    "dataset_pos = dataset_pos.reshape(sequenceLP,9)\n",
    "label_pos = np.ones((sequenceLP,), dtype=int)\n",
    "label_pos = np.expand_dims(label_pos, axis=0)\n",
    "label_pos = label_pos.reshape(sequenceLP,1)\n",
    "\n",
    "sequenceLN = int(len(dataset_neg)/9)\n",
    "dataset_neg = np.expand_dims(dataset_neg, axis=0)\n",
    "dataset_neg = dataset_neg.reshape(sequenceLN,9)\n",
    "label_neg = np.zeros((sequenceLN,), dtype=int)\n",
    "label_neg = np.expand_dims(label_neg, axis=0)\n",
    "label_neg = label_neg.reshape(sequenceLN,1)\n",
    "\n",
    "# Validate\n",
    "\n",
    "print('Positive Dataset shape: ', dataset_pos.shape)\n",
    "print('Positive Label shape: ', label_pos.shape)\n",
    "print('Negative Dataset shape: ', dataset_neg.shape)\n",
    "print('Negative Label shape: ', label_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main X shape:  (3097, 9)\n",
      "main Y shape:  (3097, 2)\n",
      "train X shape:  (2477, 9)\n",
      "train Y shape:  (2477, 2)\n",
      "valid X shape:  (620, 9)\n",
      "valid Y shape:  (620, 2)\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation\n",
    "\n",
    "dataset_X = np.concatenate((dataset_pos, dataset_neg), axis=0, out=None)\n",
    "dataset_Y = np.concatenate((label_pos, label_neg), axis=0, out=None)\n",
    "\n",
    "# Tokenizing, Unique character got its own number\n",
    "\n",
    "asam = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(asam)\n",
    "dataset_X_token = []\n",
    "for i in range(len(dataset_X)):\n",
    "    temp = tokenizer.texts_to_sequences(dataset_X[i])\n",
    "    dataset_X_token = np.append(dataset_X_token, temp)\n",
    "\n",
    "dataset_X_token = dataset_X_token-1\n",
    "dataset_X_token = dataset_X_token.reshape(len(dataset_X),9)\n",
    "\n",
    "# Onehot\n",
    "\n",
    "dataset_X_token_onehot = to_categorical(dataset_X_token)\n",
    "dataset_X_token_onehot = np.expand_dims(dataset_X_token_onehot, axis=3)\n",
    "dataset_X_token_onehot = dataset_X_token_onehot.reshape(len(dataset_X),9,20,1)\n",
    "\n",
    "dataset_Y_onehot = to_categorical(dataset_Y)\n",
    "\n",
    "# Shuffle Dataset, devide\n",
    "\n",
    "main_X, main_Y = shuffle(dataset_X_token, dataset_Y_onehot, random_state=13)\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(dataset_X_token, dataset_Y_onehot, \n",
    "                                                              test_size=0.2, random_state=13)\n",
    "\n",
    "# Validation\n",
    "\n",
    "print('main X shape: ', main_X.shape)\n",
    "print('main Y shape: ', main_Y.shape)\n",
    "print('train X shape: ', train_X.shape)\n",
    "print('train Y shape: ', train_Y.shape)\n",
    "print('valid X shape: ', valid_X.shape)\n",
    "print('valid Y shape: ', valid_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 9, 8)         160         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 9)            648         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 9, 1)         0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9, 8)         0           reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 9, 8)         0           embedding_1[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 9, 20)        2320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 9, 20)        3280        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 9, 20)        3280        lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 20)           3280        lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            42          lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 13,010\n",
      "Trainable params: 13,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "epochs = 300\n",
    "\n",
    "inp = Input(shape=(9,))\n",
    "emb = Embedding(20, 8, input_length=9)(inp)\n",
    "\n",
    "\n",
    "att = LSTM(9, activation = 'softmax')(emb)\n",
    "att = Reshape(target_shape=(9,1))(att)\n",
    "att = concatenate([att,att,att,att,att,att,att,att], axis=2)\n",
    "emb = multiply([emb, att])\n",
    "\n",
    "i = LSTM(20, return_sequences=True)(emb)\n",
    "i = LSTM(20, return_sequences=True)(i)\n",
    "i = LSTM(20, return_sequences=True)(i)\n",
    "i = LSTM(20, return_sequences=False)(i)\n",
    "\n",
    "out = Dense(2, activation='softmax')(i)\n",
    "\n",
    "model_LSTM = Model(inputs=inp, outputs=out)\n",
    "model_LSTM.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_LSTM.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 9, 8)         160         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 9)            1296        embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 9, 1)         0           bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 9, 8)         0           reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "                                                                 reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 9, 8)         0           embedding_8[0][0]                \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 9, 40)        4640        multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 9, 40)        0           bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 9, 40)        9760        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 9, 40)        0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 40)           9760        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2)            82          bidirectional_21[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 25,698\n",
      "Trainable params: 25,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional LSTM\n",
    "epochs = 300\n",
    "\n",
    "inp = Input(shape=(9,))\n",
    "emb = Embedding(20, 8, input_length=9)(inp)\n",
    "\n",
    "\n",
    "att = Bidirectional(LSTM(9, activation = 'softmax'), merge_mode='ave', weights=None)(emb)\n",
    "att = Reshape(target_shape=(9,1))(att)\n",
    "att = concatenate([att,att,att,att,att,att,att,att], axis=2)\n",
    "emb = multiply([emb, att])\n",
    "\n",
    "i = Bidirectional(LSTM(20, return_sequences=True), merge_mode='concat', weights=None)(emb)\n",
    "i = Dropout(0.6, noise_shape=None, seed=None)(i)\n",
    "i = Bidirectional(LSTM(20, return_sequences=True), merge_mode='concat', weights=None)(i)\n",
    "i = Dropout(0.6, noise_shape=None, seed=None)(i)\n",
    "i = Bidirectional(LSTM(20, return_sequences=False), merge_mode='concat', weights=None)(i)\n",
    "\n",
    "out = Dense(2, activation='softmax')(i)\n",
    "\n",
    "model_BLSTM = Model(inputs=inp, outputs=out)\n",
    "model_BLSTM.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_BLSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 9, 8)         160         input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 9, 1)         9           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 9, 8)         0           dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 9, 8)         0           embedding_21[0][0]               \n",
      "                                                                 concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 9, 20)        180         multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 9, 20)        420         dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 9, 20)        420         dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 9, 20)        420         dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 9, 20)        420         dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 9, 20)        420         dense_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 9, 20)        420         dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 9, 20)        420         dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 9, 20)        420         dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 9, 20)        420         dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 9, 20)        420         dense_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 9, 20)        420         dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 9, 20)        420         dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 9, 20)        420         dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 9, 20)        420         dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 9, 20)        420         dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 9, 20)        420         dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 180)          0           dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 2)            362         flatten_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,431\n",
      "Trainable params: 7,431\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Dense\n",
    "epochs = 300\n",
    "\n",
    "inp = Input(shape=(9,))\n",
    "emb = Embedding(20, 8, input_length=9)(inp)\n",
    "\n",
    "\n",
    "att = Dense(1, activation = 'softmax')(emb)\n",
    "att = concatenate([att,att,att,att,att,att,att,att], axis=2)\n",
    "emb = multiply([emb, att])\n",
    "\n",
    "i = Dense(20)(emb)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Dense(20)(i)\n",
    "i = Flatten()(i)\n",
    "\n",
    "out = Dense(2, activation='softmax')(i)\n",
    "\n",
    "model_Dense = Model(inputs=inp, outputs=out)\n",
    "model_Dense.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_Dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2477 samples, validate on 620 samples\n",
      "Epoch 1/300\n",
      "2477/2477 [==============================] - 10s 4ms/step - loss: 0.6936 - acc: 0.4925 - val_loss: 0.6938 - val_acc: 0.4806\n",
      "Epoch 2/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.6051 - acc: 0.6790 - val_loss: 0.4458 - val_acc: 0.7984\n",
      "Epoch 3/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.3920 - acc: 0.8333 - val_loss: 0.3514 - val_acc: 0.8484\n",
      "Epoch 4/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.3197 - acc: 0.8668 - val_loss: 0.2864 - val_acc: 0.8742\n",
      "Epoch 5/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2825 - acc: 0.8866 - val_loss: 0.2726 - val_acc: 0.8839\n",
      "Epoch 6/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2717 - acc: 0.8890 - val_loss: 0.2575 - val_acc: 0.8935\n",
      "Epoch 7/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2648 - acc: 0.8946 - val_loss: 0.2489 - val_acc: 0.8903\n",
      "Epoch 8/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2592 - acc: 0.8938 - val_loss: 0.2384 - val_acc: 0.9000\n",
      "Epoch 9/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2570 - acc: 0.8954 - val_loss: 0.2392 - val_acc: 0.8984\n",
      "Epoch 10/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2562 - acc: 0.8962 - val_loss: 0.3006 - val_acc: 0.8710\n",
      "Epoch 11/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2547 - acc: 0.8926 - val_loss: 0.2507 - val_acc: 0.8952\n",
      "Epoch 12/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2522 - acc: 0.8954 - val_loss: 0.2499 - val_acc: 0.8968\n",
      "Epoch 13/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2507 - acc: 0.8979 - val_loss: 0.2395 - val_acc: 0.8952\n",
      "Epoch 14/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2465 - acc: 0.8999 - val_loss: 0.2446 - val_acc: 0.8984\n",
      "Epoch 15/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2464 - acc: 0.9003 - val_loss: 0.2475 - val_acc: 0.8952\n",
      "Epoch 16/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2455 - acc: 0.8991 - val_loss: 0.2475 - val_acc: 0.9016\n",
      "Epoch 17/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2478 - acc: 0.8995 - val_loss: 0.2403 - val_acc: 0.8984\n",
      "Epoch 18/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2423 - acc: 0.9003 - val_loss: 0.2549 - val_acc: 0.8935\n",
      "Epoch 19/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2448 - acc: 0.9023 - val_loss: 0.2449 - val_acc: 0.8984\n",
      "Epoch 20/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2437 - acc: 0.9011 - val_loss: 0.2450 - val_acc: 0.8919\n",
      "Epoch 21/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2477 - acc: 0.8975 - val_loss: 0.2428 - val_acc: 0.8984\n",
      "Epoch 22/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2469 - acc: 0.8991 - val_loss: 0.2423 - val_acc: 0.9000\n",
      "Epoch 23/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2451 - acc: 0.8991 - val_loss: 0.2489 - val_acc: 0.8919\n",
      "Epoch 24/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2417 - acc: 0.9043 - val_loss: 0.2440 - val_acc: 0.8952\n",
      "Epoch 25/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2427 - acc: 0.8991 - val_loss: 0.2490 - val_acc: 0.8952\n",
      "Epoch 26/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2428 - acc: 0.9047 - val_loss: 0.2440 - val_acc: 0.8984\n",
      "Epoch 27/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2412 - acc: 0.9043 - val_loss: 0.2447 - val_acc: 0.8968\n",
      "Epoch 28/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2406 - acc: 0.9039 - val_loss: 0.2417 - val_acc: 0.8952\n",
      "Epoch 29/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2420 - acc: 0.9019 - val_loss: 0.2440 - val_acc: 0.8952\n",
      "Epoch 30/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2399 - acc: 0.9031 - val_loss: 0.2418 - val_acc: 0.8968\n",
      "Epoch 31/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2390 - acc: 0.9015 - val_loss: 0.2485 - val_acc: 0.8968\n",
      "Epoch 32/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2455 - acc: 0.9003 - val_loss: 0.2413 - val_acc: 0.8984\n",
      "Epoch 33/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2407 - acc: 0.9031 - val_loss: 0.2420 - val_acc: 0.8968\n",
      "Epoch 34/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2397 - acc: 0.9023 - val_loss: 0.2402 - val_acc: 0.9000\n",
      "Epoch 35/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2375 - acc: 0.9047 - val_loss: 0.2433 - val_acc: 0.8952\n",
      "Epoch 36/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2411 - acc: 0.8962 - val_loss: 0.2412 - val_acc: 0.8968\n",
      "Epoch 37/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2373 - acc: 0.9027 - val_loss: 0.2435 - val_acc: 0.8952\n",
      "Epoch 38/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2384 - acc: 0.9043 - val_loss: 0.2430 - val_acc: 0.8968\n",
      "Epoch 39/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2343 - acc: 0.9059 - val_loss: 0.2421 - val_acc: 0.8935\n",
      "Epoch 40/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2390 - acc: 0.9055 - val_loss: 0.2410 - val_acc: 0.8952\n",
      "Epoch 41/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2415 - acc: 0.9047 - val_loss: 0.2449 - val_acc: 0.8984\n",
      "Epoch 42/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2356 - acc: 0.9043 - val_loss: 0.2421 - val_acc: 0.8984\n",
      "Epoch 43/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2368 - acc: 0.9023 - val_loss: 0.2367 - val_acc: 0.9000\n",
      "Epoch 44/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2322 - acc: 0.9096 - val_loss: 0.2453 - val_acc: 0.8935\n",
      "Epoch 45/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2343 - acc: 0.9063 - val_loss: 0.2458 - val_acc: 0.8952\n",
      "Epoch 46/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2320 - acc: 0.9096 - val_loss: 0.2390 - val_acc: 0.9016\n",
      "Epoch 47/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2285 - acc: 0.9071 - val_loss: 0.2371 - val_acc: 0.9016\n",
      "Epoch 48/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2292 - acc: 0.9096 - val_loss: 0.2346 - val_acc: 0.9032\n",
      "Epoch 49/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2284 - acc: 0.9075 - val_loss: 0.2373 - val_acc: 0.9000\n",
      "Epoch 50/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2220 - acc: 0.9148 - val_loss: 0.2334 - val_acc: 0.9016\n",
      "Epoch 51/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2201 - acc: 0.9092 - val_loss: 0.2342 - val_acc: 0.9016\n",
      "Epoch 52/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2181 - acc: 0.9116 - val_loss: 0.2402 - val_acc: 0.9000\n",
      "Epoch 53/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2182 - acc: 0.9096 - val_loss: 0.2509 - val_acc: 0.8919\n",
      "Epoch 54/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2215 - acc: 0.9108 - val_loss: 0.2377 - val_acc: 0.9016\n",
      "Epoch 55/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2183 - acc: 0.9164 - val_loss: 0.2337 - val_acc: 0.9048\n",
      "Epoch 56/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2138 - acc: 0.9144 - val_loss: 0.2323 - val_acc: 0.9048\n",
      "Epoch 57/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2139 - acc: 0.9152 - val_loss: 0.2333 - val_acc: 0.9065\n",
      "Epoch 58/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2122 - acc: 0.9140 - val_loss: 0.2367 - val_acc: 0.9000\n",
      "Epoch 59/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2142 - acc: 0.9148 - val_loss: 0.2348 - val_acc: 0.9048\n",
      "Epoch 60/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2147 - acc: 0.9152 - val_loss: 0.2360 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2094 - acc: 0.9172 - val_loss: 0.2299 - val_acc: 0.9065\n",
      "Epoch 62/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2093 - acc: 0.9176 - val_loss: 0.2269 - val_acc: 0.9129\n",
      "Epoch 63/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2080 - acc: 0.9197 - val_loss: 0.2362 - val_acc: 0.9016\n",
      "Epoch 64/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2080 - acc: 0.9193 - val_loss: 0.2274 - val_acc: 0.9097\n",
      "Epoch 65/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2091 - acc: 0.9168 - val_loss: 0.2349 - val_acc: 0.9048\n",
      "Epoch 66/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2061 - acc: 0.9189 - val_loss: 0.2275 - val_acc: 0.9161\n",
      "Epoch 67/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2090 - acc: 0.9172 - val_loss: 0.2455 - val_acc: 0.8919\n",
      "Epoch 68/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2147 - acc: 0.9132 - val_loss: 0.2279 - val_acc: 0.9048\n",
      "Epoch 69/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2068 - acc: 0.9217 - val_loss: 0.2282 - val_acc: 0.9129\n",
      "Epoch 70/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2092 - acc: 0.9160 - val_loss: 0.2312 - val_acc: 0.9048\n",
      "Epoch 71/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2040 - acc: 0.9164 - val_loss: 0.2360 - val_acc: 0.9048\n",
      "Epoch 72/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2066 - acc: 0.9164 - val_loss: 0.2364 - val_acc: 0.9048\n",
      "Epoch 73/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2075 - acc: 0.9184 - val_loss: 0.2309 - val_acc: 0.9129\n",
      "Epoch 74/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2017 - acc: 0.9172 - val_loss: 0.2293 - val_acc: 0.9113\n",
      "Epoch 75/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2056 - acc: 0.9164 - val_loss: 0.2268 - val_acc: 0.9097\n",
      "Epoch 76/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2018 - acc: 0.9180 - val_loss: 0.2365 - val_acc: 0.9097\n",
      "Epoch 77/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2044 - acc: 0.9172 - val_loss: 0.2425 - val_acc: 0.9032\n",
      "Epoch 78/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2072 - acc: 0.9213 - val_loss: 0.2242 - val_acc: 0.9081\n",
      "Epoch 79/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2063 - acc: 0.9205 - val_loss: 0.2310 - val_acc: 0.9097\n",
      "Epoch 80/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2014 - acc: 0.9205 - val_loss: 0.2312 - val_acc: 0.9016\n",
      "Epoch 81/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2010 - acc: 0.9217 - val_loss: 0.2266 - val_acc: 0.9016\n",
      "Epoch 82/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2005 - acc: 0.9237 - val_loss: 0.2309 - val_acc: 0.9048\n",
      "Epoch 83/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2026 - acc: 0.9201 - val_loss: 0.2330 - val_acc: 0.9048\n",
      "Epoch 84/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1984 - acc: 0.9209 - val_loss: 0.2278 - val_acc: 0.9145\n",
      "Epoch 85/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1993 - acc: 0.9245 - val_loss: 0.2264 - val_acc: 0.9097\n",
      "Epoch 86/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2004 - acc: 0.9237 - val_loss: 0.2329 - val_acc: 0.9016\n",
      "Epoch 87/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2019 - acc: 0.9193 - val_loss: 0.2303 - val_acc: 0.9016\n",
      "Epoch 88/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2015 - acc: 0.9197 - val_loss: 0.2312 - val_acc: 0.9048\n",
      "Epoch 89/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.2001 - acc: 0.9225 - val_loss: 0.2265 - val_acc: 0.9097\n",
      "Epoch 90/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1988 - acc: 0.9172 - val_loss: 0.2288 - val_acc: 0.9081\n",
      "Epoch 91/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1974 - acc: 0.9269 - val_loss: 0.2288 - val_acc: 0.9081\n",
      "Epoch 92/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1995 - acc: 0.9209 - val_loss: 0.2384 - val_acc: 0.8919\n",
      "Epoch 93/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1957 - acc: 0.9253 - val_loss: 0.2306 - val_acc: 0.9032\n",
      "Epoch 94/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1979 - acc: 0.9245 - val_loss: 0.2332 - val_acc: 0.8968\n",
      "Epoch 95/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1979 - acc: 0.9245 - val_loss: 0.2288 - val_acc: 0.9113\n",
      "Epoch 96/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1999 - acc: 0.9245 - val_loss: 0.2335 - val_acc: 0.9048\n",
      "Epoch 97/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1955 - acc: 0.9233 - val_loss: 0.2319 - val_acc: 0.9081\n",
      "Epoch 98/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1952 - acc: 0.9237 - val_loss: 0.2279 - val_acc: 0.9161\n",
      "Epoch 99/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1952 - acc: 0.9261 - val_loss: 0.2300 - val_acc: 0.9048\n",
      "Epoch 100/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1953 - acc: 0.9257 - val_loss: 0.2312 - val_acc: 0.9113\n",
      "Epoch 101/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1946 - acc: 0.9249 - val_loss: 0.2275 - val_acc: 0.9081\n",
      "Epoch 102/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1975 - acc: 0.9277 - val_loss: 0.2294 - val_acc: 0.9097\n",
      "Epoch 103/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1913 - acc: 0.9281 - val_loss: 0.2340 - val_acc: 0.9113\n",
      "Epoch 104/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1933 - acc: 0.9269 - val_loss: 0.2263 - val_acc: 0.9113\n",
      "Epoch 105/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1961 - acc: 0.9265 - val_loss: 0.2308 - val_acc: 0.9161\n",
      "Epoch 106/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1908 - acc: 0.9257 - val_loss: 0.2324 - val_acc: 0.9048\n",
      "Epoch 107/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1923 - acc: 0.9289 - val_loss: 0.2349 - val_acc: 0.9081\n",
      "Epoch 108/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1951 - acc: 0.9253 - val_loss: 0.2404 - val_acc: 0.9081\n",
      "Epoch 109/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1913 - acc: 0.9265 - val_loss: 0.2280 - val_acc: 0.9113\n",
      "Epoch 110/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1909 - acc: 0.9273 - val_loss: 0.2345 - val_acc: 0.9145\n",
      "Epoch 111/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1892 - acc: 0.9241 - val_loss: 0.2385 - val_acc: 0.9016\n",
      "Epoch 112/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1889 - acc: 0.9249 - val_loss: 0.2278 - val_acc: 0.9129\n",
      "Epoch 113/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1923 - acc: 0.9322 - val_loss: 0.2385 - val_acc: 0.9000\n",
      "Epoch 114/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1889 - acc: 0.9261 - val_loss: 0.2319 - val_acc: 0.9145\n",
      "Epoch 115/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1881 - acc: 0.9289 - val_loss: 0.2316 - val_acc: 0.9065\n",
      "Epoch 116/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1896 - acc: 0.9273 - val_loss: 0.2328 - val_acc: 0.9032\n",
      "Epoch 117/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1875 - acc: 0.9253 - val_loss: 0.2300 - val_acc: 0.9081\n",
      "Epoch 118/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1841 - acc: 0.9302 - val_loss: 0.2390 - val_acc: 0.9129\n",
      "Epoch 119/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1901 - acc: 0.9285 - val_loss: 0.2315 - val_acc: 0.9032\n",
      "Epoch 120/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1882 - acc: 0.9269 - val_loss: 0.2333 - val_acc: 0.9081\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1852 - acc: 0.9289 - val_loss: 0.2379 - val_acc: 0.9081\n",
      "Epoch 122/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1839 - acc: 0.9322 - val_loss: 0.2329 - val_acc: 0.9032\n",
      "Epoch 123/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1837 - acc: 0.9302 - val_loss: 0.2339 - val_acc: 0.9032\n",
      "Epoch 124/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1814 - acc: 0.9310 - val_loss: 0.2408 - val_acc: 0.9113\n",
      "Epoch 125/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1852 - acc: 0.9342 - val_loss: 0.2320 - val_acc: 0.9145\n",
      "Epoch 126/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1824 - acc: 0.9265 - val_loss: 0.2340 - val_acc: 0.9097\n",
      "Epoch 127/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1814 - acc: 0.9285 - val_loss: 0.2348 - val_acc: 0.9032\n",
      "Epoch 128/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1808 - acc: 0.9314 - val_loss: 0.2401 - val_acc: 0.9097\n",
      "Epoch 129/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1855 - acc: 0.9298 - val_loss: 0.2361 - val_acc: 0.9097\n",
      "Epoch 130/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1787 - acc: 0.9326 - val_loss: 0.2374 - val_acc: 0.9016\n",
      "Epoch 131/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1800 - acc: 0.9314 - val_loss: 0.2358 - val_acc: 0.9145\n",
      "Epoch 132/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1803 - acc: 0.9350 - val_loss: 0.2361 - val_acc: 0.9161\n",
      "Epoch 133/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1809 - acc: 0.9310 - val_loss: 0.2376 - val_acc: 0.9145\n",
      "Epoch 134/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1793 - acc: 0.9342 - val_loss: 0.2441 - val_acc: 0.9065\n",
      "Epoch 135/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1772 - acc: 0.9334 - val_loss: 0.2434 - val_acc: 0.9113\n",
      "Epoch 136/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1764 - acc: 0.9302 - val_loss: 0.2436 - val_acc: 0.9097\n",
      "Epoch 137/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1743 - acc: 0.9362 - val_loss: 0.2422 - val_acc: 0.9048\n",
      "Epoch 138/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1749 - acc: 0.9322 - val_loss: 0.2562 - val_acc: 0.9016\n",
      "Epoch 139/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1746 - acc: 0.9334 - val_loss: 0.2402 - val_acc: 0.9145\n",
      "Epoch 140/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1744 - acc: 0.9338 - val_loss: 0.2460 - val_acc: 0.9081\n",
      "Epoch 141/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1743 - acc: 0.9326 - val_loss: 0.2482 - val_acc: 0.9113\n",
      "Epoch 142/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1771 - acc: 0.9330 - val_loss: 0.2419 - val_acc: 0.9113\n",
      "Epoch 143/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1711 - acc: 0.9330 - val_loss: 0.2486 - val_acc: 0.9145\n",
      "Epoch 144/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1733 - acc: 0.9330 - val_loss: 0.2539 - val_acc: 0.9032\n",
      "Epoch 145/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1716 - acc: 0.9322 - val_loss: 0.2441 - val_acc: 0.9113\n",
      "Epoch 146/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1693 - acc: 0.9378 - val_loss: 0.2526 - val_acc: 0.9032\n",
      "Epoch 147/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1733 - acc: 0.9386 - val_loss: 0.2518 - val_acc: 0.9129\n",
      "Epoch 148/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1681 - acc: 0.9382 - val_loss: 0.2586 - val_acc: 0.9065\n",
      "Epoch 149/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1711 - acc: 0.9378 - val_loss: 0.2465 - val_acc: 0.9065\n",
      "Epoch 150/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1655 - acc: 0.9394 - val_loss: 0.2531 - val_acc: 0.9113\n",
      "Epoch 151/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1650 - acc: 0.9378 - val_loss: 0.2529 - val_acc: 0.9048\n",
      "Epoch 152/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1668 - acc: 0.9338 - val_loss: 0.2558 - val_acc: 0.9065\n",
      "Epoch 153/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1635 - acc: 0.9346 - val_loss: 0.2589 - val_acc: 0.9032\n",
      "Epoch 154/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1623 - acc: 0.9407 - val_loss: 0.2604 - val_acc: 0.9032\n",
      "Epoch 155/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1619 - acc: 0.9382 - val_loss: 0.2547 - val_acc: 0.9065\n",
      "Epoch 156/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1604 - acc: 0.9403 - val_loss: 0.2579 - val_acc: 0.9145\n",
      "Epoch 157/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1614 - acc: 0.9394 - val_loss: 0.2577 - val_acc: 0.9048\n",
      "Epoch 158/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1608 - acc: 0.9378 - val_loss: 0.2639 - val_acc: 0.9000\n",
      "Epoch 159/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1571 - acc: 0.9386 - val_loss: 0.2753 - val_acc: 0.9081\n",
      "Epoch 160/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1568 - acc: 0.9427 - val_loss: 0.2791 - val_acc: 0.9048\n",
      "Epoch 161/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1587 - acc: 0.9427 - val_loss: 0.2673 - val_acc: 0.9065\n",
      "Epoch 162/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1545 - acc: 0.9386 - val_loss: 0.2774 - val_acc: 0.9000\n",
      "Epoch 163/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1506 - acc: 0.9439 - val_loss: 0.2912 - val_acc: 0.9048\n",
      "Epoch 164/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1589 - acc: 0.9374 - val_loss: 0.2796 - val_acc: 0.9097\n",
      "Epoch 165/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1512 - acc: 0.9439 - val_loss: 0.3027 - val_acc: 0.8952\n",
      "Epoch 166/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1577 - acc: 0.9382 - val_loss: 0.2772 - val_acc: 0.9048\n",
      "Epoch 167/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1558 - acc: 0.9394 - val_loss: 0.2830 - val_acc: 0.8984\n",
      "Epoch 168/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1534 - acc: 0.9427 - val_loss: 0.2833 - val_acc: 0.9000\n",
      "Epoch 169/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1504 - acc: 0.9439 - val_loss: 0.2884 - val_acc: 0.9048\n",
      "Epoch 170/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1485 - acc: 0.9451 - val_loss: 0.2891 - val_acc: 0.9048\n",
      "Epoch 171/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1455 - acc: 0.9459 - val_loss: 0.2834 - val_acc: 0.9065\n",
      "Epoch 172/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1447 - acc: 0.9435 - val_loss: 0.2939 - val_acc: 0.8968\n",
      "Epoch 173/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1442 - acc: 0.9483 - val_loss: 0.2989 - val_acc: 0.8968\n",
      "Epoch 174/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1466 - acc: 0.9475 - val_loss: 0.2904 - val_acc: 0.9065\n",
      "Epoch 175/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1425 - acc: 0.9459 - val_loss: 0.2932 - val_acc: 0.8968\n",
      "Epoch 176/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1432 - acc: 0.9487 - val_loss: 0.2838 - val_acc: 0.9065\n",
      "Epoch 177/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1545 - acc: 0.9398 - val_loss: 0.2800 - val_acc: 0.9032\n",
      "Epoch 178/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1429 - acc: 0.9475 - val_loss: 0.2945 - val_acc: 0.9097\n",
      "Epoch 179/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1440 - acc: 0.9487 - val_loss: 0.2926 - val_acc: 0.9032\n",
      "Epoch 180/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1422 - acc: 0.9439 - val_loss: 0.2981 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1365 - acc: 0.9503 - val_loss: 0.2867 - val_acc: 0.9097\n",
      "Epoch 182/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1344 - acc: 0.9491 - val_loss: 0.2976 - val_acc: 0.9065\n",
      "Epoch 183/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1383 - acc: 0.9475 - val_loss: 0.3194 - val_acc: 0.9032\n",
      "Epoch 184/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1383 - acc: 0.9524 - val_loss: 0.3134 - val_acc: 0.9016\n",
      "Epoch 185/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1396 - acc: 0.9475 - val_loss: 0.2996 - val_acc: 0.9016\n",
      "Epoch 186/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1344 - acc: 0.9487 - val_loss: 0.3294 - val_acc: 0.8887\n",
      "Epoch 187/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1383 - acc: 0.9516 - val_loss: 0.3046 - val_acc: 0.9048\n",
      "Epoch 188/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1324 - acc: 0.9524 - val_loss: 0.3010 - val_acc: 0.9081\n",
      "Epoch 189/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1312 - acc: 0.9536 - val_loss: 0.3079 - val_acc: 0.9048\n",
      "Epoch 190/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1306 - acc: 0.9499 - val_loss: 0.3033 - val_acc: 0.9065\n",
      "Epoch 191/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1352 - acc: 0.9499 - val_loss: 0.3124 - val_acc: 0.8903\n",
      "Epoch 192/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1301 - acc: 0.9516 - val_loss: 0.3106 - val_acc: 0.9048\n",
      "Epoch 193/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1304 - acc: 0.9520 - val_loss: 0.3159 - val_acc: 0.9032\n",
      "Epoch 194/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1290 - acc: 0.9528 - val_loss: 0.3187 - val_acc: 0.9032\n",
      "Epoch 195/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1307 - acc: 0.9516 - val_loss: 0.3156 - val_acc: 0.9032\n",
      "Epoch 196/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1261 - acc: 0.9564 - val_loss: 0.3255 - val_acc: 0.9065\n",
      "Epoch 197/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1301 - acc: 0.9520 - val_loss: 0.3131 - val_acc: 0.9065\n",
      "Epoch 198/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1283 - acc: 0.9548 - val_loss: 0.3261 - val_acc: 0.8952\n",
      "Epoch 199/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1313 - acc: 0.9495 - val_loss: 0.3605 - val_acc: 0.8903\n",
      "Epoch 200/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1227 - acc: 0.9560 - val_loss: 0.3354 - val_acc: 0.9000\n",
      "Epoch 201/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1296 - acc: 0.9540 - val_loss: 0.3416 - val_acc: 0.9000\n",
      "Epoch 202/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1224 - acc: 0.9528 - val_loss: 0.3371 - val_acc: 0.9065\n",
      "Epoch 203/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1178 - acc: 0.9572 - val_loss: 0.3286 - val_acc: 0.9081\n",
      "Epoch 204/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1184 - acc: 0.9564 - val_loss: 0.3367 - val_acc: 0.8984\n",
      "Epoch 205/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1256 - acc: 0.9560 - val_loss: 0.3600 - val_acc: 0.8919\n",
      "Epoch 206/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1178 - acc: 0.9548 - val_loss: 0.3750 - val_acc: 0.8919\n",
      "Epoch 207/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1225 - acc: 0.9560 - val_loss: 0.3570 - val_acc: 0.8984\n",
      "Epoch 208/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1186 - acc: 0.9572 - val_loss: 0.3488 - val_acc: 0.9065\n",
      "Epoch 209/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1157 - acc: 0.9576 - val_loss: 0.3381 - val_acc: 0.9048\n",
      "Epoch 210/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1161 - acc: 0.9552 - val_loss: 0.3464 - val_acc: 0.9016\n",
      "Epoch 211/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1143 - acc: 0.9572 - val_loss: 0.3519 - val_acc: 0.8984\n",
      "Epoch 212/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1138 - acc: 0.9592 - val_loss: 0.3664 - val_acc: 0.8984\n",
      "Epoch 213/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1140 - acc: 0.9576 - val_loss: 0.3706 - val_acc: 0.9000\n",
      "Epoch 214/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1141 - acc: 0.9580 - val_loss: 0.3540 - val_acc: 0.9016\n",
      "Epoch 215/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1115 - acc: 0.9580 - val_loss: 0.3616 - val_acc: 0.9016\n",
      "Epoch 216/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1081 - acc: 0.9604 - val_loss: 0.3979 - val_acc: 0.8935\n",
      "Epoch 217/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1190 - acc: 0.9572 - val_loss: 0.3577 - val_acc: 0.8968\n",
      "Epoch 218/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1084 - acc: 0.9604 - val_loss: 0.3679 - val_acc: 0.9032\n",
      "Epoch 219/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1049 - acc: 0.9621 - val_loss: 0.3958 - val_acc: 0.8952\n",
      "Epoch 220/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1095 - acc: 0.9576 - val_loss: 0.3878 - val_acc: 0.8935\n",
      "Epoch 221/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1036 - acc: 0.9629 - val_loss: 0.3591 - val_acc: 0.9048\n",
      "Epoch 222/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1030 - acc: 0.9649 - val_loss: 0.3923 - val_acc: 0.9048\n",
      "Epoch 223/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0992 - acc: 0.9637 - val_loss: 0.3740 - val_acc: 0.9016\n",
      "Epoch 224/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1094 - acc: 0.9572 - val_loss: 0.3983 - val_acc: 0.8968\n",
      "Epoch 225/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1088 - acc: 0.9584 - val_loss: 0.4081 - val_acc: 0.8903\n",
      "Epoch 226/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1066 - acc: 0.9568 - val_loss: 0.3740 - val_acc: 0.9048\n",
      "Epoch 227/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1030 - acc: 0.9596 - val_loss: 0.3961 - val_acc: 0.8952\n",
      "Epoch 228/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1052 - acc: 0.9592 - val_loss: 0.3819 - val_acc: 0.9000\n",
      "Epoch 229/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0955 - acc: 0.9649 - val_loss: 0.3970 - val_acc: 0.8952\n",
      "Epoch 230/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0923 - acc: 0.9669 - val_loss: 0.4412 - val_acc: 0.8871\n",
      "Epoch 231/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0982 - acc: 0.9629 - val_loss: 0.4372 - val_acc: 0.8887\n",
      "Epoch 232/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0927 - acc: 0.9653 - val_loss: 0.3929 - val_acc: 0.9016\n",
      "Epoch 233/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0929 - acc: 0.9661 - val_loss: 0.4397 - val_acc: 0.8887\n",
      "Epoch 234/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0961 - acc: 0.9661 - val_loss: 0.3876 - val_acc: 0.9016\n",
      "Epoch 235/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1049 - acc: 0.9625 - val_loss: 0.4148 - val_acc: 0.9000\n",
      "Epoch 236/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0930 - acc: 0.9665 - val_loss: 0.4598 - val_acc: 0.8871\n",
      "Epoch 237/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0920 - acc: 0.9665 - val_loss: 0.4249 - val_acc: 0.8919\n",
      "Epoch 238/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0855 - acc: 0.9689 - val_loss: 0.4836 - val_acc: 0.8855\n",
      "Epoch 239/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0876 - acc: 0.9701 - val_loss: 0.4386 - val_acc: 0.8952\n",
      "Epoch 240/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0870 - acc: 0.9673 - val_loss: 0.4361 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0970 - acc: 0.9633 - val_loss: 0.4443 - val_acc: 0.8968\n",
      "Epoch 242/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0879 - acc: 0.9685 - val_loss: 0.4454 - val_acc: 0.8919\n",
      "Epoch 243/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0791 - acc: 0.9709 - val_loss: 0.4896 - val_acc: 0.8984\n",
      "Epoch 244/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0879 - acc: 0.9637 - val_loss: 0.4524 - val_acc: 0.8952\n",
      "Epoch 245/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0798 - acc: 0.9701 - val_loss: 0.4674 - val_acc: 0.8871\n",
      "Epoch 246/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0940 - acc: 0.9645 - val_loss: 0.4498 - val_acc: 0.8903\n",
      "Epoch 247/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0837 - acc: 0.9705 - val_loss: 0.4947 - val_acc: 0.8871\n",
      "Epoch 248/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0813 - acc: 0.9697 - val_loss: 0.4754 - val_acc: 0.8968\n",
      "Epoch 249/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0758 - acc: 0.9709 - val_loss: 0.4673 - val_acc: 0.8968\n",
      "Epoch 250/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0797 - acc: 0.9717 - val_loss: 0.4941 - val_acc: 0.8903\n",
      "Epoch 251/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0763 - acc: 0.9717 - val_loss: 0.5032 - val_acc: 0.8871\n",
      "Epoch 252/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1084 - acc: 0.9612 - val_loss: 0.5317 - val_acc: 0.8839\n",
      "Epoch 253/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1013 - acc: 0.9629 - val_loss: 0.4611 - val_acc: 0.8935\n",
      "Epoch 254/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0877 - acc: 0.9649 - val_loss: 0.5000 - val_acc: 0.8984\n",
      "Epoch 255/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0798 - acc: 0.9721 - val_loss: 0.4884 - val_acc: 0.8952\n",
      "Epoch 256/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0774 - acc: 0.9705 - val_loss: 0.4943 - val_acc: 0.8855\n",
      "Epoch 257/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0753 - acc: 0.9701 - val_loss: 0.5369 - val_acc: 0.8839\n",
      "Epoch 258/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0808 - acc: 0.9693 - val_loss: 0.4539 - val_acc: 0.8855\n",
      "Epoch 259/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0908 - acc: 0.9693 - val_loss: 0.4777 - val_acc: 0.8887\n",
      "Epoch 260/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0669 - acc: 0.9758 - val_loss: 0.4770 - val_acc: 0.8871\n",
      "Epoch 261/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0656 - acc: 0.9742 - val_loss: 0.5134 - val_acc: 0.8903\n",
      "Epoch 262/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0643 - acc: 0.9770 - val_loss: 0.5206 - val_acc: 0.8903\n",
      "Epoch 263/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0672 - acc: 0.9742 - val_loss: 0.5581 - val_acc: 0.8806\n",
      "Epoch 264/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0660 - acc: 0.9750 - val_loss: 0.5501 - val_acc: 0.8871\n",
      "Epoch 265/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0648 - acc: 0.9766 - val_loss: 0.4871 - val_acc: 0.8919\n",
      "Epoch 266/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0653 - acc: 0.9754 - val_loss: 0.5496 - val_acc: 0.8823\n",
      "Epoch 267/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0665 - acc: 0.9754 - val_loss: 0.5956 - val_acc: 0.8806\n",
      "Epoch 268/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0709 - acc: 0.9742 - val_loss: 0.5681 - val_acc: 0.8823\n",
      "Epoch 269/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0657 - acc: 0.9730 - val_loss: 0.4755 - val_acc: 0.9016\n",
      "Epoch 270/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0616 - acc: 0.9782 - val_loss: 0.5735 - val_acc: 0.8871\n",
      "Epoch 271/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0678 - acc: 0.9738 - val_loss: 0.5238 - val_acc: 0.8887\n",
      "Epoch 272/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0695 - acc: 0.9709 - val_loss: 0.5638 - val_acc: 0.8823\n",
      "Epoch 273/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0584 - acc: 0.9790 - val_loss: 0.5420 - val_acc: 0.8855\n",
      "Epoch 274/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0694 - acc: 0.9742 - val_loss: 0.5276 - val_acc: 0.8887\n",
      "Epoch 275/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1864 - acc: 0.9411 - val_loss: 0.4210 - val_acc: 0.8935\n",
      "Epoch 276/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.1039 - acc: 0.9596 - val_loss: 0.4856 - val_acc: 0.8855\n",
      "Epoch 277/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0638 - acc: 0.9738 - val_loss: 0.5202 - val_acc: 0.8823\n",
      "Epoch 278/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0568 - acc: 0.9790 - val_loss: 0.5540 - val_acc: 0.8855\n",
      "Epoch 279/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0559 - acc: 0.9802 - val_loss: 0.5576 - val_acc: 0.8887\n",
      "Epoch 280/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0547 - acc: 0.9810 - val_loss: 0.5511 - val_acc: 0.8855\n",
      "Epoch 281/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0517 - acc: 0.9822 - val_loss: 0.6402 - val_acc: 0.8806\n",
      "Epoch 282/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0574 - acc: 0.9778 - val_loss: 0.5660 - val_acc: 0.8774\n",
      "Epoch 283/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0514 - acc: 0.9814 - val_loss: 0.5941 - val_acc: 0.8855\n",
      "Epoch 284/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0511 - acc: 0.9806 - val_loss: 0.5845 - val_acc: 0.8774\n",
      "Epoch 285/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0460 - acc: 0.9826 - val_loss: 0.5877 - val_acc: 0.8839\n",
      "Epoch 286/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0583 - acc: 0.9774 - val_loss: 0.5771 - val_acc: 0.8871\n",
      "Epoch 287/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0507 - acc: 0.9810 - val_loss: 0.5610 - val_acc: 0.8855\n",
      "Epoch 288/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0501 - acc: 0.9810 - val_loss: 0.6021 - val_acc: 0.8855\n",
      "Epoch 289/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0575 - acc: 0.9782 - val_loss: 0.5753 - val_acc: 0.8871\n",
      "Epoch 290/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0657 - acc: 0.9746 - val_loss: 0.5551 - val_acc: 0.8806\n",
      "Epoch 291/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0561 - acc: 0.9794 - val_loss: 0.5913 - val_acc: 0.8806\n",
      "Epoch 292/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0449 - acc: 0.9818 - val_loss: 0.6324 - val_acc: 0.8823\n",
      "Epoch 293/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0459 - acc: 0.9830 - val_loss: 0.6116 - val_acc: 0.8726\n",
      "Epoch 294/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0420 - acc: 0.9839 - val_loss: 0.6383 - val_acc: 0.8806\n",
      "Epoch 295/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0490 - acc: 0.9822 - val_loss: 0.6180 - val_acc: 0.8823\n",
      "Epoch 296/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0451 - acc: 0.9834 - val_loss: 0.6472 - val_acc: 0.8839\n",
      "Epoch 297/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0419 - acc: 0.9847 - val_loss: 0.6441 - val_acc: 0.8710\n",
      "Epoch 298/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0381 - acc: 0.9851 - val_loss: 0.6227 - val_acc: 0.8758\n",
      "Epoch 299/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0384 - acc: 0.9843 - val_loss: 0.6422 - val_acc: 0.8806\n",
      "Epoch 300/300\n",
      "2477/2477 [==============================] - 4s 2ms/step - loss: 0.0445 - acc: 0.9834 - val_loss: 0.6459 - val_acc: 0.8871\n"
     ]
    }
   ],
   "source": [
    "model_LSTM_train = model_LSTM.fit(train_X, train_Y, epochs=epochs, batch_size=32, validation_data=(valid_X, valid_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_LSTM_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1455ddca9a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the training accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_LSTM_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_LSTM_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_LSTM_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_LSTM_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_LSTM_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the training accuracy\n",
    "accuracy = model_LSTM_train.history['acc']\n",
    "val_accuracy = model_LSTM_train.history['val_acc']\n",
    "loss = model_LSTM_train.history['loss']\n",
    "val_loss = model_LSTM_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('LSTM Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('LSTM Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pred = np.argmax(model_LSTM.predict(valid_X), axis=1)\n",
    "y_true = np.argmax(valid_Y, axis = 1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "f1 = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "auc = roc_auc_score(y_true, y_pred, average='macro', sample_weight=None, max_fpr=None)\n",
    "sensi = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "accu = (tn + tp)/(tn + tp + fn + fp)\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print('{} Result'.format(string_name))\n",
    "print('Accuracy :', accu)\n",
    "print('AUC :', auc)\n",
    "print('Sensitivity :', sensi)\n",
    "print('Specificity :', specificity)\n",
    "print('F1 :', f1)\n",
    "print('MCC :', mcc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2477 samples, validate on 620 samples\n",
      "Epoch 1/300\n",
      "2477/2477 [==============================] - 12s 5ms/step - loss: 0.6931 - acc: 0.5196 - val_loss: 0.6901 - val_acc: 0.5194\n",
      "Epoch 2/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.4858 - acc: 0.7485 - val_loss: 0.2868 - val_acc: 0.8919\n",
      "Epoch 3/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2813 - acc: 0.8857 - val_loss: 0.2513 - val_acc: 0.9065\n",
      "Epoch 4/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2633 - acc: 0.8926 - val_loss: 0.2637 - val_acc: 0.8871\n",
      "Epoch 5/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2645 - acc: 0.8918 - val_loss: 0.2416 - val_acc: 0.8984\n",
      "Epoch 6/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2500 - acc: 0.9043 - val_loss: 0.2544 - val_acc: 0.8968\n",
      "Epoch 7/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2560 - acc: 0.8979 - val_loss: 0.2379 - val_acc: 0.8984\n",
      "Epoch 8/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2495 - acc: 0.8946 - val_loss: 0.2472 - val_acc: 0.8903\n",
      "Epoch 9/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2486 - acc: 0.8983 - val_loss: 0.2412 - val_acc: 0.9000\n",
      "Epoch 10/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2488 - acc: 0.8934 - val_loss: 0.2471 - val_acc: 0.8968\n",
      "Epoch 11/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2457 - acc: 0.8975 - val_loss: 0.2410 - val_acc: 0.8935\n",
      "Epoch 12/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2499 - acc: 0.8966 - val_loss: 0.2535 - val_acc: 0.8919\n",
      "Epoch 13/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2464 - acc: 0.9015 - val_loss: 0.2655 - val_acc: 0.8855\n",
      "Epoch 14/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2469 - acc: 0.8983 - val_loss: 0.2582 - val_acc: 0.9000\n",
      "Epoch 15/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2491 - acc: 0.8983 - val_loss: 0.2420 - val_acc: 0.8952\n",
      "Epoch 16/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2449 - acc: 0.9007 - val_loss: 0.2449 - val_acc: 0.8919\n",
      "Epoch 17/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2408 - acc: 0.9011 - val_loss: 0.2391 - val_acc: 0.8968\n",
      "Epoch 18/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2471 - acc: 0.8954 - val_loss: 0.2496 - val_acc: 0.8952\n",
      "Epoch 19/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2475 - acc: 0.9003 - val_loss: 0.2646 - val_acc: 0.8839\n",
      "Epoch 20/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2464 - acc: 0.8995 - val_loss: 0.2461 - val_acc: 0.8984\n",
      "Epoch 21/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2412 - acc: 0.9011 - val_loss: 0.2438 - val_acc: 0.8952\n",
      "Epoch 22/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2396 - acc: 0.9027 - val_loss: 0.2498 - val_acc: 0.8952\n",
      "Epoch 23/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2362 - acc: 0.9015 - val_loss: 0.2519 - val_acc: 0.8968\n",
      "Epoch 24/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2396 - acc: 0.9015 - val_loss: 0.2481 - val_acc: 0.8935\n",
      "Epoch 25/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2458 - acc: 0.8999 - val_loss: 0.2410 - val_acc: 0.8952\n",
      "Epoch 26/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2370 - acc: 0.9043 - val_loss: 0.2460 - val_acc: 0.8968\n",
      "Epoch 27/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2366 - acc: 0.9043 - val_loss: 0.2427 - val_acc: 0.8887\n",
      "Epoch 28/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2336 - acc: 0.9059 - val_loss: 0.2403 - val_acc: 0.8919\n",
      "Epoch 29/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2412 - acc: 0.8995 - val_loss: 0.2387 - val_acc: 0.8935\n",
      "Epoch 30/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2315 - acc: 0.9055 - val_loss: 0.2384 - val_acc: 0.8984\n",
      "Epoch 31/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2323 - acc: 0.9096 - val_loss: 0.2592 - val_acc: 0.8903\n",
      "Epoch 32/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2333 - acc: 0.9039 - val_loss: 0.2500 - val_acc: 0.9016\n",
      "Epoch 33/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2292 - acc: 0.9092 - val_loss: 0.2410 - val_acc: 0.8952\n",
      "Epoch 34/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2310 - acc: 0.9075 - val_loss: 0.2398 - val_acc: 0.9000\n",
      "Epoch 35/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2275 - acc: 0.9063 - val_loss: 0.2433 - val_acc: 0.9000\n",
      "Epoch 36/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2330 - acc: 0.9039 - val_loss: 0.2525 - val_acc: 0.8919\n",
      "Epoch 37/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2271 - acc: 0.9067 - val_loss: 0.2437 - val_acc: 0.8919\n",
      "Epoch 38/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2294 - acc: 0.9043 - val_loss: 0.2437 - val_acc: 0.8919\n",
      "Epoch 39/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2254 - acc: 0.9092 - val_loss: 0.2406 - val_acc: 0.8968\n",
      "Epoch 40/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2273 - acc: 0.9063 - val_loss: 0.2444 - val_acc: 0.9000\n",
      "Epoch 41/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.2307 - acc: 0.9071 - val_loss: 0.2414 - val_acc: 0.8984\n",
      "Epoch 42/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.2246 - acc: 0.9088 - val_loss: 0.2456 - val_acc: 0.8968\n",
      "Epoch 43/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2236 - acc: 0.9088 - val_loss: 0.2408 - val_acc: 0.8935\n",
      "Epoch 44/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2228 - acc: 0.9088 - val_loss: 0.2600 - val_acc: 0.8935\n",
      "Epoch 45/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2220 - acc: 0.9108 - val_loss: 0.2422 - val_acc: 0.9000\n",
      "Epoch 46/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2200 - acc: 0.9124 - val_loss: 0.2447 - val_acc: 0.8968\n",
      "Epoch 47/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2203 - acc: 0.9100 - val_loss: 0.2390 - val_acc: 0.9048\n",
      "Epoch 48/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2218 - acc: 0.9108 - val_loss: 0.2393 - val_acc: 0.9000\n",
      "Epoch 49/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2201 - acc: 0.9120 - val_loss: 0.2628 - val_acc: 0.8903\n",
      "Epoch 50/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2184 - acc: 0.9124 - val_loss: 0.2427 - val_acc: 0.9000\n",
      "Epoch 51/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2171 - acc: 0.9128 - val_loss: 0.2435 - val_acc: 0.9016\n",
      "Epoch 52/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2173 - acc: 0.9136 - val_loss: 0.2440 - val_acc: 0.9032\n",
      "Epoch 53/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2159 - acc: 0.9128 - val_loss: 0.2566 - val_acc: 0.8952\n",
      "Epoch 54/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2125 - acc: 0.9132 - val_loss: 0.2612 - val_acc: 0.8806\n",
      "Epoch 55/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2181 - acc: 0.9164 - val_loss: 0.2422 - val_acc: 0.9016\n",
      "Epoch 56/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2153 - acc: 0.9080 - val_loss: 0.2989 - val_acc: 0.8952\n",
      "Epoch 57/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2164 - acc: 0.9100 - val_loss: 0.2381 - val_acc: 0.9032\n",
      "Epoch 58/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2122 - acc: 0.9136 - val_loss: 0.2440 - val_acc: 0.8984\n",
      "Epoch 59/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2154 - acc: 0.9201 - val_loss: 0.2463 - val_acc: 0.9016\n",
      "Epoch 60/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2107 - acc: 0.9180 - val_loss: 0.2417 - val_acc: 0.9032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2082 - acc: 0.9197 - val_loss: 0.2422 - val_acc: 0.9097\n",
      "Epoch 62/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2143 - acc: 0.9148 - val_loss: 0.2473 - val_acc: 0.9097\n",
      "Epoch 63/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2067 - acc: 0.9217 - val_loss: 0.2456 - val_acc: 0.9032\n",
      "Epoch 64/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2043 - acc: 0.9180 - val_loss: 0.2640 - val_acc: 0.8935\n",
      "Epoch 65/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2122 - acc: 0.9168 - val_loss: 0.2399 - val_acc: 0.9113\n",
      "Epoch 66/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2079 - acc: 0.9180 - val_loss: 0.2371 - val_acc: 0.9081\n",
      "Epoch 67/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2052 - acc: 0.9193 - val_loss: 0.2450 - val_acc: 0.9097\n",
      "Epoch 68/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2082 - acc: 0.9209 - val_loss: 0.2495 - val_acc: 0.9032\n",
      "Epoch 69/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2052 - acc: 0.9205 - val_loss: 0.2434 - val_acc: 0.9016\n",
      "Epoch 70/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2036 - acc: 0.9205 - val_loss: 0.2650 - val_acc: 0.8952\n",
      "Epoch 71/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2057 - acc: 0.9189 - val_loss: 0.2367 - val_acc: 0.9129\n",
      "Epoch 72/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1998 - acc: 0.9249 - val_loss: 0.2506 - val_acc: 0.9048\n",
      "Epoch 73/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2018 - acc: 0.9176 - val_loss: 0.2419 - val_acc: 0.9113\n",
      "Epoch 74/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.2020 - acc: 0.9249 - val_loss: 0.2349 - val_acc: 0.9113\n",
      "Epoch 75/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1997 - acc: 0.9229 - val_loss: 0.2416 - val_acc: 0.9097\n",
      "Epoch 76/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1983 - acc: 0.9221 - val_loss: 0.2317 - val_acc: 0.9145\n",
      "Epoch 77/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.2003 - acc: 0.9241 - val_loss: 0.2340 - val_acc: 0.9145\n",
      "Epoch 78/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1952 - acc: 0.9249 - val_loss: 0.2468 - val_acc: 0.9081\n",
      "Epoch 79/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1972 - acc: 0.9269 - val_loss: 0.2351 - val_acc: 0.9097\n",
      "Epoch 80/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1938 - acc: 0.9273 - val_loss: 0.2403 - val_acc: 0.9113\n",
      "Epoch 81/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1936 - acc: 0.9257 - val_loss: 0.2450 - val_acc: 0.9129\n",
      "Epoch 82/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1945 - acc: 0.9225 - val_loss: 0.2410 - val_acc: 0.9145\n",
      "Epoch 83/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1927 - acc: 0.9285 - val_loss: 0.2472 - val_acc: 0.9129\n",
      "Epoch 84/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1922 - acc: 0.9273 - val_loss: 0.2363 - val_acc: 0.9161\n",
      "Epoch 85/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1881 - acc: 0.9314 - val_loss: 0.2275 - val_acc: 0.9145\n",
      "Epoch 86/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1871 - acc: 0.9289 - val_loss: 0.2351 - val_acc: 0.9177\n",
      "Epoch 87/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1923 - acc: 0.9273 - val_loss: 0.2353 - val_acc: 0.9177\n",
      "Epoch 88/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1866 - acc: 0.9306 - val_loss: 0.2322 - val_acc: 0.9161\n",
      "Epoch 89/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1850 - acc: 0.9326 - val_loss: 0.2360 - val_acc: 0.9145\n",
      "Epoch 90/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1837 - acc: 0.9318 - val_loss: 0.2354 - val_acc: 0.9129\n",
      "Epoch 91/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1856 - acc: 0.9310 - val_loss: 0.2277 - val_acc: 0.9177\n",
      "Epoch 92/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1825 - acc: 0.9310 - val_loss: 0.2279 - val_acc: 0.9194\n",
      "Epoch 93/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1847 - acc: 0.9306 - val_loss: 0.2284 - val_acc: 0.9113\n",
      "Epoch 94/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1837 - acc: 0.9306 - val_loss: 0.2461 - val_acc: 0.9129\n",
      "Epoch 95/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1820 - acc: 0.9322 - val_loss: 0.2354 - val_acc: 0.9161\n",
      "Epoch 96/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1823 - acc: 0.9314 - val_loss: 0.2353 - val_acc: 0.9161\n",
      "Epoch 97/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1837 - acc: 0.9310 - val_loss: 0.2406 - val_acc: 0.9145\n",
      "Epoch 98/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1798 - acc: 0.9302 - val_loss: 0.2313 - val_acc: 0.9113\n",
      "Epoch 99/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1797 - acc: 0.9342 - val_loss: 0.2414 - val_acc: 0.9177\n",
      "Epoch 100/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1758 - acc: 0.9358 - val_loss: 0.2391 - val_acc: 0.9161\n",
      "Epoch 101/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1800 - acc: 0.9330 - val_loss: 0.2292 - val_acc: 0.9145\n",
      "Epoch 102/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1780 - acc: 0.9306 - val_loss: 0.2338 - val_acc: 0.9097\n",
      "Epoch 103/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1740 - acc: 0.9362 - val_loss: 0.2349 - val_acc: 0.9129\n",
      "Epoch 104/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1776 - acc: 0.9289 - val_loss: 0.2322 - val_acc: 0.9097\n",
      "Epoch 105/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1719 - acc: 0.9398 - val_loss: 0.2363 - val_acc: 0.9113\n",
      "Epoch 106/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1751 - acc: 0.9366 - val_loss: 0.2365 - val_acc: 0.9113\n",
      "Epoch 107/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1751 - acc: 0.9314 - val_loss: 0.2373 - val_acc: 0.9097\n",
      "Epoch 108/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1706 - acc: 0.9386 - val_loss: 0.2385 - val_acc: 0.9097\n",
      "Epoch 109/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1723 - acc: 0.9342 - val_loss: 0.2420 - val_acc: 0.9129\n",
      "Epoch 110/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1711 - acc: 0.9358 - val_loss: 0.2348 - val_acc: 0.9129\n",
      "Epoch 111/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1707 - acc: 0.9338 - val_loss: 0.2419 - val_acc: 0.9129\n",
      "Epoch 112/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1713 - acc: 0.9350 - val_loss: 0.2393 - val_acc: 0.9129\n",
      "Epoch 113/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1715 - acc: 0.9354 - val_loss: 0.2315 - val_acc: 0.9097\n",
      "Epoch 114/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1669 - acc: 0.9366 - val_loss: 0.2600 - val_acc: 0.9113\n",
      "Epoch 115/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1723 - acc: 0.9378 - val_loss: 0.2348 - val_acc: 0.9129\n",
      "Epoch 116/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1658 - acc: 0.9358 - val_loss: 0.2435 - val_acc: 0.9113\n",
      "Epoch 117/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1695 - acc: 0.9346 - val_loss: 0.2313 - val_acc: 0.9097\n",
      "Epoch 118/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1655 - acc: 0.9354 - val_loss: 0.2386 - val_acc: 0.9113\n",
      "Epoch 119/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1639 - acc: 0.9390 - val_loss: 0.2427 - val_acc: 0.9097\n",
      "Epoch 120/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1693 - acc: 0.9358 - val_loss: 0.2239 - val_acc: 0.9145\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1659 - acc: 0.9358 - val_loss: 0.2285 - val_acc: 0.9129\n",
      "Epoch 122/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1689 - acc: 0.9354 - val_loss: 0.2452 - val_acc: 0.9081\n",
      "Epoch 123/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1649 - acc: 0.9370 - val_loss: 0.2357 - val_acc: 0.9081\n",
      "Epoch 124/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1655 - acc: 0.9366 - val_loss: 0.2359 - val_acc: 0.9097\n",
      "Epoch 125/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1641 - acc: 0.9374 - val_loss: 0.2390 - val_acc: 0.9129\n",
      "Epoch 126/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1593 - acc: 0.9403 - val_loss: 0.2433 - val_acc: 0.9145\n",
      "Epoch 127/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1604 - acc: 0.9366 - val_loss: 0.2392 - val_acc: 0.9032\n",
      "Epoch 128/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.1578 - acc: 0.9378 - val_loss: 0.2421 - val_acc: 0.9081\n",
      "Epoch 129/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1625 - acc: 0.9407 - val_loss: 0.2495 - val_acc: 0.9016\n",
      "Epoch 130/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1568 - acc: 0.9403 - val_loss: 0.2500 - val_acc: 0.9016\n",
      "Epoch 131/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1547 - acc: 0.9407 - val_loss: 0.2450 - val_acc: 0.9081\n",
      "Epoch 132/300\n",
      "2477/2477 [==============================] - 7s 3ms/step - loss: 0.1543 - acc: 0.9423 - val_loss: 0.2450 - val_acc: 0.9048\n",
      "Epoch 133/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1568 - acc: 0.9403 - val_loss: 0.2599 - val_acc: 0.9065\n",
      "Epoch 134/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1556 - acc: 0.9411 - val_loss: 0.2449 - val_acc: 0.9081\n",
      "Epoch 135/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1532 - acc: 0.9419 - val_loss: 0.2485 - val_acc: 0.9065\n",
      "Epoch 136/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.1537 - acc: 0.9386 - val_loss: 0.2571 - val_acc: 0.9065\n",
      "Epoch 137/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1495 - acc: 0.9419 - val_loss: 0.2538 - val_acc: 0.9016\n",
      "Epoch 138/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1519 - acc: 0.9403 - val_loss: 0.2452 - val_acc: 0.9081\n",
      "Epoch 139/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1478 - acc: 0.9411 - val_loss: 0.2870 - val_acc: 0.9065\n",
      "Epoch 140/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.1502 - acc: 0.9451 - val_loss: 0.2614 - val_acc: 0.9016\n",
      "Epoch 141/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.1528 - acc: 0.9427 - val_loss: 0.2580 - val_acc: 0.9081\n",
      "Epoch 142/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1525 - acc: 0.9447 - val_loss: 0.2574 - val_acc: 0.8984\n",
      "Epoch 143/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1533 - acc: 0.9423 - val_loss: 0.2427 - val_acc: 0.9129\n",
      "Epoch 144/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1504 - acc: 0.9455 - val_loss: 0.2420 - val_acc: 0.9097\n",
      "Epoch 145/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1460 - acc: 0.9459 - val_loss: 0.2353 - val_acc: 0.9113\n",
      "Epoch 146/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1464 - acc: 0.9459 - val_loss: 0.2460 - val_acc: 0.9113\n",
      "Epoch 147/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1465 - acc: 0.9443 - val_loss: 0.2558 - val_acc: 0.9065\n",
      "Epoch 148/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1434 - acc: 0.9459 - val_loss: 0.2549 - val_acc: 0.9048\n",
      "Epoch 149/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1406 - acc: 0.9479 - val_loss: 0.2601 - val_acc: 0.9081\n",
      "Epoch 150/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1409 - acc: 0.9455 - val_loss: 0.2556 - val_acc: 0.9097\n",
      "Epoch 151/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1420 - acc: 0.9479 - val_loss: 0.2618 - val_acc: 0.9048\n",
      "Epoch 152/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1424 - acc: 0.9471 - val_loss: 0.2715 - val_acc: 0.9032\n",
      "Epoch 153/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1484 - acc: 0.9443 - val_loss: 0.2678 - val_acc: 0.9048\n",
      "Epoch 154/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1422 - acc: 0.9443 - val_loss: 0.2969 - val_acc: 0.8968\n",
      "Epoch 155/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1371 - acc: 0.9471 - val_loss: 0.2694 - val_acc: 0.9081\n",
      "Epoch 156/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1377 - acc: 0.9483 - val_loss: 0.2841 - val_acc: 0.9113\n",
      "Epoch 157/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1375 - acc: 0.9471 - val_loss: 0.2814 - val_acc: 0.9032\n",
      "Epoch 158/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1429 - acc: 0.9479 - val_loss: 0.2742 - val_acc: 0.9081\n",
      "Epoch 159/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1379 - acc: 0.9471 - val_loss: 0.2886 - val_acc: 0.9048\n",
      "Epoch 160/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1409 - acc: 0.9451 - val_loss: 0.2738 - val_acc: 0.9065\n",
      "Epoch 161/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1396 - acc: 0.9495 - val_loss: 0.2576 - val_acc: 0.9113\n",
      "Epoch 162/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1356 - acc: 0.9512 - val_loss: 0.2691 - val_acc: 0.9097\n",
      "Epoch 163/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1347 - acc: 0.9503 - val_loss: 0.2746 - val_acc: 0.9081\n",
      "Epoch 164/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1450 - acc: 0.9447 - val_loss: 0.2806 - val_acc: 0.9081\n",
      "Epoch 165/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1329 - acc: 0.9487 - val_loss: 0.2764 - val_acc: 0.9065\n",
      "Epoch 166/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1352 - acc: 0.9487 - val_loss: 0.2860 - val_acc: 0.9032\n",
      "Epoch 167/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1319 - acc: 0.9507 - val_loss: 0.2767 - val_acc: 0.9113\n",
      "Epoch 168/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1328 - acc: 0.9516 - val_loss: 0.3144 - val_acc: 0.9032\n",
      "Epoch 169/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1372 - acc: 0.9528 - val_loss: 0.2755 - val_acc: 0.9097\n",
      "Epoch 170/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1342 - acc: 0.9503 - val_loss: 0.2844 - val_acc: 0.9016\n",
      "Epoch 171/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1296 - acc: 0.9520 - val_loss: 0.2845 - val_acc: 0.9081\n",
      "Epoch 172/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1255 - acc: 0.9536 - val_loss: 0.2824 - val_acc: 0.9081\n",
      "Epoch 173/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1232 - acc: 0.9564 - val_loss: 0.2949 - val_acc: 0.9081\n",
      "Epoch 174/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1283 - acc: 0.9499 - val_loss: 0.2968 - val_acc: 0.9097\n",
      "Epoch 175/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1301 - acc: 0.9491 - val_loss: 0.3021 - val_acc: 0.9048\n",
      "Epoch 176/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1282 - acc: 0.9524 - val_loss: 0.3087 - val_acc: 0.9032\n",
      "Epoch 177/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1321 - acc: 0.9483 - val_loss: 0.2990 - val_acc: 0.9081\n",
      "Epoch 178/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1334 - acc: 0.9495 - val_loss: 0.2982 - val_acc: 0.9065\n",
      "Epoch 179/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.1339 - acc: 0.9495 - val_loss: 0.2699 - val_acc: 0.9113\n",
      "Epoch 180/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1346 - acc: 0.9483 - val_loss: 0.2925 - val_acc: 0.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1241 - acc: 0.9544 - val_loss: 0.2823 - val_acc: 0.9048\n",
      "Epoch 182/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1244 - acc: 0.9528 - val_loss: 0.2966 - val_acc: 0.9081\n",
      "Epoch 183/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1191 - acc: 0.9556 - val_loss: 0.3213 - val_acc: 0.9000\n",
      "Epoch 184/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1201 - acc: 0.9552 - val_loss: 0.3016 - val_acc: 0.9016\n",
      "Epoch 185/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1247 - acc: 0.9528 - val_loss: 0.3104 - val_acc: 0.9048\n",
      "Epoch 186/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1279 - acc: 0.9528 - val_loss: 0.2955 - val_acc: 0.9032\n",
      "Epoch 187/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1240 - acc: 0.9540 - val_loss: 0.3052 - val_acc: 0.9065\n",
      "Epoch 188/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1184 - acc: 0.9580 - val_loss: 0.2914 - val_acc: 0.9000\n",
      "Epoch 189/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1167 - acc: 0.9556 - val_loss: 0.3084 - val_acc: 0.9081\n",
      "Epoch 190/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1292 - acc: 0.9524 - val_loss: 0.3162 - val_acc: 0.8968\n",
      "Epoch 191/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1249 - acc: 0.9560 - val_loss: 0.3216 - val_acc: 0.9000\n",
      "Epoch 192/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1150 - acc: 0.9560 - val_loss: 0.3218 - val_acc: 0.8984\n",
      "Epoch 193/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1147 - acc: 0.9580 - val_loss: 0.3168 - val_acc: 0.9048\n",
      "Epoch 194/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1201 - acc: 0.9572 - val_loss: 0.3111 - val_acc: 0.9032\n",
      "Epoch 195/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1157 - acc: 0.9580 - val_loss: 0.3166 - val_acc: 0.9016\n",
      "Epoch 196/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1201 - acc: 0.9536 - val_loss: 0.3185 - val_acc: 0.9016\n",
      "Epoch 197/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1164 - acc: 0.9548 - val_loss: 0.3184 - val_acc: 0.9065\n",
      "Epoch 198/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1091 - acc: 0.9608 - val_loss: 0.3306 - val_acc: 0.8968\n",
      "Epoch 199/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1204 - acc: 0.9491 - val_loss: 0.3467 - val_acc: 0.9000\n",
      "Epoch 200/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1156 - acc: 0.9544 - val_loss: 0.3087 - val_acc: 0.9081\n",
      "Epoch 201/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1093 - acc: 0.9616 - val_loss: 0.3298 - val_acc: 0.9048\n",
      "Epoch 202/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1082 - acc: 0.9600 - val_loss: 0.3387 - val_acc: 0.9000\n",
      "Epoch 203/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1197 - acc: 0.9568 - val_loss: 0.3150 - val_acc: 0.9081\n",
      "Epoch 204/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1252 - acc: 0.9540 - val_loss: 0.3085 - val_acc: 0.9065\n",
      "Epoch 205/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1091 - acc: 0.9612 - val_loss: 0.3279 - val_acc: 0.9065\n",
      "Epoch 206/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1088 - acc: 0.9596 - val_loss: 0.3682 - val_acc: 0.9000\n",
      "Epoch 207/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1178 - acc: 0.9560 - val_loss: 0.3032 - val_acc: 0.9129\n",
      "Epoch 208/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1100 - acc: 0.9600 - val_loss: 0.3234 - val_acc: 0.9097\n",
      "Epoch 209/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1075 - acc: 0.9580 - val_loss: 0.3418 - val_acc: 0.9000\n",
      "Epoch 210/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1028 - acc: 0.9621 - val_loss: 0.3208 - val_acc: 0.9081\n",
      "Epoch 211/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1118 - acc: 0.9592 - val_loss: 0.3181 - val_acc: 0.9097\n",
      "Epoch 212/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1087 - acc: 0.9612 - val_loss: 0.3446 - val_acc: 0.9065\n",
      "Epoch 213/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1058 - acc: 0.9633 - val_loss: 0.3373 - val_acc: 0.9081\n",
      "Epoch 214/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1094 - acc: 0.9596 - val_loss: 0.3379 - val_acc: 0.9048\n",
      "Epoch 215/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1039 - acc: 0.9621 - val_loss: 0.3380 - val_acc: 0.9065\n",
      "Epoch 216/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1085 - acc: 0.9588 - val_loss: 0.3351 - val_acc: 0.9129\n",
      "Epoch 217/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1139 - acc: 0.9552 - val_loss: 0.3391 - val_acc: 0.9065\n",
      "Epoch 218/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0986 - acc: 0.9641 - val_loss: 0.3271 - val_acc: 0.9097\n",
      "Epoch 219/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1003 - acc: 0.9641 - val_loss: 0.3740 - val_acc: 0.8968\n",
      "Epoch 220/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1017 - acc: 0.9657 - val_loss: 0.3282 - val_acc: 0.9048\n",
      "Epoch 221/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0994 - acc: 0.9592 - val_loss: 0.3389 - val_acc: 0.9048\n",
      "Epoch 222/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1015 - acc: 0.9641 - val_loss: 0.3469 - val_acc: 0.9081\n",
      "Epoch 223/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1056 - acc: 0.9616 - val_loss: 0.3293 - val_acc: 0.9048\n",
      "Epoch 224/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0931 - acc: 0.9621 - val_loss: 0.3852 - val_acc: 0.9065\n",
      "Epoch 225/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0998 - acc: 0.9616 - val_loss: 0.3444 - val_acc: 0.9016\n",
      "Epoch 226/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0954 - acc: 0.9669 - val_loss: 0.3291 - val_acc: 0.9048\n",
      "Epoch 227/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1024 - acc: 0.9625 - val_loss: 0.3597 - val_acc: 0.9081\n",
      "Epoch 228/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0939 - acc: 0.9629 - val_loss: 0.3749 - val_acc: 0.9032\n",
      "Epoch 229/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1024 - acc: 0.9616 - val_loss: 0.3620 - val_acc: 0.9032\n",
      "Epoch 230/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1065 - acc: 0.9584 - val_loss: 0.3593 - val_acc: 0.9032\n",
      "Epoch 231/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0942 - acc: 0.9645 - val_loss: 0.3678 - val_acc: 0.9032\n",
      "Epoch 232/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1020 - acc: 0.9633 - val_loss: 0.3941 - val_acc: 0.8984\n",
      "Epoch 233/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0970 - acc: 0.9673 - val_loss: 0.3844 - val_acc: 0.9081\n",
      "Epoch 234/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0977 - acc: 0.9629 - val_loss: 0.3695 - val_acc: 0.8968\n",
      "Epoch 235/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0995 - acc: 0.9649 - val_loss: 0.3993 - val_acc: 0.9016\n",
      "Epoch 236/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.1005 - acc: 0.9616 - val_loss: 0.3739 - val_acc: 0.9000\n",
      "Epoch 237/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0912 - acc: 0.9669 - val_loss: 0.3854 - val_acc: 0.9016\n",
      "Epoch 238/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0943 - acc: 0.9625 - val_loss: 0.3700 - val_acc: 0.8935\n",
      "Epoch 239/300\n",
      "2477/2477 [==============================] - 5s 2ms/step - loss: 0.0893 - acc: 0.9665 - val_loss: 0.3955 - val_acc: 0.9081\n",
      "Epoch 240/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0978 - acc: 0.9604 - val_loss: 0.3583 - val_acc: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0944 - acc: 0.9641 - val_loss: 0.3992 - val_acc: 0.8984\n",
      "Epoch 242/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0880 - acc: 0.9673 - val_loss: 0.3710 - val_acc: 0.9081\n",
      "Epoch 243/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0876 - acc: 0.9689 - val_loss: 0.4140 - val_acc: 0.8952\n",
      "Epoch 244/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0887 - acc: 0.9657 - val_loss: 0.3991 - val_acc: 0.9048\n",
      "Epoch 245/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0903 - acc: 0.9653 - val_loss: 0.4064 - val_acc: 0.9000\n",
      "Epoch 246/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.1002 - acc: 0.9612 - val_loss: 0.3732 - val_acc: 0.9081\n",
      "Epoch 247/300\n",
      "2477/2477 [==============================] - 6s 3ms/step - loss: 0.0978 - acc: 0.9669 - val_loss: 0.4020 - val_acc: 0.9016\n",
      "Epoch 248/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0877 - acc: 0.9665 - val_loss: 0.3997 - val_acc: 0.8952\n",
      "Epoch 249/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0847 - acc: 0.9665 - val_loss: 0.4302 - val_acc: 0.8968\n",
      "Epoch 250/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0820 - acc: 0.9713 - val_loss: 0.3930 - val_acc: 0.9032\n",
      "Epoch 251/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0909 - acc: 0.9681 - val_loss: 0.4031 - val_acc: 0.9048\n",
      "Epoch 252/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0896 - acc: 0.9665 - val_loss: 0.4006 - val_acc: 0.9065\n",
      "Epoch 253/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0810 - acc: 0.9713 - val_loss: 0.4572 - val_acc: 0.8984\n",
      "Epoch 254/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0902 - acc: 0.9697 - val_loss: 0.4074 - val_acc: 0.9081\n",
      "Epoch 255/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0871 - acc: 0.9653 - val_loss: 0.3961 - val_acc: 0.9016\n",
      "Epoch 256/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0941 - acc: 0.9645 - val_loss: 0.4027 - val_acc: 0.9048\n",
      "Epoch 257/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.1065 - acc: 0.9637 - val_loss: 0.4012 - val_acc: 0.9000\n",
      "Epoch 258/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0825 - acc: 0.9685 - val_loss: 0.3921 - val_acc: 0.9065\n",
      "Epoch 259/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0826 - acc: 0.9693 - val_loss: 0.4125 - val_acc: 0.9000\n",
      "Epoch 260/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0787 - acc: 0.9734 - val_loss: 0.4228 - val_acc: 0.9048\n",
      "Epoch 261/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0878 - acc: 0.9657 - val_loss: 0.4248 - val_acc: 0.8984\n",
      "Epoch 262/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0790 - acc: 0.9730 - val_loss: 0.4285 - val_acc: 0.9032\n",
      "Epoch 263/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0817 - acc: 0.9697 - val_loss: 0.4920 - val_acc: 0.8903\n",
      "Epoch 264/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0867 - acc: 0.9689 - val_loss: 0.4570 - val_acc: 0.9048\n",
      "Epoch 265/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0818 - acc: 0.9713 - val_loss: 0.4350 - val_acc: 0.9016\n",
      "Epoch 266/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0789 - acc: 0.9705 - val_loss: 0.4516 - val_acc: 0.8984\n",
      "Epoch 267/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0750 - acc: 0.9717 - val_loss: 0.4386 - val_acc: 0.9032\n",
      "Epoch 268/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0755 - acc: 0.9709 - val_loss: 0.4321 - val_acc: 0.9032\n",
      "Epoch 269/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0738 - acc: 0.9766 - val_loss: 0.4500 - val_acc: 0.9000\n",
      "Epoch 270/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0738 - acc: 0.9754 - val_loss: 0.4610 - val_acc: 0.9016\n",
      "Epoch 271/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0770 - acc: 0.9709 - val_loss: 0.4993 - val_acc: 0.8952\n",
      "Epoch 272/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0717 - acc: 0.9738 - val_loss: 0.4779 - val_acc: 0.8984\n",
      "Epoch 273/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0875 - acc: 0.9701 - val_loss: 0.4677 - val_acc: 0.9016\n",
      "Epoch 274/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0925 - acc: 0.9653 - val_loss: 0.4150 - val_acc: 0.9048\n",
      "Epoch 275/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0781 - acc: 0.9725 - val_loss: 0.4197 - val_acc: 0.9048\n",
      "Epoch 276/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0929 - acc: 0.9653 - val_loss: 0.4567 - val_acc: 0.8935\n",
      "Epoch 277/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0848 - acc: 0.9681 - val_loss: 0.4549 - val_acc: 0.9016\n",
      "Epoch 278/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0741 - acc: 0.9742 - val_loss: 0.4670 - val_acc: 0.8984\n",
      "Epoch 279/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0755 - acc: 0.9730 - val_loss: 0.4391 - val_acc: 0.9065\n",
      "Epoch 280/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0680 - acc: 0.9750 - val_loss: 0.5083 - val_acc: 0.8984\n",
      "Epoch 281/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0747 - acc: 0.9730 - val_loss: 0.4625 - val_acc: 0.9000\n",
      "Epoch 282/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0729 - acc: 0.9721 - val_loss: 0.4548 - val_acc: 0.8984\n",
      "Epoch 283/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0682 - acc: 0.9766 - val_loss: 0.4957 - val_acc: 0.9000\n",
      "Epoch 284/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0799 - acc: 0.9689 - val_loss: 0.4705 - val_acc: 0.8968\n",
      "Epoch 285/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0718 - acc: 0.9705 - val_loss: 0.4368 - val_acc: 0.9048\n",
      "Epoch 286/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0680 - acc: 0.9738 - val_loss: 0.4895 - val_acc: 0.9065\n",
      "Epoch 287/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0648 - acc: 0.9774 - val_loss: 0.4942 - val_acc: 0.9032\n",
      "Epoch 288/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0723 - acc: 0.9730 - val_loss: 0.4896 - val_acc: 0.8952\n",
      "Epoch 289/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0804 - acc: 0.9677 - val_loss: 0.5413 - val_acc: 0.9032\n",
      "Epoch 290/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0794 - acc: 0.9697 - val_loss: 0.4493 - val_acc: 0.9016\n",
      "Epoch 291/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0753 - acc: 0.9725 - val_loss: 0.4860 - val_acc: 0.9032\n",
      "Epoch 292/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0698 - acc: 0.9734 - val_loss: 0.4608 - val_acc: 0.9048\n",
      "Epoch 293/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0745 - acc: 0.9746 - val_loss: 0.5097 - val_acc: 0.9048\n",
      "Epoch 294/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0694 - acc: 0.9774 - val_loss: 0.5216 - val_acc: 0.8952\n",
      "Epoch 295/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0674 - acc: 0.9758 - val_loss: 0.5151 - val_acc: 0.9016\n",
      "Epoch 296/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0814 - acc: 0.9701 - val_loss: 0.4199 - val_acc: 0.8968\n",
      "Epoch 297/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0820 - acc: 0.9705 - val_loss: 0.4777 - val_acc: 0.9048\n",
      "Epoch 298/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0708 - acc: 0.9725 - val_loss: 0.5086 - val_acc: 0.9016\n",
      "Epoch 299/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0715 - acc: 0.9746 - val_loss: 0.4822 - val_acc: 0.9016\n",
      "Epoch 300/300\n",
      "2477/2477 [==============================] - 6s 2ms/step - loss: 0.0691 - acc: 0.9754 - val_loss: 0.4734 - val_acc: 0.9065\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model_BLSTM_train = model_BLSTM.fit(train_X, train_Y, epochs=epochs, batch_size=32, validation_data=(valid_X, valid_Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELM_s Result\n",
      "Accuracy : 0.9064516129032258\n",
      "AUC : 0.9056859393888866\n",
      "Sensitivity : 0.9254658385093167\n",
      "Specificity : 0.8859060402684564\n",
      "F1 : 0.91131498470948\n",
      "MCC : 0.8128131733108196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the training accuracy\n",
    "accuracy = model_BLSTM_train.history['acc']\n",
    "val_accuracy = model_BLSTM_train.history['val_acc']\n",
    "loss = model_BLSTM_train.history['loss']\n",
    "val_loss = model_BLSTM_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('BSTM Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('BLSTM Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pred = np.argmax(model_BLSTM.predict(valid_X), axis=1)\n",
    "y_true = np.argmax(valid_Y, axis = 1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "f1 = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "auc = roc_auc_score(y_true, y_pred, average='macro', sample_weight=None, max_fpr=None)\n",
    "sensi = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "accu = (tn + tp)/(tn + tp + fn + fp)\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print('{} Result'.format(string_name))\n",
    "print('Accuracy :', accu)\n",
    "print('AUC :', auc)\n",
    "print('Sensitivity :', sensi)\n",
    "print('Specificity :', specificity)\n",
    "print('F1 :', f1)\n",
    "print('MCC :', mcc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2477 samples, validate on 620 samples\n",
      "Epoch 1/300\n",
      "2477/2477 [==============================] - 7s 3ms/step - loss: 0.4267 - acc: 0.7909 - val_loss: 0.2572 - val_acc: 0.8823\n",
      "Epoch 2/300\n",
      "2477/2477 [==============================] - 1s 227us/step - loss: 0.2560 - acc: 0.8946 - val_loss: 0.2259 - val_acc: 0.9177\n",
      "Epoch 3/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2390 - acc: 0.9067 - val_loss: 0.2249 - val_acc: 0.9145\n",
      "Epoch 4/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2438 - acc: 0.9019 - val_loss: 0.2254 - val_acc: 0.9194\n",
      "Epoch 5/300\n",
      "2477/2477 [==============================] - 1s 228us/step - loss: 0.2364 - acc: 0.9055 - val_loss: 0.2126 - val_acc: 0.9210\n",
      "Epoch 6/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2277 - acc: 0.9112 - val_loss: 0.2120 - val_acc: 0.9242\n",
      "Epoch 7/300\n",
      "2477/2477 [==============================] - 1s 228us/step - loss: 0.2263 - acc: 0.9043 - val_loss: 0.2197 - val_acc: 0.9161\n",
      "Epoch 8/300\n",
      "2477/2477 [==============================] - 1s 246us/step - loss: 0.2182 - acc: 0.9124 - val_loss: 0.2171 - val_acc: 0.9177\n",
      "Epoch 9/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2224 - acc: 0.9104 - val_loss: 0.2080 - val_acc: 0.9226\n",
      "Epoch 10/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2330 - acc: 0.9092 - val_loss: 0.2023 - val_acc: 0.9274\n",
      "Epoch 11/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2267 - acc: 0.9096 - val_loss: 0.2153 - val_acc: 0.9194\n",
      "Epoch 12/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2296 - acc: 0.9063 - val_loss: 0.2468 - val_acc: 0.9000\n",
      "Epoch 13/300\n",
      "2477/2477 [==============================] - 1s 257us/step - loss: 0.2229 - acc: 0.9124 - val_loss: 0.2115 - val_acc: 0.9129\n",
      "Epoch 14/300\n",
      "2477/2477 [==============================] - 1s 246us/step - loss: 0.2264 - acc: 0.9088 - val_loss: 0.2078 - val_acc: 0.9194\n",
      "Epoch 15/300\n",
      "2477/2477 [==============================] - 1s 242us/step - loss: 0.2176 - acc: 0.9184 - val_loss: 0.2013 - val_acc: 0.9210\n",
      "Epoch 16/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2219 - acc: 0.9100 - val_loss: 0.2018 - val_acc: 0.9210\n",
      "Epoch 17/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2291 - acc: 0.9080 - val_loss: 0.1984 - val_acc: 0.9226\n",
      "Epoch 18/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2157 - acc: 0.9152 - val_loss: 0.2070 - val_acc: 0.9177\n",
      "Epoch 19/300\n",
      "2477/2477 [==============================] - 1s 233us/step - loss: 0.2238 - acc: 0.9140 - val_loss: 0.2249 - val_acc: 0.9290\n",
      "Epoch 20/300\n",
      "2477/2477 [==============================] - 1s 236us/step - loss: 0.2225 - acc: 0.9116 - val_loss: 0.2088 - val_acc: 0.9145\n",
      "Epoch 21/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2221 - acc: 0.9088 - val_loss: 0.2111 - val_acc: 0.9194\n",
      "Epoch 22/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2241 - acc: 0.9096 - val_loss: 0.2094 - val_acc: 0.9210\n",
      "Epoch 23/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2224 - acc: 0.9108 - val_loss: 0.2103 - val_acc: 0.9258\n",
      "Epoch 24/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2193 - acc: 0.9160 - val_loss: 0.2354 - val_acc: 0.9113\n",
      "Epoch 25/300\n",
      "2477/2477 [==============================] - 1s 233us/step - loss: 0.2225 - acc: 0.9128 - val_loss: 0.2082 - val_acc: 0.9210\n",
      "Epoch 26/300\n",
      "2477/2477 [==============================] - 1s 235us/step - loss: 0.2217 - acc: 0.9164 - val_loss: 0.2159 - val_acc: 0.9177\n",
      "Epoch 27/300\n",
      "2477/2477 [==============================] - 1s 233us/step - loss: 0.2210 - acc: 0.9092 - val_loss: 0.2095 - val_acc: 0.9258\n",
      "Epoch 28/300\n",
      "2477/2477 [==============================] - 1s 247us/step - loss: 0.2269 - acc: 0.9116 - val_loss: 0.2053 - val_acc: 0.9242\n",
      "Epoch 29/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2162 - acc: 0.9124 - val_loss: 0.2075 - val_acc: 0.9258\n",
      "Epoch 30/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2221 - acc: 0.9120 - val_loss: 0.2094 - val_acc: 0.9242\n",
      "Epoch 31/300\n",
      "2477/2477 [==============================] - 1s 234us/step - loss: 0.2220 - acc: 0.9100 - val_loss: 0.2310 - val_acc: 0.9065\n",
      "Epoch 32/300\n",
      "2477/2477 [==============================] - 1s 236us/step - loss: 0.2145 - acc: 0.9132 - val_loss: 0.2264 - val_acc: 0.8968\n",
      "Epoch 33/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2157 - acc: 0.9156 - val_loss: 0.2038 - val_acc: 0.9226\n",
      "Epoch 34/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2176 - acc: 0.9116 - val_loss: 0.2009 - val_acc: 0.9194\n",
      "Epoch 35/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2164 - acc: 0.9156 - val_loss: 0.2096 - val_acc: 0.9210\n",
      "Epoch 36/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2198 - acc: 0.9120 - val_loss: 0.2020 - val_acc: 0.9306\n",
      "Epoch 37/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2149 - acc: 0.9193 - val_loss: 0.2053 - val_acc: 0.9210\n",
      "Epoch 38/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2152 - acc: 0.9140 - val_loss: 0.2004 - val_acc: 0.9242\n",
      "Epoch 39/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2148 - acc: 0.9148 - val_loss: 0.2060 - val_acc: 0.9161\n",
      "Epoch 40/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2187 - acc: 0.9096 - val_loss: 0.2082 - val_acc: 0.9161\n",
      "Epoch 41/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2184 - acc: 0.9112 - val_loss: 0.2013 - val_acc: 0.9258\n",
      "Epoch 42/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2157 - acc: 0.9144 - val_loss: 0.2133 - val_acc: 0.9274\n",
      "Epoch 43/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2215 - acc: 0.9160 - val_loss: 0.2030 - val_acc: 0.9258\n",
      "Epoch 44/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2172 - acc: 0.9120 - val_loss: 0.2023 - val_acc: 0.9210\n",
      "Epoch 45/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2148 - acc: 0.9193 - val_loss: 0.2132 - val_acc: 0.9258\n",
      "Epoch 46/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2199 - acc: 0.9112 - val_loss: 0.2641 - val_acc: 0.9032\n",
      "Epoch 47/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2210 - acc: 0.9112 - val_loss: 0.2012 - val_acc: 0.9274\n",
      "Epoch 48/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2172 - acc: 0.9197 - val_loss: 0.2144 - val_acc: 0.9242\n",
      "Epoch 49/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2176 - acc: 0.9152 - val_loss: 0.2140 - val_acc: 0.9242\n",
      "Epoch 50/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2257 - acc: 0.9168 - val_loss: 0.2079 - val_acc: 0.9258\n",
      "Epoch 51/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2174 - acc: 0.9168 - val_loss: 0.2121 - val_acc: 0.9226\n",
      "Epoch 52/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2155 - acc: 0.9140 - val_loss: 0.2140 - val_acc: 0.9177\n",
      "Epoch 53/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2136 - acc: 0.9116 - val_loss: 0.2133 - val_acc: 0.9274\n",
      "Epoch 54/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2164 - acc: 0.9144 - val_loss: 0.2218 - val_acc: 0.9129\n",
      "Epoch 55/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2162 - acc: 0.9180 - val_loss: 0.2003 - val_acc: 0.9258\n",
      "Epoch 56/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2186 - acc: 0.9156 - val_loss: 0.2103 - val_acc: 0.9258\n",
      "Epoch 57/300\n",
      "2477/2477 [==============================] - 1s 241us/step - loss: 0.2174 - acc: 0.9193 - val_loss: 0.2099 - val_acc: 0.9226\n",
      "Epoch 58/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2161 - acc: 0.9152 - val_loss: 0.2052 - val_acc: 0.9210\n",
      "Epoch 59/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2227 - acc: 0.9144 - val_loss: 0.2125 - val_acc: 0.9258\n",
      "Epoch 60/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2208 - acc: 0.9128 - val_loss: 0.2048 - val_acc: 0.9242\n",
      "Epoch 61/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2244 - acc: 0.9116 - val_loss: 0.1997 - val_acc: 0.9290\n",
      "Epoch 62/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2179 - acc: 0.9184 - val_loss: 0.1992 - val_acc: 0.9258\n",
      "Epoch 63/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2173 - acc: 0.9152 - val_loss: 0.2147 - val_acc: 0.9290\n",
      "Epoch 64/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2156 - acc: 0.9144 - val_loss: 0.2140 - val_acc: 0.9242\n",
      "Epoch 65/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2158 - acc: 0.9152 - val_loss: 0.2288 - val_acc: 0.9113\n",
      "Epoch 66/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2190 - acc: 0.9116 - val_loss: 0.2061 - val_acc: 0.9290\n",
      "Epoch 67/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2185 - acc: 0.9189 - val_loss: 0.2314 - val_acc: 0.9226\n",
      "Epoch 68/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2151 - acc: 0.9172 - val_loss: 0.2008 - val_acc: 0.9242\n",
      "Epoch 69/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2191 - acc: 0.9148 - val_loss: 0.2039 - val_acc: 0.9210\n",
      "Epoch 70/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2155 - acc: 0.9132 - val_loss: 0.2044 - val_acc: 0.9210\n",
      "Epoch 71/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2202 - acc: 0.9128 - val_loss: 0.2217 - val_acc: 0.9194\n",
      "Epoch 72/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2196 - acc: 0.9156 - val_loss: 0.2028 - val_acc: 0.9242\n",
      "Epoch 73/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2178 - acc: 0.9144 - val_loss: 0.2095 - val_acc: 0.9161\n",
      "Epoch 74/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2174 - acc: 0.9144 - val_loss: 0.2035 - val_acc: 0.9290\n",
      "Epoch 75/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2170 - acc: 0.9100 - val_loss: 0.2072 - val_acc: 0.9258\n",
      "Epoch 76/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2172 - acc: 0.9156 - val_loss: 0.2136 - val_acc: 0.9177\n",
      "Epoch 77/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2120 - acc: 0.9136 - val_loss: 0.2017 - val_acc: 0.9242\n",
      "Epoch 78/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2126 - acc: 0.9116 - val_loss: 0.2106 - val_acc: 0.9274\n",
      "Epoch 79/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2164 - acc: 0.9197 - val_loss: 0.2072 - val_acc: 0.9194\n",
      "Epoch 80/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2152 - acc: 0.9116 - val_loss: 0.2169 - val_acc: 0.9177\n",
      "Epoch 81/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2127 - acc: 0.9180 - val_loss: 0.2114 - val_acc: 0.9194\n",
      "Epoch 82/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2161 - acc: 0.9096 - val_loss: 0.2098 - val_acc: 0.9210\n",
      "Epoch 83/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2140 - acc: 0.9156 - val_loss: 0.1994 - val_acc: 0.9258\n",
      "Epoch 84/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2148 - acc: 0.9120 - val_loss: 0.2021 - val_acc: 0.9258\n",
      "Epoch 85/300\n",
      "2477/2477 [==============================] - 1s 232us/step - loss: 0.2139 - acc: 0.9180 - val_loss: 0.2041 - val_acc: 0.9194\n",
      "Epoch 86/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2157 - acc: 0.9116 - val_loss: 0.2087 - val_acc: 0.9210\n",
      "Epoch 87/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2149 - acc: 0.9148 - val_loss: 0.2018 - val_acc: 0.9210\n",
      "Epoch 88/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2166 - acc: 0.9156 - val_loss: 0.2000 - val_acc: 0.9226\n",
      "Epoch 89/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2159 - acc: 0.9168 - val_loss: 0.1977 - val_acc: 0.9306\n",
      "Epoch 90/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2214 - acc: 0.9071 - val_loss: 0.2222 - val_acc: 0.9177\n",
      "Epoch 91/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2149 - acc: 0.9156 - val_loss: 0.1975 - val_acc: 0.9290\n",
      "Epoch 92/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2173 - acc: 0.9124 - val_loss: 0.2029 - val_acc: 0.9258\n",
      "Epoch 93/300\n",
      "2477/2477 [==============================] - 1s 235us/step - loss: 0.2134 - acc: 0.9164 - val_loss: 0.2009 - val_acc: 0.9258\n",
      "Epoch 94/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2133 - acc: 0.9164 - val_loss: 0.2043 - val_acc: 0.9226\n",
      "Epoch 95/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2163 - acc: 0.9144 - val_loss: 0.2050 - val_acc: 0.9290\n",
      "Epoch 96/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2158 - acc: 0.9144 - val_loss: 0.2033 - val_acc: 0.9210\n",
      "Epoch 97/300\n",
      "2477/2477 [==============================] - 1s 232us/step - loss: 0.2111 - acc: 0.9144 - val_loss: 0.2054 - val_acc: 0.9242\n",
      "Epoch 98/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2170 - acc: 0.9132 - val_loss: 0.2124 - val_acc: 0.9290\n",
      "Epoch 99/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2140 - acc: 0.9184 - val_loss: 0.2089 - val_acc: 0.9242\n",
      "Epoch 100/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2155 - acc: 0.9184 - val_loss: 0.2060 - val_acc: 0.9226\n",
      "Epoch 101/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2159 - acc: 0.9116 - val_loss: 0.2050 - val_acc: 0.9210\n",
      "Epoch 102/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2144 - acc: 0.9189 - val_loss: 0.2059 - val_acc: 0.9194\n",
      "Epoch 103/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2175 - acc: 0.9112 - val_loss: 0.2073 - val_acc: 0.9274\n",
      "Epoch 104/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2147 - acc: 0.9164 - val_loss: 0.2050 - val_acc: 0.9274\n",
      "Epoch 105/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2167 - acc: 0.9152 - val_loss: 0.2062 - val_acc: 0.9274\n",
      "Epoch 106/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2148 - acc: 0.9180 - val_loss: 0.1996 - val_acc: 0.9274\n",
      "Epoch 107/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2143 - acc: 0.9168 - val_loss: 0.2060 - val_acc: 0.9258\n",
      "Epoch 108/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2141 - acc: 0.9176 - val_loss: 0.2224 - val_acc: 0.9226\n",
      "Epoch 109/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2167 - acc: 0.9116 - val_loss: 0.2081 - val_acc: 0.9210\n",
      "Epoch 110/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2102 - acc: 0.9136 - val_loss: 0.2047 - val_acc: 0.9258\n",
      "Epoch 111/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2157 - acc: 0.9152 - val_loss: 0.2181 - val_acc: 0.9242\n",
      "Epoch 112/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2123 - acc: 0.9156 - val_loss: 0.1997 - val_acc: 0.9274\n",
      "Epoch 113/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2184 - acc: 0.9128 - val_loss: 0.2155 - val_acc: 0.9323\n",
      "Epoch 114/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2166 - acc: 0.9136 - val_loss: 0.2015 - val_acc: 0.9194\n",
      "Epoch 115/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2184 - acc: 0.9136 - val_loss: 0.2023 - val_acc: 0.9226\n",
      "Epoch 116/300\n",
      "2477/2477 [==============================] - 1s 228us/step - loss: 0.2122 - acc: 0.9193 - val_loss: 0.2073 - val_acc: 0.9242\n",
      "Epoch 117/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2183 - acc: 0.9144 - val_loss: 0.2004 - val_acc: 0.9226\n",
      "Epoch 118/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2148 - acc: 0.9176 - val_loss: 0.1983 - val_acc: 0.9226\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2157 - acc: 0.9140 - val_loss: 0.1979 - val_acc: 0.9274\n",
      "Epoch 120/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2126 - acc: 0.9148 - val_loss: 0.2009 - val_acc: 0.9242\n",
      "Epoch 121/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2146 - acc: 0.9168 - val_loss: 0.2055 - val_acc: 0.9161\n",
      "Epoch 122/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2121 - acc: 0.9140 - val_loss: 0.2106 - val_acc: 0.9290\n",
      "Epoch 123/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2136 - acc: 0.9120 - val_loss: 0.2032 - val_acc: 0.9242\n",
      "Epoch 124/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2153 - acc: 0.9152 - val_loss: 0.2011 - val_acc: 0.9258\n",
      "Epoch 125/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2138 - acc: 0.9156 - val_loss: 0.2068 - val_acc: 0.9226\n",
      "Epoch 126/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2119 - acc: 0.9176 - val_loss: 0.2061 - val_acc: 0.9194\n",
      "Epoch 127/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2159 - acc: 0.9144 - val_loss: 0.1987 - val_acc: 0.9306\n",
      "Epoch 128/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2150 - acc: 0.9193 - val_loss: 0.2063 - val_acc: 0.9194\n",
      "Epoch 129/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2147 - acc: 0.9156 - val_loss: 0.2028 - val_acc: 0.9226\n",
      "Epoch 130/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2128 - acc: 0.9124 - val_loss: 0.2109 - val_acc: 0.9210\n",
      "Epoch 131/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2130 - acc: 0.9144 - val_loss: 0.2061 - val_acc: 0.9226\n",
      "Epoch 132/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2154 - acc: 0.9132 - val_loss: 0.2067 - val_acc: 0.9210\n",
      "Epoch 133/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2170 - acc: 0.9156 - val_loss: 0.2172 - val_acc: 0.9258\n",
      "Epoch 134/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2156 - acc: 0.9140 - val_loss: 0.2063 - val_acc: 0.9242\n",
      "Epoch 135/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2121 - acc: 0.9148 - val_loss: 0.2032 - val_acc: 0.9194\n",
      "Epoch 136/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2165 - acc: 0.9132 - val_loss: 0.2015 - val_acc: 0.9258\n",
      "Epoch 137/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2139 - acc: 0.9164 - val_loss: 0.2060 - val_acc: 0.9226\n",
      "Epoch 138/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2141 - acc: 0.9197 - val_loss: 0.2053 - val_acc: 0.9274\n",
      "Epoch 139/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2160 - acc: 0.9148 - val_loss: 0.2041 - val_acc: 0.9274\n",
      "Epoch 140/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2109 - acc: 0.9164 - val_loss: 0.2063 - val_acc: 0.9274\n",
      "Epoch 141/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2141 - acc: 0.9160 - val_loss: 0.2198 - val_acc: 0.9177\n",
      "Epoch 142/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2125 - acc: 0.9156 - val_loss: 0.2167 - val_acc: 0.9161\n",
      "Epoch 143/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2121 - acc: 0.9184 - val_loss: 0.1987 - val_acc: 0.9242\n",
      "Epoch 144/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2117 - acc: 0.9152 - val_loss: 0.2035 - val_acc: 0.9242\n",
      "Epoch 145/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2138 - acc: 0.9144 - val_loss: 0.2033 - val_acc: 0.9226\n",
      "Epoch 146/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2130 - acc: 0.9148 - val_loss: 0.2029 - val_acc: 0.9210\n",
      "Epoch 147/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2100 - acc: 0.9184 - val_loss: 0.2046 - val_acc: 0.9210\n",
      "Epoch 148/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2106 - acc: 0.9193 - val_loss: 0.2064 - val_acc: 0.9226\n",
      "Epoch 149/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2134 - acc: 0.9180 - val_loss: 0.2004 - val_acc: 0.9274\n",
      "Epoch 150/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2099 - acc: 0.9168 - val_loss: 0.2045 - val_acc: 0.9226\n",
      "Epoch 151/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2132 - acc: 0.9168 - val_loss: 0.2036 - val_acc: 0.9226\n",
      "Epoch 152/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2204 - acc: 0.9128 - val_loss: 0.1986 - val_acc: 0.9242\n",
      "Epoch 153/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2168 - acc: 0.9136 - val_loss: 0.1983 - val_acc: 0.9258\n",
      "Epoch 154/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2126 - acc: 0.9168 - val_loss: 0.2024 - val_acc: 0.9242\n",
      "Epoch 155/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2100 - acc: 0.9160 - val_loss: 0.2063 - val_acc: 0.9258\n",
      "Epoch 156/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2187 - acc: 0.9120 - val_loss: 0.2025 - val_acc: 0.9274\n",
      "Epoch 157/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2127 - acc: 0.9168 - val_loss: 0.2041 - val_acc: 0.9194\n",
      "Epoch 158/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2123 - acc: 0.9189 - val_loss: 0.2042 - val_acc: 0.9274\n",
      "Epoch 159/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2118 - acc: 0.9193 - val_loss: 0.2209 - val_acc: 0.9210\n",
      "Epoch 160/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2133 - acc: 0.9180 - val_loss: 0.2030 - val_acc: 0.9242\n",
      "Epoch 161/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2119 - acc: 0.9156 - val_loss: 0.2015 - val_acc: 0.9274\n",
      "Epoch 162/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2130 - acc: 0.9229 - val_loss: 0.2117 - val_acc: 0.9210\n",
      "Epoch 163/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2142 - acc: 0.9176 - val_loss: 0.2090 - val_acc: 0.9258\n",
      "Epoch 164/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2125 - acc: 0.9144 - val_loss: 0.1984 - val_acc: 0.9242\n",
      "Epoch 165/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2142 - acc: 0.9128 - val_loss: 0.2006 - val_acc: 0.9242\n",
      "Epoch 166/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2150 - acc: 0.9144 - val_loss: 0.2013 - val_acc: 0.9242\n",
      "Epoch 167/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2122 - acc: 0.9160 - val_loss: 0.2039 - val_acc: 0.9290\n",
      "Epoch 168/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2105 - acc: 0.9164 - val_loss: 0.2174 - val_acc: 0.9177\n",
      "Epoch 169/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2132 - acc: 0.9164 - val_loss: 0.2119 - val_acc: 0.9194\n",
      "Epoch 170/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2149 - acc: 0.9144 - val_loss: 0.2040 - val_acc: 0.9242\n",
      "Epoch 171/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2112 - acc: 0.9156 - val_loss: 0.2041 - val_acc: 0.9194\n",
      "Epoch 172/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2103 - acc: 0.9184 - val_loss: 0.2021 - val_acc: 0.9258\n",
      "Epoch 173/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2158 - acc: 0.9156 - val_loss: 0.2084 - val_acc: 0.9242\n",
      "Epoch 174/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2103 - acc: 0.9209 - val_loss: 0.1989 - val_acc: 0.9210\n",
      "Epoch 175/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2139 - acc: 0.9140 - val_loss: 0.1993 - val_acc: 0.9226\n",
      "Epoch 176/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2139 - acc: 0.9217 - val_loss: 0.2018 - val_acc: 0.9258\n",
      "Epoch 177/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2135 - acc: 0.9197 - val_loss: 0.2014 - val_acc: 0.9242\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2141 - acc: 0.9152 - val_loss: 0.2063 - val_acc: 0.9226\n",
      "Epoch 179/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2140 - acc: 0.9156 - val_loss: 0.2004 - val_acc: 0.9274\n",
      "Epoch 180/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2140 - acc: 0.9128 - val_loss: 0.1979 - val_acc: 0.9274\n",
      "Epoch 181/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2129 - acc: 0.9193 - val_loss: 0.2061 - val_acc: 0.9274\n",
      "Epoch 182/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2135 - acc: 0.9168 - val_loss: 0.2120 - val_acc: 0.9242\n",
      "Epoch 183/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2117 - acc: 0.9184 - val_loss: 0.1993 - val_acc: 0.9242\n",
      "Epoch 184/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2133 - acc: 0.9180 - val_loss: 0.2214 - val_acc: 0.9194\n",
      "Epoch 185/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2132 - acc: 0.9197 - val_loss: 0.2192 - val_acc: 0.9242\n",
      "Epoch 186/300\n",
      "2477/2477 [==============================] - 1s 252us/step - loss: 0.2132 - acc: 0.9164 - val_loss: 0.2000 - val_acc: 0.9242\n",
      "Epoch 187/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2143 - acc: 0.9168 - val_loss: 0.2063 - val_acc: 0.9177\n",
      "Epoch 188/300\n",
      "2477/2477 [==============================] - 1s 225us/step - loss: 0.2140 - acc: 0.9156 - val_loss: 0.2029 - val_acc: 0.9226\n",
      "Epoch 189/300\n",
      "2477/2477 [==============================] - 1s 254us/step - loss: 0.2112 - acc: 0.9193 - val_loss: 0.2009 - val_acc: 0.9242\n",
      "Epoch 190/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2121 - acc: 0.9184 - val_loss: 0.1997 - val_acc: 0.9242\n",
      "Epoch 191/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2128 - acc: 0.9160 - val_loss: 0.2118 - val_acc: 0.9145\n",
      "Epoch 192/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2134 - acc: 0.9140 - val_loss: 0.2054 - val_acc: 0.9210\n",
      "Epoch 193/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2108 - acc: 0.9140 - val_loss: 0.2039 - val_acc: 0.9274\n",
      "Epoch 194/300\n",
      "2477/2477 [==============================] - 1s 230us/step - loss: 0.2129 - acc: 0.9172 - val_loss: 0.2057 - val_acc: 0.9242\n",
      "Epoch 195/300\n",
      "2477/2477 [==============================] - 1s 233us/step - loss: 0.2147 - acc: 0.9132 - val_loss: 0.2080 - val_acc: 0.9226\n",
      "Epoch 196/300\n",
      "2477/2477 [==============================] - 1s 242us/step - loss: 0.2122 - acc: 0.9160 - val_loss: 0.1972 - val_acc: 0.9290\n",
      "Epoch 197/300\n",
      "2477/2477 [==============================] - 1s 242us/step - loss: 0.2131 - acc: 0.9168 - val_loss: 0.2003 - val_acc: 0.9258\n",
      "Epoch 198/300\n",
      "2477/2477 [==============================] - 1s 241us/step - loss: 0.2137 - acc: 0.9136 - val_loss: 0.2075 - val_acc: 0.9242\n",
      "Epoch 199/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2172 - acc: 0.9128 - val_loss: 0.2045 - val_acc: 0.9242\n",
      "Epoch 200/300\n",
      "2477/2477 [==============================] - 1s 235us/step - loss: 0.2127 - acc: 0.9213 - val_loss: 0.2076 - val_acc: 0.9226\n",
      "Epoch 201/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2117 - acc: 0.9184 - val_loss: 0.2047 - val_acc: 0.9274\n",
      "Epoch 202/300\n",
      "2477/2477 [==============================] - 1s 245us/step - loss: 0.2151 - acc: 0.9152 - val_loss: 0.2067 - val_acc: 0.9258\n",
      "Epoch 203/300\n",
      "2477/2477 [==============================] - 1s 246us/step - loss: 0.2128 - acc: 0.9168 - val_loss: 0.2042 - val_acc: 0.9258\n",
      "Epoch 204/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2162 - acc: 0.9176 - val_loss: 0.2041 - val_acc: 0.9194\n",
      "Epoch 205/300\n",
      "2477/2477 [==============================] - 1s 255us/step - loss: 0.2090 - acc: 0.9164 - val_loss: 0.2009 - val_acc: 0.9210\n",
      "Epoch 206/300\n",
      "2477/2477 [==============================] - 1s 243us/step - loss: 0.2112 - acc: 0.9160 - val_loss: 0.1992 - val_acc: 0.9258\n",
      "Epoch 207/300\n",
      "2477/2477 [==============================] - 1s 238us/step - loss: 0.2108 - acc: 0.9176 - val_loss: 0.2244 - val_acc: 0.9274\n",
      "Epoch 208/300\n",
      "2477/2477 [==============================] - 1s 235us/step - loss: 0.2127 - acc: 0.9148 - val_loss: 0.1995 - val_acc: 0.9210\n",
      "Epoch 209/300\n",
      "2477/2477 [==============================] - 1s 233us/step - loss: 0.2089 - acc: 0.9168 - val_loss: 0.2063 - val_acc: 0.9242\n",
      "Epoch 210/300\n",
      "2477/2477 [==============================] - 1s 233us/step - loss: 0.2123 - acc: 0.9152 - val_loss: 0.2126 - val_acc: 0.9145\n",
      "Epoch 211/300\n",
      "2477/2477 [==============================] - 1s 243us/step - loss: 0.2185 - acc: 0.9124 - val_loss: 0.2096 - val_acc: 0.9242\n",
      "Epoch 212/300\n",
      "2477/2477 [==============================] - 1s 248us/step - loss: 0.2119 - acc: 0.9180 - val_loss: 0.2080 - val_acc: 0.9290\n",
      "Epoch 213/300\n",
      "2477/2477 [==============================] - 1s 232us/step - loss: 0.2118 - acc: 0.9189 - val_loss: 0.1990 - val_acc: 0.9226\n",
      "Epoch 214/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2098 - acc: 0.9180 - val_loss: 0.2031 - val_acc: 0.9210\n",
      "Epoch 215/300\n",
      "2477/2477 [==============================] - 1s 235us/step - loss: 0.2118 - acc: 0.9184 - val_loss: 0.2048 - val_acc: 0.9258\n",
      "Epoch 216/300\n",
      "2477/2477 [==============================] - 1s 230us/step - loss: 0.2084 - acc: 0.9217 - val_loss: 0.2094 - val_acc: 0.9242\n",
      "Epoch 217/300\n",
      "2477/2477 [==============================] - 1s 239us/step - loss: 0.2132 - acc: 0.9184 - val_loss: 0.2023 - val_acc: 0.9210\n",
      "Epoch 218/300\n",
      "2477/2477 [==============================] - 1s 234us/step - loss: 0.2097 - acc: 0.9164 - val_loss: 0.2082 - val_acc: 0.9258\n",
      "Epoch 219/300\n",
      "2477/2477 [==============================] - 1s 236us/step - loss: 0.2110 - acc: 0.9160 - val_loss: 0.1979 - val_acc: 0.9274\n",
      "Epoch 220/300\n",
      "2477/2477 [==============================] - 1s 230us/step - loss: 0.2105 - acc: 0.9172 - val_loss: 0.2105 - val_acc: 0.9226\n",
      "Epoch 221/300\n",
      "2477/2477 [==============================] - 1s 232us/step - loss: 0.2089 - acc: 0.9136 - val_loss: 0.2036 - val_acc: 0.9323\n",
      "Epoch 222/300\n",
      "2477/2477 [==============================] - 1s 230us/step - loss: 0.2111 - acc: 0.9144 - val_loss: 0.2028 - val_acc: 0.9274\n",
      "Epoch 223/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2119 - acc: 0.9160 - val_loss: 0.2018 - val_acc: 0.9258\n",
      "Epoch 224/300\n",
      "2477/2477 [==============================] - 1s 230us/step - loss: 0.2094 - acc: 0.9197 - val_loss: 0.2056 - val_acc: 0.9210\n",
      "Epoch 225/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2116 - acc: 0.9168 - val_loss: 0.2073 - val_acc: 0.9258\n",
      "Epoch 226/300\n",
      "2477/2477 [==============================] - 1s 229us/step - loss: 0.2132 - acc: 0.9172 - val_loss: 0.2071 - val_acc: 0.9242\n",
      "Epoch 227/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2118 - acc: 0.9164 - val_loss: 0.2024 - val_acc: 0.9258\n",
      "Epoch 228/300\n",
      "2477/2477 [==============================] - 1s 240us/step - loss: 0.2090 - acc: 0.9152 - val_loss: 0.2022 - val_acc: 0.9226\n",
      "Epoch 229/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2112 - acc: 0.9160 - val_loss: 0.2023 - val_acc: 0.9242\n",
      "Epoch 230/300\n",
      "2477/2477 [==============================] - 1s 232us/step - loss: 0.2136 - acc: 0.9120 - val_loss: 0.2068 - val_acc: 0.9290\n",
      "Epoch 231/300\n",
      "2477/2477 [==============================] - 1s 231us/step - loss: 0.2100 - acc: 0.9197 - val_loss: 0.2009 - val_acc: 0.9258\n",
      "Epoch 232/300\n",
      "2477/2477 [==============================] - 1s 226us/step - loss: 0.2101 - acc: 0.9176 - val_loss: 0.2044 - val_acc: 0.9226\n",
      "Epoch 233/300\n",
      "2477/2477 [==============================] - 1s 231us/step - loss: 0.2114 - acc: 0.9152 - val_loss: 0.2056 - val_acc: 0.9226\n",
      "Epoch 234/300\n",
      "2477/2477 [==============================] - 1s 230us/step - loss: 0.2091 - acc: 0.9168 - val_loss: 0.2122 - val_acc: 0.9145\n",
      "Epoch 235/300\n",
      "2477/2477 [==============================] - 1s 237us/step - loss: 0.2112 - acc: 0.9201 - val_loss: 0.2084 - val_acc: 0.9242\n",
      "Epoch 236/300\n",
      "2477/2477 [==============================] - 1s 232us/step - loss: 0.2096 - acc: 0.9164 - val_loss: 0.2007 - val_acc: 0.9226\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2120 - acc: 0.9201 - val_loss: 0.2028 - val_acc: 0.9226\n",
      "Epoch 238/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2116 - acc: 0.9176 - val_loss: 0.1974 - val_acc: 0.9226\n",
      "Epoch 239/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2081 - acc: 0.9180 - val_loss: 0.2090 - val_acc: 0.9194\n",
      "Epoch 240/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2133 - acc: 0.9164 - val_loss: 0.2024 - val_acc: 0.9194\n",
      "Epoch 241/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2082 - acc: 0.9189 - val_loss: 0.2007 - val_acc: 0.9258\n",
      "Epoch 242/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2109 - acc: 0.9180 - val_loss: 0.2030 - val_acc: 0.9274\n",
      "Epoch 243/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2103 - acc: 0.9189 - val_loss: 0.2072 - val_acc: 0.9226\n",
      "Epoch 244/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2154 - acc: 0.9156 - val_loss: 0.2020 - val_acc: 0.9242\n",
      "Epoch 245/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2146 - acc: 0.9164 - val_loss: 0.2028 - val_acc: 0.9258\n",
      "Epoch 246/300\n",
      "2477/2477 [==============================] - 1s 227us/step - loss: 0.2122 - acc: 0.9140 - val_loss: 0.1986 - val_acc: 0.9306\n",
      "Epoch 247/300\n",
      "2477/2477 [==============================] - 1s 224us/step - loss: 0.2151 - acc: 0.9112 - val_loss: 0.2016 - val_acc: 0.9226\n",
      "Epoch 248/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2127 - acc: 0.9140 - val_loss: 0.2179 - val_acc: 0.9258\n",
      "Epoch 249/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2089 - acc: 0.9164 - val_loss: 0.1995 - val_acc: 0.9242\n",
      "Epoch 250/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2105 - acc: 0.9156 - val_loss: 0.1959 - val_acc: 0.9242\n",
      "Epoch 251/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2122 - acc: 0.9152 - val_loss: 0.2081 - val_acc: 0.9274\n",
      "Epoch 252/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2100 - acc: 0.9164 - val_loss: 0.2022 - val_acc: 0.9226\n",
      "Epoch 253/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2111 - acc: 0.9136 - val_loss: 0.2045 - val_acc: 0.9210\n",
      "Epoch 254/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2141 - acc: 0.9152 - val_loss: 0.2007 - val_acc: 0.9258\n",
      "Epoch 255/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2087 - acc: 0.9176 - val_loss: 0.2066 - val_acc: 0.9258\n",
      "Epoch 256/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2122 - acc: 0.9176 - val_loss: 0.2064 - val_acc: 0.9226\n",
      "Epoch 257/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2191 - acc: 0.9108 - val_loss: 0.2028 - val_acc: 0.9242\n",
      "Epoch 258/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2099 - acc: 0.9197 - val_loss: 0.2018 - val_acc: 0.9258\n",
      "Epoch 259/300\n",
      "2477/2477 [==============================] - 1s 228us/step - loss: 0.2076 - acc: 0.9193 - val_loss: 0.2000 - val_acc: 0.9226\n",
      "Epoch 260/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2095 - acc: 0.9132 - val_loss: 0.2117 - val_acc: 0.9258\n",
      "Epoch 261/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2170 - acc: 0.9160 - val_loss: 0.2115 - val_acc: 0.9242\n",
      "Epoch 262/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2109 - acc: 0.9168 - val_loss: 0.2021 - val_acc: 0.9242\n",
      "Epoch 263/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2119 - acc: 0.9164 - val_loss: 0.2045 - val_acc: 0.9210\n",
      "Epoch 264/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2096 - acc: 0.9172 - val_loss: 0.2028 - val_acc: 0.9210\n",
      "Epoch 265/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2118 - acc: 0.9156 - val_loss: 0.2054 - val_acc: 0.9210\n",
      "Epoch 266/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2116 - acc: 0.9180 - val_loss: 0.2004 - val_acc: 0.9274\n",
      "Epoch 267/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2140 - acc: 0.9176 - val_loss: 0.2038 - val_acc: 0.9274\n",
      "Epoch 268/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2095 - acc: 0.9144 - val_loss: 0.2000 - val_acc: 0.9226\n",
      "Epoch 269/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2115 - acc: 0.9180 - val_loss: 0.2076 - val_acc: 0.9242\n",
      "Epoch 270/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2153 - acc: 0.9144 - val_loss: 0.2089 - val_acc: 0.9258\n",
      "Epoch 271/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2115 - acc: 0.9164 - val_loss: 0.1960 - val_acc: 0.9274\n",
      "Epoch 272/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2096 - acc: 0.9152 - val_loss: 0.1995 - val_acc: 0.9242\n",
      "Epoch 273/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2097 - acc: 0.9160 - val_loss: 0.1968 - val_acc: 0.9226\n",
      "Epoch 274/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2093 - acc: 0.9172 - val_loss: 0.1997 - val_acc: 0.9226\n",
      "Epoch 275/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2110 - acc: 0.9164 - val_loss: 0.1986 - val_acc: 0.9226\n",
      "Epoch 276/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2096 - acc: 0.9176 - val_loss: 0.2048 - val_acc: 0.9242\n",
      "Epoch 277/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2109 - acc: 0.9164 - val_loss: 0.2013 - val_acc: 0.9306\n",
      "Epoch 278/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2103 - acc: 0.9180 - val_loss: 0.2047 - val_acc: 0.9258\n",
      "Epoch 279/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2098 - acc: 0.9164 - val_loss: 0.2077 - val_acc: 0.9210\n",
      "Epoch 280/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2104 - acc: 0.9148 - val_loss: 0.2019 - val_acc: 0.9258\n",
      "Epoch 281/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2086 - acc: 0.9176 - val_loss: 0.2055 - val_acc: 0.9242\n",
      "Epoch 282/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2111 - acc: 0.9168 - val_loss: 0.2069 - val_acc: 0.9194\n",
      "Epoch 283/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2114 - acc: 0.9189 - val_loss: 0.2083 - val_acc: 0.9258\n",
      "Epoch 284/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2107 - acc: 0.9176 - val_loss: 0.2123 - val_acc: 0.9210\n",
      "Epoch 285/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2106 - acc: 0.9189 - val_loss: 0.1998 - val_acc: 0.9226\n",
      "Epoch 286/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2072 - acc: 0.9148 - val_loss: 0.2053 - val_acc: 0.9258\n",
      "Epoch 287/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2105 - acc: 0.9168 - val_loss: 0.1983 - val_acc: 0.9274\n",
      "Epoch 288/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2128 - acc: 0.9140 - val_loss: 0.2166 - val_acc: 0.9274\n",
      "Epoch 289/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2084 - acc: 0.9193 - val_loss: 0.1998 - val_acc: 0.9242\n",
      "Epoch 290/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2124 - acc: 0.9124 - val_loss: 0.2018 - val_acc: 0.9258\n",
      "Epoch 291/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2103 - acc: 0.9189 - val_loss: 0.1995 - val_acc: 0.9258\n",
      "Epoch 292/300\n",
      "2477/2477 [==============================] - 1s 222us/step - loss: 0.2105 - acc: 0.9156 - val_loss: 0.2031 - val_acc: 0.9258\n",
      "Epoch 293/300\n",
      "2477/2477 [==============================] - 1s 223us/step - loss: 0.2099 - acc: 0.9197 - val_loss: 0.1998 - val_acc: 0.9242\n",
      "Epoch 294/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2092 - acc: 0.9197 - val_loss: 0.2029 - val_acc: 0.9290\n",
      "Epoch 295/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2101 - acc: 0.9205 - val_loss: 0.2014 - val_acc: 0.9242\n",
      "Epoch 296/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2062 - acc: 0.9168 - val_loss: 0.2068 - val_acc: 0.9306\n",
      "Epoch 297/300\n",
      "2477/2477 [==============================] - 1s 219us/step - loss: 0.2155 - acc: 0.9172 - val_loss: 0.2111 - val_acc: 0.9242\n",
      "Epoch 298/300\n",
      "2477/2477 [==============================] - 1s 220us/step - loss: 0.2116 - acc: 0.9189 - val_loss: 0.1985 - val_acc: 0.9274\n",
      "Epoch 299/300\n",
      "2477/2477 [==============================] - 1s 218us/step - loss: 0.2129 - acc: 0.9120 - val_loss: 0.2052 - val_acc: 0.9274\n",
      "Epoch 300/300\n",
      "2477/2477 [==============================] - 1s 221us/step - loss: 0.2105 - acc: 0.9164 - val_loss: 0.2011 - val_acc: 0.9210\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model_Dense_train = model_Dense.fit(train_X, train_Y, epochs=epochs, batch_size=32, validation_data=(valid_X, valid_Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PELM_s Result\n",
      "Accuracy : 0.9209677419354839\n",
      "AUC : 0.9201613239401393\n",
      "Sensitivity : 0.9409937888198758\n",
      "Specificity : 0.8993288590604027\n",
      "F1 : 0.9251908396946565\n",
      "MCC : 0.8420135324127758\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot the training accuracy\n",
    "accuracy = model_Dense_train.history['acc']\n",
    "val_accuracy = model_Dense_train.history['val_acc']\n",
    "loss = model_Dense_train.history['loss']\n",
    "val_loss = model_Dense_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Dense Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Dense Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pred = np.argmax(model_Dense.predict(valid_X), axis=1)\n",
    "y_true = np.argmax(valid_Y, axis = 1)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "f1 = f1_score(y_true, y_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "auc = roc_auc_score(y_true, y_pred, average='macro', sample_weight=None, max_fpr=None)\n",
    "sensi = tp/(tp+fn)\n",
    "specificity = tn/(tn+fp)\n",
    "accu = (tn + tp)/(tn + tp + fn + fp)\n",
    "mcc = ((tp*tn)-(fp*fn))/np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "print('{} Result'.format(string_name))\n",
    "print('Accuracy :', accu)\n",
    "print('AUC :', auc)\n",
    "print('Sensitivity :', sensi)\n",
    "print('Specificity :', specificity)\n",
    "print('F1 :', f1)\n",
    "print('MCC :', mcc)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
